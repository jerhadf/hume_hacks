Hello world, what is up? Welcome back to the Feelings Lab. I'm your host Matt Forte and for today's episode, we're talking about you. That's right, our team meticulously combed through the mountains of junk mail that comes with a public facing email address and found some of the best questions you've submitted to us here at the Feelings Lab. So today, I'm taking those questions and I'm making Alan answer them. And by making, I of course mean asking politely. We're also going to take a look at some of the latest news in the world of emotion science. Alan, did you know lobsters have feelings? I didn't. Did you know that? No, I didn't know. I still don't know. Yeah, okay, well, we'll see. I don't know if that makes them more or less delicious, but we'll get into that and more stories just like it in a little bit. Before any of that, what would this show be without my co-host? I already brought him in with the lobster thing, but please welcome a friend and why the hell not my inspiration, the one and only Dr. Alan Cowan is here. Alan, wonderful to see you as always. How are you doing? Are you doing all right? Doing great, Matt. It's great to see you too. Thank you very much. I appreciate that. Okay, now I know I always say I'm excited and I also always say, but this time I mean it. But in my defense for this particular episode, this has been a long time in the making. We've been accumulating all these audience questions and I've been saying for a month now, every episode, let us know what you're thinking. Maybe we'll answer them on the air and so on and so forth. So I think I'm speaking not just for myself, but for the audience as well. For the listeners, when I say this is a very exciting episode, we're finally going to get to hear some of your thoughts, Alan, on what they've been writing in about. I'm pretty stoked for that. Have you looked at the questions yet? Are you going in blind? What's your method over there? Have you seen them already? I think I've seen some of them, but I haven't seen all. Nice. Very good. That's what I want to hear. Okay, so very good. Before we get to the questions, let's jump into some news. How do you feel about doing some news first? You want to do news with me, Alan? Is that sound good? Yeah, let's do news. Let's do news. I think we should get, you know, we should, I say this as if I'm not going to edit it later, but I'm going to find like some royalty free, like a news stinger, like a bulletin. So like, did it, did it, did it?
Just to add to the drama of this moment. Very dramatic. Okay. First up, this is an article I dug up from sciencedaily.com. Headline is research shows the role empathy may play in music. So this caught my eye right away. I'll read a little bit and then we'll get into it. So it says here, can people who understand the emotions of others better interpret emotions conveyed through music? New study by international team of researchers suggests the abilities are linked. The findings were published recently in Emotion, a scientific journal of the American Psychological Association. The study was led by Benjamin A. Tabak. I apologize, Benjamin, if I've butchered that. Assistant professor of psychology and director of the social and clinical neuroscience lab at SMU and Zachary Walmart, assistant professor of musicology and affiliated faculty at the Center for Translational Neuroscience at the University of Oregon. Okay. One more quote, and then we're going to jump into discussion here. They said, we thought it would be interesting to study rather people who more accurately understand others' thoughts and feelings might also be more accurate in understanding what musicians are intending to convey through music. Similarly, we wanted to know whether people who tend to feel the emotions that others are experiencing also tend to feel the emotions conveyed through music. Before we go any further, I don't know how large or small the emotion science community is. Those names ring a bell. Do you know those guys, Alan? Do you know those dudes at all or no? Is that the names again? It was. Okay. Here we go. Here we go. I scrolled back up. It's Benjamin A. Tabak and Zachary Walmart. Rings a bell. Rings a bell. Rings a bell. All right. I'm going to get a bell sound effect as well. Early results are showing that yes, they are in fact linked. Alan, you had a chance, I think, to take a look at this. I sent you this earlier to read. What do you think about the study or what they found here? What were your thoughts in reading through this particular piece? I mean, it's a great study. I think it really aligns with what we see a lot in our data. I haven't really formalized it, but there are people who, just based on our studies, who label facial expressions and vocal expressions and music and they do it all. Some people are really granular and kind of...
I think that might be a big part of it. There's probably some separation you need to do between emotional granularity. So, I think they did some analysis on this too. I'll probably have to read the study in more detail. But and like, what is it that's, you know, that's accurate? You know, what's the accuracy of a judgment versus like, I'm just, you know, spend more time thinking about it. Maybe it's also motivational. I think a lot of it is motivational. People are really interested in emotion sort of inherently and want to spend the time thinking about that and kind of deciphering it. Well, it's so funny. You mentioned the accuracy, right? And that feels like something I've heard come up multiple times on this show. It's like the holy grail is how do we know we're getting accurate data, accurate information? How accurate is this person's assessment? What is missing? How many years away are we from having the exact accuracy that you dream of at night? What is limiting us from knowing 100%? Yeah, I mean, like, accuracy means so many different things. And when you're studying emotion, people get confused about it because emotion judgments are really judgments of something that's intangible. So, just something that somebody is feeling, right? And there's no ability to know whether you're right or wrong. Even like the person's self-reported emotions might not be incredibly accurate. So, there are ways of conceiving accuracy. If you presented this expression to a wide swath of the population, what would be the modal response? Somebody could say, I think this is how this is perceived by the average person. Or I think this is the range, this is the distribution of how this was perceived. Or I think this is the distribution of self-report that somebody or a distribution of people might say they felt in response to a bit of music or they say they're feeling while they're expressing that thing or making that for facial expression. I think there's a sense in which there is accuracy to that. But I think that rather than do the one-to-one mapping between single expression and single set of feelings, I think it's important to think about distribution overall. And there's very...
I'm going to ask you a really silly question here. Do you think it'll ever be possible to, in the same way that we, do you ever think it'll be possible to get data directly from an individual's brain via some kind of crazy implant? Will we ever decode the synapses and the firing in such a way? Is that ever going to be within the realm of possibility? Or is that like Star Trek level stuff of just like, whatever happens in here, we're only ever going to know so much. What do you think in our lifetime? Let's say you could measure every single neuron in the brain and perfectly accurately. So you had a full description of everything going on in the brain. You still would have to rely on what somebody says they're feeling to link like their activity in that map of neural activation to feeling. And you still wouldn't know if what that person meant by saying they're sad is the same as the next person. Yeah. And so you couldn't with absolute certainty say that this person is sad in the way that the other person is feeling the same exact emotions. It's impossible unless... Yeah. Here's what I think you could do. Is if you figure out a way that you can connect your brain to their brains... Loving it. Keep going. Keep going. Preferably by some kind of device that looks like a pasta colander with Edison light bulbs sticking out of it. If we can get that going, I'm on board. So, okay. We connect my brain to their brain. Okay. It could be that. Whatever it looks like. And I don't think it's just like... I'll handle the aesthetics. You worry about the science. Okay. Pasta colander would be cool. There we go. Okay. So I'm wearing that. I'm connected to the other person. Keep going. I think it's just some kind of organic thing. Anyway, like let's say you could do that and you actually were able to feel what the other person was experiencing. Then you could start to study what is it that... What do you think is the exact correspondence?
Okay, I'm following you, not to cut you off, but I'm so happy you're going with me down this path. So we would need another human brain to connect directly to that brain to interpret it, right? Is that what you're saying, basically, to like, kind of sync up? Well, like, you need to know if that person's sadness is the same as the other. Sadness is kind of like, that person's joy is the same person's thing as the other person's joy. Is it the same feeling? In order to feel that, you would have to have a device that made you feel their feelings, each person's feelings in turn, and you could identify for yourself subjectively, whether they were the same thing. Otherwise, like, there's no, there's no other way to compare the subjective. Got it. Okay, good. And I could spend another hour on that, but let's keep going. We got a lot of stuff here. Last thing I want to do on this story was there was this line, Professor Tabic says towards the end, we also hope that our work will highlight the value of conducting interdisciplinary research that spans the science and humanities. And so Alan, please forgive my ignorance of all of your work here. But in your career, have you conducted research in a similar way insofar as the interdisciplinary aspect combining science and humanities? Yeah, I mean, I think right now, fundamentally, psychology has just been, it's almost more humanities than science. That might offend some people, but it shouldn't, because why should we be offended to be humanities, right? But, you know, there's certainly an attachment to history. We take an intro psych class, we learn a lot about all the different, like William James, and the behaviorists, and all these people. You wouldn't learn so much about the history of physics in a physics class, except that somebody's name is attached to a formula. And then you learn a little bit about it. Yeah. Other than that, just like, you actually have a cumulative theory to test. I think psychology is more in the idea stage. And it's kind of like philosophy, where you discuss ideas and who had them. More often than not, the cumulative theories and definitive tests of hypotheses. And so, yeah, and psychology is deeply informed by philosophy. And particularly with emotion, there's a lot there. Yeah, I'm learning, yeah. And in an emotion class, you learn, an emotion science class.
We learn about Aristotle's ideas about emotion, we learn about Darwin. Darwin was a philosopher. But yeah, it's deeply a humanities oriented discipline. Very cool. All right, let's keep moving. We got another awesome story here. This next one is from nature.com. And Alan, you came across the story and sent it over the headline, why video calls are bad for brainstorming. And I'll get into how I feel because we just came with that whole colander Edison bulb brain connection idea over video. But you know what, that's neither here nor there. Let's keep going. Let me read a little bit of this story. Around the world, video meetings have become the new normal. But what impact could this have on our work? According to new research, one important skill is impacted by the restrictions of video calls, brainstorming ideas. But why is this task in particular negatively affected? And could other skills actually benefit from virtual communication? This was a super cool piece. I watched the video. And we'll have links to the accompanying story and video and all that stuff in the episode description. So you guys at home can check it out as well. Alan, what about this one jumped out to you that you said, Oh, we got to talk about this. And you sent it over. Why did this jump out for you? Well, I mean, it's a super important topic, because right now, so much work is being done over video. And so if there was an effect of video communication on creativity, the world would be less creative as a result of that. That's a pretty, that's like an important finding, right? I never, I always, I like to think that I'm a relatively intelligent human, but I never extrapolate things to the extent that you are. So when you guys drop something like that, I'm like, Oh, crap, that's right. Everything is less awesome. I didn't even think of that. Yeah. That's why it's in nature. I love studies that are, it's like not a super complicated study. And it's pretty big 1000s of people. But fundamentally, it's not the most insane methods. So what's amazing is that when a study like this gets published in nature, it's because it's asking a really important question. I love studies like that. Yeah. The analysis they do is that actually, their explanation is that the reason that video communication suppresses your creativity is because you don't have a lot of time to do it.
There was one difference between virtual and in-person conversations that did seem to make a difference, and Melanie spotted it by tracking people's gaze. Are you looking at your partner? Are you looking at the surrounding environment? Or are you looking at the task? And it's interesting, again, if you ask people what their intuition is, they think that there's more social connection when we're in person, and so we're probably engaged with our partner more. But we found the exact opposite. So we found that in the virtual condition, people are looking significantly more at their partner, almost double. And because of that, it's at the expense of their broader environment. Previous research has shown that people are more creative when they're less focused. When I'm communicating in person, I have the entire environment as our shared environment. Wherever I look, that is going to be part of my partner's environment too. However, when we're talking virtually, our shared environment is pretty limited to the screen. And we thought that this could lead to more focus, which would hurt idea generation, because we're actually the most creative when we're unfocused and free. So rather than online conversations being inherently always better or worse, it could be that we need to adjust how we talk based on what we want to achieve. All right, so I stopped, I cut you off to the throat of that, because what was so interesting to me, and we've only ever scratched the surface on here of how powerful and important one's gaze can be. And this was something that I wasn't much like how you extrapolated the data into the effects on all of it. I wasn't even thinking about gaze in this way. But when I started to think about it, yeah, an individual's gaze can be super important in communication. Sometimes I'm pretty sure my dog looks at something just to get me to look at it. How significant for you guys, Alan, has it been tracking someone's gaze, understanding the meaning behind it, and stuff like that? I want to ask that. 
And I want to go back to what you were saying about the significance of it to them and their findings. But how important has it been to you to keep track of that, of where we're looking and what we're doing? It definitely signals something socially. And I think this gets really into the reason, I think, for their findings, which is that when you're looking at each other, you're kind of signaling, I'm in the midst of thinking about what you're saying. And we're sort of to the point, whereas when you're looking away, you're kind of signaling to somebody, I'm in the midst of thinking about something else. And it gives you an opportunity to break away from the linearity of the conversation and kind of bring in other ideas. But it's because it's like an important signaling mechanism. That maybe is not, they see it as like a signal of focus, but I think even when you're looking away, you're still focused on something. I agree. I agree. Was that the part that you started to, I don't want to put words in your mouth and say, take issue. But you were like, I don't know about that. Right before I cut you off, was it the idea that if your gaze drifts, that you're not focused? Is that the thing that you were saying? Like, I don't know if I align with that. Yeah. Well, I think that it is a way of explaining the findings. I don't think it's wrong. I think it's just that they need to think about sort of the social significance of it a little bit more than thinking about it in terms of like purely cognitive. I think their explanation is purely cognitive and not social. And creativity is also something that comes out of a certain kind of focus, different kind of focus. But it's nice. It's more focused internally on ideas that are being produced in your brain and focused on ideas that are coming from the environment. That's the difference. And we're able to do that, you know, when you're a person, I think the key thing is my explanation. And this is something probably worth testing, is that when you're in the same environment as somebody and you look away, it's very clear to them that you're not looking at anything specific because they're in the environment with you and they know that there's nothing there. Okay. But when you're on video chat and you look away, it looks like you're distracted.
That's why you can't look away. And Alan and I have run into this numerous times where he allows me to stare off into space hours at a time. And it's where I derive a lot of my creative ideas from, but I assure him I'm not ignoring him. I'm not. It's funny. They tap on. They do mention that in the clip, the significance of a communal space and how they don't really dig deeper into it like you just have there. But you're right. I didn't even think of that. If we're in the same space, I know what it is that you're looking at, even if it's not me. Versus now, if you were to just look off screen, I'll sit here going, what the hell is he distracted by? I'm talking to him right now. And I could see how that could impede creative progress and collaborative progress. But very interesting. OK, any other thoughts before we move on to our third and final story and then get to some questions? You good? Yeah. Yeah. OK, very cool. Our third, I couldn't be more excited. I teased this in the opening. This one was from BigThink.com. And again, all the links will be in the description and show notes so you can check them out for yourself. Here it is. The inner life of a lobster. Do invertebrates have emotions? And this is near and dear to not only my heart, but this show's heart. Every episode in the first season, I asked Alan about animals and emotions. So let's let's talk a little bit about this article. Let me read a bit. Many people agree that dogs, as well as cats, chimpanzees and other mammals, have feelings. Most would argue that these animals experience a whole suite of emotions from joy to distress. In other words, we consider dogs sentient, meaning they can have feelings beyond simple pain. But if you ask anyone to consider the emotional life of a hermit crab, you will probably get a more skeptical response. The inner lives of invertebrates like hermit crabs recently made news overseas when deciding whether to add invertebrates to its animal welfare bill. The British government commissioned the London School of Economics and Political Science to, I love everything about this story, to assess the evidence supporting invertebrate sentience. The LSE team reviewed more than 300 scientific studies on the topic and came to a firm conclusion. Are you ready for this? Hold for dramatic pause.
There is solid evidence that mollusks and crustaceans are sentient. The government took LSE's advice and confirmed that the scope of their animal welfare bill would extend to most crustaceans, most including crabs, lobsters, and crayfish, as well as cephalopod mollusks like octopuses and squid. I mean, what more can you ask for? This story has it all. First of all, I'll never skip a chance to say the word cephalopod mollusks on this show. If it presents itself, I'm going to take it. Second, this has my favorite things. It's got animals. It's got emotion science. It's got British government officials seriously debating the validity of what lobsters feel. And I've said it many times in the show. I love that. Alan, first blush, what do you think of this story? You seem skeptical, sir. What do you think? I'm not skeptical. You're not? Okay. First of all, I'm asking, why is the default that lobsters don't have feelings? That's the question. I mean, I would have assumed that everything that has motives and flexible thoughts, like cognition and has an environment that has to kind of weigh different considerations and make a decision. I mean, those things, like, I think... It's a very good point. It's a very good point. They do. They make decisions. They make calculated adjustments. They make movements based on their environment. And those decisions must have some level of emotional weight. Who knows what that spectrum is, but they must exist, right? How else do they make those decisions? Right. I mean, you don't know, right? You'll never know for sure. But if we're just going by whether something makes... I think what the study reveals is that when you really watch something and living its life, you start to realize it's smarter than you thought. I think that is a really key finding, but not surprising, I think. It's not surprising. It's always fun to have it confirmed. Here's a little anecdotal evidence, and I don't know if this is even applicable here, but I have a very good...
I have two good family friends and they live on Martha's Vineyard now and every once in a while I'll get to be fortunate enough to go out and visit them and see them. And typically when you're out there, what do you eat? You got to have at least one lobster dinner, right? And my friend's mom, who infinite wisdom and one of the kindest souls in the world, insists that before we boil the lobsters, she holds them upside down and gently strokes their underbelly and what she calls hypnotizes them so that it's less traumatic when she puts them in the pot. So I've been a part of a circle that is firmly believed in lobster emotion for a while. So it's just nice to have those suspicions confirmed from British officials, government, British government officials. I mean, how much more official do you get than that is what I say? You got to hypnotize your lobster. You have to. That's the takeaway from this episode, everybody, is hypnotize your lobsters. You just said a moment ago, we'll never truly know. Here comes another patented Matt Forte insanity question. If there's evidence to support the scientific community believes, and as you said, if you observe long enough, we know there's emotions. How many decades away are we from or is it truly forever impossible for there being an emotion map for the animal kingdom similar to the emotion map that you guys have built for human existence? I know we're just now getting used to that existing. It's brand new. But do you think it would ever be possible to do something similar to better understand that of the animal world? And I understand why that's a crazy question, but I would like to know a smart person's take. I mean, Darwin tried to do that. The expression of emotion of man and animals. He was really talking about animals a lot, birds and monkeys. And I don't know, maybe talk about lobsters. I have to check. But like that book, two things. One is there's a kind of self-report experience that unless we find a way to get animals to communicate with us, maybe dolphins. I don't think we're going to be able to do that. We're not going to be able to ask them. But what Darwin described as purposeless behaviors, and he didn't mean that.
They have no purpose. He just meant they have no functional purpose other than communication, and I think that gets misunderstood sometimes. His aim was to look at primates, and if they had what was seemingly an expressive behavior and it didn't serve a kind of behavioral function or function other than just communication, then he considered that an expressive signal. And you can map those out. And I think he really set the stage for mapping those out. And that's what he tried to do, not quantitatively, but qualitatively. And I think we can. I think we should. We should have that. And there's lots of studies of... People started it with chimps, actually. And you can do studies of facial expressions. And I saw one that's seven different dimensions compared to some of the human facial expressions and saw parallels there. So, yeah, I think that needs to be done. Yeah. Very cool. All right. Amazing. Well, those were the stories that jumped out this month. Obviously, there's a million more, but we only got so much podcast here. So, we'll put links and info to all of that stuff in the show notes and description so you, like I said, can read along and watch for yourselves at home. But the time has arrived. Let's go ahead and let's finally do it. 20 some odd episodes, eight, nine months in the making. Alan, let's take some listener questions. I can't wait because I'm almost positive none of these are for me. And I got to say, actually, I was pretty impressed with a lot of these, right? I don't know about you. I was impressed with some of these questions. I thought these were really great questions. When you open the window to the world with no screen, anything can fly in, right? You put a call to the universe like we have. You're going to get your jokers, your funny guys and gals, your ne'er-do-wells, your chuckle heads. And we saw plenty of that. We did. But there were multiple hidden gems in there. So, no more delay. This first one is from Ashley. And Ashley writes, hello, I'm Ashley. Hi, Ashley. I'm an undergraduate at Harvard. Ooh, let me pick up that name she just dropped real quick. Harvard. Humble brag, Ashley. And I'm a huge fan of the Feelings Lab podcast.
And I just made fun of you. I'm sorry, Ashley. Thank you so much for being a fan of watching the show. All right, Ashley goes on to say, data exposure and privacy are obviously becoming a huge concern for users of any technological platform. And I was wondering how we can address the privacy risks of emotion AI. And we've talked about privacy risk before in the show. Alan, I'm going to sit this one out. I'll let you take it. What do you think? Yeah, I mean, this is a really frequent question that we get. It really speaks to legitimate concerns people have about their privacy and AI-based surveillance and what's going on with their data. And I think when you're adding more data into the equation of empathic AI, it adds to that equation. But before I delve too far into the surveillance use case, which is a very small, hopefully, swath of the uses of emotion AI, empathic AI, face recognition, and so forth, maybe bigger for face recognition. Before I delve too far into that, I just want to make the distinction that privacy is probably not about whether your data is being accessed by more algorithms, unless you're really, truly concerned that there's an AI that's so smart that you actually worry about it judging you or whatever. It's about who... Humans have access to your data. So a lot of your data is being processed by algorithms. And you don't care. You thought about it. For example, algorithms to improve the photos that you take on your phone. Every time you take a picture on your phone, you're actually taking a bunch of pictures in sequence and algorithms deciding what's the best one. You like that. Users want it. Algorithms that improve your results on Google. You search Google for pretty intimate things. Some people do. Intimate things. And you want them to be kept private. And hopefully they are. I think they are. And not being seen by other people. And so Netflix recommendations, all kinds of things. And so what's the privacy concern with another algorithm analyzing that? That's not really the concern. The concern is what if this is leaked? Or what if somebody... I don't want to have access to my Google searches as access.
Age-old what if this falls into the wrong hands, this sort of thing. An entity doing surveillance or whatever, your first concern when somebody has your Google search history is probably not like, are they analyzing the sentiment of my Google searches? Oh, no. No, my first concern is I've got to get out of the country. Yeah, I've got to leave immediately. That's my first concern. I think whether someone's analyzing the sentiment of it is like the least of your concern. You can have a drop of data from that, but the semantic value of that is more what the concern is. If it's face recognition, where you were more important probably than what you were expressing at a given time. So it's not, you know, empathic AI does add to the suite of surveillance technologies. And that's something we can, we should be concerned about, in my view, is that that's a misuse of the technology, that if you have a reasonable expectation of privacy, neither empathic AI, nor face recognition, nor language transcription should be used to mine that data and use it against you. It should be private by default. They're very clear that surveillance is a bad use case. Yeah. Very anti-surveillance. Yeah. But that being said, if there's just another algorithm that is being used privately on your phone, and nobody sees the output of that, but it's used to inform things that are helpful to you, like that's not a privacy issue really at all in any, you know, it's the same thing as like a compression algorithm, like it's being used to help you store more photos. The fact that the compression algorithm sees your photos, you're not worried about that as a privacy leak. So I think that's sort of how we need to think about this issue. One of the things from the moment we first met, and one of the things that endeared me to Hume and what you guys were doing is how much you mentioned and made a point to say, we are working on establishing the ethical guidelines for how this stuff is going to be used and focusing so much on the ethics of it. And that was always such a priority from the second I met you. And that gave me good vibes. I was like, all right, well, let me see what's going on with these people and feel them out. But I knew from the beginning because of that, because I don't hear a lot of that. I hear, I see a lot of that in headlines.
It's buzzwords and stuff, but you guys are putting in the work, and it's a very big focus. And I know you put a lot of effort into making sure that those guidelines are being established, and that's a very big priority for you guys. And that's been true from day one, long before you met me, right? The Hume was founded on that. Am I correct in that? Yeah. I mean, when we created Hume AI, we also created the Hume Initiative, which is a separate nonprofit with the commitment that anybody using where Hume AI was putting out to the world would have to comply with the Hume Initiative's guidelines, which have now been voted upon by ethicists, by AI researchers, by cyber law experts, by health ethicists, or independent people who don't know what's interesting in Hume. And that's how we determine what are the supported use cases and where are the unsupported use cases, the ones that we actually say you cannot pursue with Hume. And we have defined surveillance as an unsupported use case. You cannot use our technology to pursue it. And things like manipulation, and we define that in our guidelines. So you shouldn't use people's data against them, essentially. Unless, of course, it's like somebody who's misbehaved on a social media platform and they're bullying somebody. And then you can say like, oh, well, probably should use this to make sure there's less bullying. And look, and I agree with you wholeheartedly. But I mean, you want to talk about slippery slope because then it's like, well, what if the generally accepted bad guy feels like he's being bullied, but it's like you're just trying to correct the air and help him? It's such a slippery slope. This is a really big... And so you always need to have an appeals process, which will give humans to moderate it. And that's never going to change. But at the same time, there's just an enormous amount of misbehavior that happens. And if you want to catch it in time to actually protect people, you can't just rely on human moderators. It's not even feasible. So you need to flag it somehow. What a wild problem humanity has to solve. It's so crazy. All right. Great question.
Question, Ashley, thank you so much. Go, I think it was a Pilgrims. What's the, you know, the Harvard mascot is, I think it's the Pilgrims. I could be wrong. It's a color. It's a color. Crimson. Crimson. Right. Okay. I don't know where I got Pilgrims. I know. Yeah. I'm Dan. I know that. I know they have a bulldog. Yeah. Yes. I know that from Gilmore girls. So yeah, I went to art school. I don't know why I'm trying to drop sports knowledge here, but thank you, Ashley. And thank you, Alan. Let's go on. We got another one from Julia. Julia writes, hi there. My name is Julia from Berkeley. Is there a healthy level of emotional expressivity that is conducive to long-term emotional wellbeing? That is such a very eloquently, succinctly worded question, Julia. Very smart. Alan, what do you think are the long-term benefits to regularly engaging and expressing our emotions? Is there a bar we should aim for there? How do you think about Julia's question? Yeah, I think that there's a lot of evidence to show that, you know, definitely expressing certain emotions is beneficial and doing it routinely. Expressing gratitude, laughter is good for people, really good for your relationships. And not suppressing negative emotion, not suppressing sadness. Yeah. And confronting it. I mean, this has been hypothesized for a long time. I'm not sure that there's really a definitive proof. Yeah. But I think it's pretty apparent. And different emotional regulation strategies. So if you do feel sad, suppression is bad. Things like reappraisal are good. That's pretty definitive. How fine is the line between healthy expressivity of emotion and someone who just loves the drama? How do you know you've expressed enough? And if I don't stop, I'll have expressed too much and people will talk about me behind my back. Do you know where that line is? Have you found it? You know, I don't express my emotions, Matt. You went the other way.
You let the pendulum swing too far in the other direction. I do. Well, I think some people are more expressive than others, and that's for sure. I think that in some cultures, being really intense about your emotions is not as socially acceptable. And so in those cultures, and being content is sort of the main thing. For example, like Tibetan Buddhism, the goal is contentment. It's not like pleasure or amusement or whatever, the euphoria. In Western cultures, well, the cultural cultures that we associate with romance languages and so forth, are generally much more in favor of positive emotions. Hmm. Very good. Awesome. Awesome question, Julia. Thank you for that. I don't know why seeing the word expressivity written out really choked me up in the middle of that one. Assuming it's the same Berkeley, say hi to Decker for us over there. We got time for a couple more. The next one is from Moses. Let me pull this up here real quick. Moses writes, oh, I like this. Moses doesn't waste any time with any familiarities saying hi or anything like that No, Moses. It's just one word opens this whole thing. Bias. And then dash. All right, Moses. I like it. A person of business, right to the point. Bias. I've heard that people in different cultures express emotions differently. Yeah. By using English emotion terms, are we introducing a Western bias? That's a really cool question. All right. Thank you, Moses. So what do we think by using English emotion terms? Are we introducing a Western bias, Alan? Yeah, I mean, this is a really important topic for emotion science and empathic AI. And we gather data from around the world. So we can actually address this in a computational kind of data driven way. And that's been our approach. So rather than taking a few pictures and getting people to label them in different cultures, we actually take thousands of responses to stimuli, actual people.
The lab is designed to help people understand what they are feeling at the time and what they say their expression means. They do it in their own language, like English emotion terms, Spanish, Mandarin Chinese, and Empiric. And they use emotion terms in terms of smile, scowl, laugh, and cry. And about 75% of the time, the English emotion terms line up with what people say, what experts say is their most direct translations. Different cultures when they're used to describe expressions. And that's like when you're looking at globalized culture, somewhat globalized cultures. I mean, almost everybody on Earth, basically. But about 25% of the time, there are subtle to moderate differences in what the expressions mean in terms of how they're linked to emotions. And so it could be misleading in some cases to say, like, this is the emotion term that's linked to this expression. In addition to the fact that, like, you don't want to describe an expression in emotion terms and have people think that you're trying to attribute that emotional experience to that person. When people know that it's a social signal, it can be authentic, it can be posed, or it can be used for communication and all that. So, there are all these subtleties that we're sensitive to. On the other hand, like, if you don't use emotion terms at all, it's really hard to capture the meaning people take away from expressions or even just like characterize a facial expression at all. Like a scowl is just this really... And it turns out that that's just not a very specific word. It can be pain or anger or any number of things. But the expression people associate with pain is so reliably distinct from the one people associate with anger. And so it's tricky. You kind of have to use emotion terms if you want to get at the specificity of expressions. Then we train algorithms on those terms. And it's not that we are trying to predict what people are feeling, but the terms, the set, the suite, the distribution of terms people use to label an expression. And we use methods that basically take out the different compounds. And then we take those...
Algorithms, and now the outfits are proxies, like basically anger in this algorithm. We have one for facial expression, vocal expression, and they don't always align. So it should be very clear that this is not attributing a feeling. There's different modalities, not saying the same thing, but it's a really good proxy for what is a pattern of expression. I'm curious, if you if someone came to you right now, and they said, Hey, I'm going to get as specific as I can with my limited knowledge of the actual work you do. But if someone said, Hey, we want to leverage the data sets that you formed. And we want to do something in three completely different cultures in three completely different parts of the world. Would you say, Okay, our data set has been trained to address those biases? Or would you actually say, Okay, well, we should establish three separate data sets unique to each region so we can get the best data possible. So this is a really good question. So I mean, it depends on what they're doing. What our data sets do is they take as many different dimensions of expression as possible. And they say like, Okay, this is the anger expression that recognizes anger in the US, China, Venezuela, India, Ethiopia, where it's like most direct translations are Chinese, Spanish. And, you know, this expression means contentment in this country. And, and, you know, relaxation in this country, maybe those are close. And then in this country, it means something slightly different. It means excitement. There isn't a question like that. But like, we have, we have certain dimensions that actually don't have the same meaning in different cultures, right? But they do serve as a really good embedding of that same facial expression, independent of who's forming it, their gender, their ethnicity, their age. So you have this amazing embedding of expressions. And then you have like, what might be different meanings, but you're not interested in like, depends on what you're interested in, right? And doing right, like, if you're predicting whether somebody is, let's see, like, whether somebody's feeling
And if you're not sure whether to say the word well or not, then you probably want to collect some data points on what well-being looks like in those different cultures. But now you have the expression, the facial expression, vocal expression, language they're using, and you can train a model that's really simple, maybe because we have a really good embedding, to go from, like, what are the different indicators of well-being to well-being, basically. And it could be a different model in each culture, but you don't need as much data to train that because now you've started with something so rich. Got it. Thank you. Thank you, Moses. Another great question and great answer, Alan. All right, let's do, we got one more question because we're coming into the homestretch here. Let's get one more in. It's from Imran from LA. Okay, this is a long one. AI is in everything now. I'm reading about a bunch of other emotion AI companies. Oh, I'm not going to read this list. They list a bunch of other companies. They can start their own podcast. Here's the question. Okay, here it is. How is Hume different from the other emotion AI companies? Pretty straightforward question. Thank you, Imran. All right, Alan. I can't fathom a person better suited to answer this than you. How is Hume different from other emotion AI companies? Oh, man. I mean, there's a lot of differences in sort of our approach. And so, you know, I think you have to start with the science, right? So for a really long time, there's emotion science, there's affective computing, which is sort of the field of computer science that trains these algorithms. And the way they've sort of functioned for a really long time is let's take faces. And we already know sort of what the emotions are that are expressed in these faces. Because some guy in the 1970s said it was happy, sad, anger, surprise. Good job, some guy. Thank you. He didn't really say that, but that became the norm of how you categorize facial expressions. And they focused on faces. The emotion science field for a long time did focus on face. But they kind of like affective computing assumed these things have been solved. And then they brought in people and they said, all right, let's sort these expressions into these known categories. And.
And that's how we're going to train our algorithm, or we're going to use facial action coding system, which is another scheme in the 1970s for how you label faces, but it's a trained graders. We trained for a week. And the premise is that now you can identify all the different facial muscle movements by looking at somebody. So I can look at you and I can say, you're a larvicularis oculis active or whatever. I beg your pardon? Which is like the bottom of the eye muscle that you make when you smile. I've been seeing someone about that. Thank you. Thank you. But humans are not actually good at doing this, even with a week of training. And it turns out these quotes are difficult to get even, you know, and they're kind of sensitive to age or people with more wrinkles in their face can get labeled with more of these quotes. Yeah. So these are kind of older ways of doing things. And the way we've come about it is we've decided, look, instead of assuming that these were solved problems, we should actually address these problems for a data science perspective from the first time. And the algorithms themselves that we're training are like scientific models that we're actually using to derive the meanings of different expressions. Different approach. We come to different conclusions, like the fact that there is, you know, over 27 different dimensions of facial expression that, you know, at least about 20 of them are pretty similar in meaning across all six countries we've collected data from and counting. And there's, you know, some subtle to strong cultural differences in how people interpret the other seven, but we have an embedding of the other seven. And, you know, these are all distinct dimensions. And the basic six, if you categorize things in terms of those six emotions that people focused on, they turn out to capture 30% of the space. And, you know, that's maybe pretty generous. This is often based on those facial expressions. And you go out into the world, most people's expressions are not that intense of anger, sad, happy. They're like confused and boredom and so forth. Anyway, so.
You're doing things a little differently. We have algorithms to capture much more, and we're doing it with experimental methods. So instead, the main two approaches people use, the main approach people use for a long time, is let's take some images from the internet, give them to professional raters. And the raters will say, you know, this is the anger expression that, you know, I've been taught to label, and this is surprise. But perception is really influenced by what somebody's wearing and their gender and ethnicity, and so on. Particularly for some expressions, like a triumph expression, really depends on if this is a person in a sporting jersey, you know, or if it's the pride expression. Pride, whether something's recognized as pride really depends on whether somebody's wearing sunglasses. Everyone wearing sunglasses is right as being proud. What we do instead of doing that is we actually gather data on what people say their expressions mean in real time. We use experimental paradigms to evoke a whole lot of different expressions. So we have different people with different cultures, expressing the same kind of distribution of expressions, because we've carefully designed the experiment, and labeling their own expressions. And now we can say, you know, this is, you know, regardless of whether this person's wearing sunglasses or not, this is the expression that they're forming. And the algorithm actually has to ignore sunglasses. The algorithm is specifically trained to ignore these other confines, perceptual confines. Wow. Now we have this more powerful way of measuring not just facial expression, but expression in the voice. We've moved on to many other modalities. That's another key distinction. And so how they fit together, when somebody's talking, speech policy, language, vocal bursts, like sighs and laughs, and so forth, facial expression, how they all fit together. And now we have more powerful algorithms. So we decided that we should have ethical guidelines for how they should be used. And so I think we're the only company, maybe the only AI company that has that kind of commitment where we're like,
There's an independent non-profit with independent people who vote on these guidelines, and we say we're legally going to commit to the way he uses these tools to adhere to the ethics guidelines. And they're transparent. So it's not like a lot of companies might have their own internal guidelines, but they're not public. So if you're a user, an end-user, you can't actually see those, you don't really know how these things are being worked out. With us, you can look at the humeinitiative.org and actually view the guidelines yourself and hold us accountable and hold other people accountable for using our solutions in compliance with those guidelines. Okay. Let me see if I could sum it up. Let me see if I got this. So, there's two major pillars I picked up here. One is, and this is really going to summarize all of your, let's hope I don't mess this up, but I think I got it. I think I did. Number one is that your data is, well, we're going to say better, but it's better because it's more accurate and the ways in which you've gathered it are unique. And it's not just one way. There's many different ways in which you've come about the data that you have. And so your data is incredibly powerful and valuable because you've amassed it in such a thorough and unique and special way. That's number one. So your data is more accurate because you're not just looking at one thing, you're looking at all the things and you've even identified things that other people didn't think to look at. Is that number one? Am I close? Yeah. I think adding that together with experimental control is really critical because we can actually use experimental control to train a model that's not biased by the kind of compounds that people are choosing. Okay. So then two and a half pillars. That plus the experimental control. And then the other one is, and you know, universe call my bluff here, but I don't know, I haven't encountered anyone else as actively, openly, and voluntarily saying to the world, Hey, let's make sure we're doing this the right way. We even have an independent body helping us stay on track. And that to me seems very unique and special as well as the depths and the lengths to which you've gone to ensure the ethical-ness of all of this. That was the other pillar. That was pillar two for me that I pulled out of that. And I think that's been excellent. Yes.
Did I do all right? Yeah, totally. I'm not sure. Emotion AI is another term people use. I don't like the term emotion AI because we're not building AI with emotions. We're not building the first AI to recognize emotions. We're building the first AI where humans come in and say, this is how it responds to emotional behaviors. But other companies, other emotion AI companies, might have great intent. They might, in practice, follow the same guidelines. In which case, no, why not just sign up? It doesn't cost you anything. You can actually say you're following these guidelines. People can hold you accountable. But I think it's really meaningful to have the guidelines out there and show people that this is what we're going to do, what we're not going to do with this. I think that's a really good model. Well, you also future-proof yourself. You can't end up like Facebook in 15 years and have some major leak because you guys are transparent and you're putting it all out there. There's no dirty laundry to air out. It's all right here. This is what we're doing. Keep us honest. This is how it needs to be done. I think more people are going to respond to that. That's the way it should be. Kudos to you guys. I also love that I sat on your show and told you, the founder-CEO, how your company works. Who the hell am I? Thank you to all of our listeners and fans that wrote in questions. There were so many, and we picked just a couple. I had a lot of fun. Alan, I think you had fun. This was fun, right? Great time, yeah. I'm going to suggest something bold, okay, and perhaps we should do this. And you be honest. You let me know how you feel. I think we should do it maybe once a month. I think we got enough of these coming in, and I'd love to do this again. What are your thoughts? Do you think we should do this more often? I think so. Yeah, definitely. Maybe if we do it more often, we'll get even more questions. I think so. Okay. We're going to wrap things up. We're in the homestretch here. We spent a bulk of today answering some of the best questions. I thought it'd be fun to just kind of rapid-fire through some of the worst ones. As you may recall, I say quite frequently, ask us anything or just write in and say hello. And, well, as to be expected, some of you took that quite literally. Here we go. West Coast Jim literally just wrote, hello. Hi, Jim. Liv wrote in and asked, where are my keys? I'm sorry, Liv. I don't have them.
Do not know. Alan, have you seen Liv's keys? I have them. You have them? Yeah. I stole them. We're talking about ethical issues. All right. Liv, I will FedEx you your keys. I am terribly sorry. I don't know what to do with Alan. Dorothy wrote in. She wrote, no question, just letting you know the weather like you've asked, 71 and sunny here in Hawthorne. That's really nice. Thank you. Appreciate that, Dorothy. Nick writes, this is great. Considerate. Three words. Are you okay? Yeah, buddy. I'm doing fine. Most of the time. There we go. Alan, we're going to have a conversation. You're stealing keys? You're only okay most of the time? You and I are going to have an on-camera chat. 99% of the time. Very good. That's a good percentage. That's going to do it. Alan, I had a lot of fun. We've established you've had some fun, 99% fun as well. Yeah. It was 100% during the course of this conversation. 100% from Alan. That's fantastic. Perfect. Perfect timing. Wonderful. Wonderful. Send us some more questions and you'll hear them just like this approximately one month from today. That's it. Thank you to those for listening and joining us and watching. You know what we think. I want to know what you think. Keep the emails coming. We had a lot of fun going through them and I'd love to see a bunch more. Just go ahead and keep sending weird stuff to us. That's thefeelingslab at Hume.ai. Like I said, if it's a really good one, I will answer it on the air in just a little bit. If it's a really bad question or just a photo of a tiny animal eating tiny food, I'm probably going to share that as well. No rules over here. We're making it up as we go. Thank you to my co-host and friend, Dr. Alan Cowan. So much, buddy. I appreciate you being here with me and doing this. Thank you to you, our listeners and viewers and what have you out there for sticking around with us and providing all of this content for another fun episode of the show. We'll be back next week, but until then, farewell for now from all of us here at The Feelings Lab. I'm Matt Forte. Thanks again, everybody. 

