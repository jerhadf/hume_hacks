Hello, world, what is up? Welcome back to the Feelings Lab. I'm your host, Matt Forte. And on today's episode, we're talking about compassion and customer service. I think it's a pretty safe bet to say by now in modern society, we've all at one point or another found ourselves at the mercy of a customer service representative. It's a very deliberate choice of phrase I've used there, at the mercy of, because at least in my personal experience, if I take stock of all my customer service phone calls and interactions over the years, a majority of them have been relatively unpleasant. Now, that's not to say I haven't had good ones. In fact, I'll even concede it's possible I've actually had more good than bad, but there's something about a negative experience that leaves an indelible impact on your overall perception. Don't worry. I'm definitely going to ask about that in a little bit. Now, to be fair, being a customer service rep is a pretty thankless job, with automated chat services handling a majority of the easy problems. Nowadays, they're left with hours on end of cranky, upset customers with complicated issues. Second, probably only to lawyers, I challenge you, the listener, to think of a profession more universally reviled and mocked. I promise you, they make a mere fraction of a fraction of a fraction of what lawyers make. With notoriously high turnover, often minimal training, and a phenomenon known as compassion fatigue, it's really important to remember that regardless of if you're the one with the issue or the one trying to solve it, whoever is on the other side of that call is just another human being. Human beings are, quite notoriously, a hot mess. Our conversations, every interaction, in fact, is this intricate dance with ebb and flow, countless social cues and signals to process, with some more easily perceived than others. It's a really challenging thing to navigate. What do we do? How do we fix this? Come on, people. It's 2022. Have you seen the James Webb Telescope? Clearly, we're better than this. Surely, as I sit here and complain, contributing nothing, someone far smarter than I is out there trying to make this whole process a bit more...
Today's guest is one such individual, their company, Cogito, has an ingenious solution that has been proven to be super effective, pretty high tech, and relatively straightforward. They're already making waves right now in the fields of customer service and in some places sales with implications that stretch far beyond its present use cases. Thus, I'm pretty excited to chat with them today. And we're going to bring them on in just a second. But first, speaking of individuals far smarter than I, with me as always, my co-host and friend, Dr. Alan Cowen is here. Alan, a pleasure as always. How are you doing today, bud? Doing great. How are you, Matt? I'm all right. Real quick. What about you? Customer service calls as a whole, what's your split bad versus good? 70-30? 60-40? What do you think? The good ones go by fast. And then you don't really remember them. They're like five minutes long. The bad ones extend for hours. They kind of ruin your day. Ruin your week? They can ruin a lot. I think it's easy to go back and be like, okay, if you count up all the minutes I spent on customer service, most of them were horrible. But that's because the bad calls take so long. I think that's probably why. Very good. All right. We'll dig into that in a little bit. Let's get to that guest. CEO and co-founder of Cogito, he is a serial entrepreneur and thought leader with a passion for creating innovative technology that helps people live more productive lives. He has more than a decade of experience as a senior executive and is regularly quoted in Forbes, Fortune and the Wall Street Journal. Holds an MBA from the MIT Sloan School of Management, where he was the Platinum Triangle Fulbright Scholar in Entrepreneurship and a Bachelor of Technology from Massey University in New Zealand. Please welcome to the show, the great Josh Feast is here. Josh, it's so good to have you. I can't thank you enough for doing this and being here with us. How are you, sir? I'm great. It's great to be here. It's a wonderful introduction. Oh, well, thank you very much. I try. I try. You guys, I know Cogito is Boston based. You're from New Zealand. But judging by the normal time that we're getting together to do this, I assume you're somewhere in the US. Are you in Boston right now? Yeah, I'm just living on the outskirts of Boston. Very cool. Well, super nice to have you here. Before we go too deep into the weeds, I want to turn the hands of time back a second, go back to the beginning a little bit. Cogito has been around for a minute now, and the earliest implementations of technology date back, from what I could tell, to about 2012-ish. You have your App Companion, which, for those who are unfamiliar, is this phenomenal app that nurses use.
Psychology and social workers would use to analyze patient audio diaries and detect early signs of PTSD, things like that. A couple of practitioners even say in the app helped avert suicide. So like absolutely amazing, right? Here's the thing people, in business, in order to keep going, you got to make money. And no fault of your own, inexplicably, there isn't a ton of money to be made and making people feel more well, right? That's a discussion for a whole other podcast. The point is, you guys had to find other areas that the tech could be leveraged, which leads me to my first question. What was the lightbulb aha moment that pointed you towards customer service as an area that you guys could have an impact? A good question. Yeah. So the history of the company goes back a little bit. So we originally were 10 years of basic science at MIT, looking at how you can reach human behavior in a psychological state. And then we developed both real-time speech guidance, as well as voice diary based and other types of behavioral signal analysis tools through sponsorship with DARPA. So our original work was focused on how do you help veterans with psychological distress, particularly PTSD, but also depression. And so the very first place we went that was commercial was actually nurses talking to patients in chronic disease contact centers. So the first thing we tried to do was help nurses identify the presence or the comorbidity of depression in patients with chronic disease. And the logic was, if you have depression as well as a chronic disease like diabetes, you're less able to look after yourself. And therefore, you can walk into the healthcare systems. There's an economic rationale for providing you with additional care. That was the place we started. And then when we got there, we discovered that that was an interesting problem to solve. It was more interesting and had much broader applicability to help nurses be more empathic in their conversations with patients. And so it was those deployments helping nurses interact successfully with patients, your phone bedside manner, that then led us to the broader customer service market after that. Wow. So amazing how those seeds sort of plant themselves and grow over time. And here we are. Let's get into
Let's get into a little bit of the complexities of customer service in general for a bit. I want to start with kind of the difference between a good and a bad experience. We started to tap into that in the intro with Alan talking about how some last longer than others. The obvious answer I would assume for a lot of people is, oh, if the customer gets what they want, they win. They're happy. Right. But I can honestly say I've had decent experiences where I wasn't offered what I expected going in. So that's not exclusively the case. There's other ways to have a good experience. You know, you can still provide a positive chat without giving away the farm, as it were. So so what what do you think makes a good or a bad experience for somebody? What's what's the what are the bones behind a good or a bad experience? Yes, I mean, we the way we think about it is that a lot of people's. What people take away from the conversation is how they've been interacted with. So it's sort of it's sort of how you how you feel when you exert is what sort of defines whether it stays in as a positive or negative memory. And it's whether that person fundamentally solved your problem on that interaction or not is important, but not definitely not the whole picture. Interesting. Interesting. Alan, we joked in the beginning that the bad ones tend to last longer. Have you had a longer conversation, but they treated you with respect? So maybe you didn't hate it as much. You know, that's true. I think that if they're hearing you, you see two sides of it. They're like really hearing your problems, your frustrations. They jump on them quickly. They're like, well, this is what you're frustrated about. Let me help you. Maybe they give you someone else. But if the right person, maybe they bring up the right information. I don't know. Somehow they pick up on it. And you also detect that this is a person who's hearing my frustrations. And that also, I think, plays a part. So I think they're correlated. Like if somebody really is being polite, being responsive, they're probably also addressing your issues more quickly. Yeah, that's a fair assumption. I don't want to go too far down this rabbit hole, but I do want I am curious because this might take us a little off the reservation. Why? What do we know about why the bad ones stick around longer? Right. Why is it that the negative experiences travel far, that you tell more people about a bad experience than you did about a good one? At least that's what I've heard. What's the science behind that? What's the thought process behind that? Why are we jerks?
I think you were, you know, we're fundamentally relationship oriented and social interaction oriented and whether social interactions going good or bad, I think I think Josh is probably 100% on point like if you if somebody is being polite to you, you would assume they have good intent, but they're at least trying to figure out your problems, right? Right. You know, even if they're not addressing them that quickly, I think they correlate, maybe they are. But if they're not, then you still have the assumption that they are doing a good job. If somebody is treating you with disrespect, you assume they're not doing a good job. And even if they're getting to it fast, maybe you assume they could have done it faster. And so we're very oriented to these cues as humans, like we're just listening to signs of empathy all the time. And I think that's really the discriminator there. Yeah. Oh, were you about to say something, Josh? I'm sorry, did I cut you off? I was just going to add to it. One of the things that we found, which I think is increasingly understood is also, I think, fascinating, which is we make that decision about whether we're well treated by the way we're interacted with, not by what people say. So a customer service agent can follow exactly the same script, exactly the same interaction, but milliseconds between how fast they respond to a query of yours will make you decide whether you've been heard or whether that they're listening to you or not. And then you'll make a judgment that will then possibly stick with you for a long time afterwards. Yeah. What I'm hearing is this comes up on every, we're a podcast about emotion that comes up on every episode. Empathy. Empathy is super important, right? That's the whole point. And that's a big part, if not the part of what you're trying to do and what you are doing over at Cogito. You have these tools that help strengthen people's empathic ability and strengthen those skills. Does Cogito have a scientific philosophy behind how to do that? In other words, if someone is feeling bored or frustrated, what do you then coach the agent to say in response kind of a thing? Yeah, I guess we do have some theories. I kind of think of them as guardrails that make us be confident that what we're doing is making a difference. So one of the things that we look to do is we only want to deal with people who are feeling bored.
We only want to deal with concrete behaviors, and we only want to deal with concrete behaviors that are human-hearable. So, our basic concept, which is not a crazy concept in terms of the science, is that we evolve social signals as a communication mechanism for the purpose of coordinating in groups. So, therefore, anything that we're trying to do that affects social signals should be something that humans can hear by definition. So, if we're trying to find something hidden, then maybe that's possible. I'm not saying there aren't hidden things, but that's kind of getting out of our bubble, our safety bubble. So, that's the first thing we do. So, we're looking for concrete things. The second thing we're trying to do is if you're going to guide somebody in the moment, particularly in the moment where there's kind of a high cognitive load, it has to be useful. And it has to be something that you can make actionable and useful in that moment. And so, what we try and do from that, even if we're kind of doing complicated measurements to tell us how engaged two parties are in a conversation, when we actually give somebody a cue in the middle of a conversation, it's very discreet and very, very simple. So, it might just be continuous speaking. You're going on too much, right? Yeah. But it's actually complicated to figure out if somebody's going on too much. That's actually a complicated thing to figure out. The nudge you give up the agent in the moment has to be really concrete and really simple. Describing it as a nudge is such a great way to describe it. Because as we're getting deeper into this, I'm becoming more aware of the fact that I didn't, for as wonderful as you said the intro was, I didn't set up necessarily exactly how Cogito does the cool things that it does. And that describes it perfectly where two individuals are on a call. There's the support agent and the person calling in. And there's some kind of screen agent they have availability to. And as Cogito's system is analyzing all the things happening in real time, just like you said, if you're going on too long, a little prompt will come in and say, hey, let them talk a little bit. Maybe that'll be better. And so, I just wanted to reiterate that and get that baseline so that those listening who don't exactly... That's kind of how it works, right? And there was this great analogy that I came upon.
I was on an article on inc.com, inc.com, a couple of years ago, but it was likening the service to when you drive a newer car with lane assist and blind spot monitoring and all these different things. They aren't driving the car for you, but enhancing the awareness. And so the question I got from out of that, was it challenging to find that balance, to figure out what constitutes a nudge and ensuring that you weren't overly notifying or overwhelming the agent? How did that take time to figure out? I'm curious as to how you arrived there and arrived at, this is the exact amount that we need to guide them in the right path. Excellent question. And thanks for the research on what we do. I love the lane assist, collision avoidance metaphor for what we do, because it's very similar. If you're driving a car, you had your coffee, you're feeling good, you're well-trained and you're not going to get any beats and nudges and flashing lights. You're going to just stay in your lane, you're going to drive really well. And that's how it should be. But if you are tired, the kids are screaming in the back and trying to drift off the lane, that's when it's really helpful and this stuff can save your life in the car analogy. It will save you from creating a very frustrated customer in the customer service analogy. And so that's how we think about it. So there can be a whole bunch of calls where you're getting no nudges from Cogito at all when you're in a conversation. However, when you mentioned the compassion fatigue point earlier in the session, people consume resources when they interact with each other. And so the agents get tired, especially if you had something that could be 20 or 30 very similar calls in a row and not every customer has been nice to you, you're going to get tired. And then what happens is you're then going to not be able to read social signals anymore because it requires effort to read social signals. And that's when the cues kick in and they help you essentially avoid this frustrated customer because you're getting this guidance in the moment. And so to kind of bring this round to the point you made, we carefully monitor the sort of the frequency of interactions or basically nudges that somebody is going to get in the course of a conversation, both in aggregate and then over the course of the day. And a lot of this becomes experiential.
One of the advantages we've had is we've been doing this for a while, we've seen a million calls a day, right? And so over time, we sort of learn the rules of thumb that in general, it's going to make sure that there's a good experience and somebody's not going to all of a sudden get flooded with a bunch of nudges that they can't do anything about. Have you, and this might've been what you were just saying, and I apologize if I didn't catch it, but have you noticed in clients that use the service for a long period of time require less and less nudges? Like that's the idea outcome, right? Like you want to train them, not just, you don't want them to have the training wheels on forever. You want to be able to take them off at some point. Yes and no. Ah, interesting. Yes and no. Yes and no. No, no. Yes and no. Because the same with you, to come back to the car driving analogy, right? Like I've been driving for 20 years. I might think I'm a fantastic driver, right? Yeah. But I can still get tired. And I still, and I still say, so we find that experienced agents still need this application and, but not on every call, right? So what do you see as you need, as you're officially getting phone ready, so, you know, with all the attrition and churn that's going on in the industry right now, you know, people have to get phone ready, they have to onboard. So there's going to be kind of more coaching as somebody gets used to interacting with customers. But even for a really good agent, they're still going to get nudges. In fact, one of the things we find is if we deploy to an initial population of agents, often the really good agents are the ones that get the most instant improvement as well. Because even though they're good, they already have mastery of the script. And what they're missing is the consistency in behavior. Is that a, is that a really great way of figuring out who the good ones even are? Because one of my questions was, is what makes a great representative, right? The idea is the system can help coach anybody, but in every, in any line of work, there's going to be people that are, you know, innately, like they have the skillset already. And has this not just in changing those interactions, has it been a way of helping to identify people that are really strong at this actually? Well, we would like to think so, yes. And so there's a bunch of traditional metrics in this particular job, you know, how effective you are, like what the sort of your post-school survey results are, how efficient you are at getting for an interaction. They're the kind of traditional metrics that are used across the industry. And, you know, I think...
Anybody in the industry would say they're somewhat of a blunt instrument for figuring things out because every conversation is nuanced. One of the things that we're very, very proud of is we've been able to build a very sophisticated model that measures, we call it customer experience on every interaction, and it measures it continuously across every single interaction. So all of a sudden, you do have a measure, and this is basically, again, a social signals measure. It's based on the rhythm of the conversation between the different parties and what the two parties are signaling to each other by the way they're interacting as to whether it's a good conversation. It's a biological, in some ways, biological signaling-based measure, and it's very, very powerful. It correlates and predicts all sorts of outcomes. So in time, we would love something like that to be the measure of whether you're really doing well. Go on, Alan. Yeah, go for it. That's fascinating. I just would love to hear more about what are the most important signals that you see that algorithm picking up on. That's what I wanted to know, too, because as I'm listening to that, I'm like, are you parsing the full spectrum of human emotion, or have you whittled it down for efficiency sake, like the most common, most important ones that you're picking up, like the call center vibes to look out for kind of thing? Yeah. I'm pleased to share on that one. So one of the things that for a measure like ours to be practical, it has to be something that's almost universal within the context of these types of calls. What that means is that we actually don't want to look at everything you can imagine. For example, to do our CX score, we ignore words completely because the words are going to be different according to every single type of phone call. They're always going to be different, right? So you need to have a measurement factor that basically goes underneath the word so that you're getting it at a more universal signal that's more generalizable, more easily generalizable. Now within that, what you're looking for are things that are human hearable. Then the things that really matter that we've found, a lot of it is about the exchange in the rhythm of back and forth. So it's very much a conversation as a dance, and these two partners dancing together in sync. That's the biggest part of it.
One of the simplest measures, for example, is how balance somebody is. How balance that interaction in the course, in the course of an interaction will be a great example of good rhythm or good interaction. Wow. That's all known for rules. Yeah. The generalizability and predictive power. The thing that's amazing is how well it predicts. We have customers, we have a customer that deploys us on 30,000 course interagents, they think, so they've told us that it predicts their customer service CSAT scores at over 90%. Wow. Which is amazing. Just looking at what, just looking at social signals. I have a million questions, but I don't want to cut on balance, because usually his are way more. I have a million questions. Yeah, I'm curious if that signal is preserved across cultures, because when you go to a country like Japan, I remember being there and there was a big pause between talking and people really were more into a turn-taking conversation, not as much interruption. So I wonder if that's something you need to incorporate. Of course, yeah. And so that was an important thing, which is a detail I didn't completely get into when I said that, which is we take our model, but we will tune our model for general call types and general kind of what I think of as really social roles. The big factors we see are social roles, some culture, and then also male-female as well. Of course, it makes a big difference because again, it's a bit of a biological thing. So those are the big input factors that we use. But then within that, there's really a tuning of a model rather than sort of a wholesale recreation of a whole new model. I think I might have been thinking of it the wrong way. One of the things is that same article with the car analogy that I was reading, in telling the history, it talks about the health insurer Humana and the results in the custom pilot was so encouraging, they rolled it out to thousands, right? And then it says that they are even piloting.
And we're going to talk a little bit about that in a moment, but first, let's take a look at a couple of songs, let's say what we'll see. So, yes, relative to the measurement, there's no question. And so that really comes down to social roles. And there's definitely a big difference between calling in to somebody for the service request and somebody calling you to sell you the third or the other thing. They're definitely very different social roles. And if you sit back and think about how those conversations are, of course, they're going to be very different. And who's going to have the most energy? And so there's no doubt that those are different. Now, one of the things that we do find that is, I think, really interesting, as well as a lot of our customers are very interested in what's called cross-sell upset. So if you call into a customer service line, they're going to want to give you a really good service experience and then offer you something else that might solve a problem that you have. Oh, I'm familiar with that. Yeah, it's a very big deal. And we do a lot of support there. And the way we support is not very complicated. We just help make sure the outside service experience is great. And if people are happy with that, then they're going to be more receptive. And so that's a case where you have that sales component, but it's within an existing social role or a service social role. But an outbound selling tele-sales, for example, is definitely a very different type of interaction. That's a really good point, though. There's something you just said in there of like if we just make sure the interaction is great, because if you're having a great interaction, you're more likely to go for the sale and they'll get you on the hook. And it makes a lot of sense. It reminds me years ago when I worked for Apple and at the stores, it was like, look, we just want to make everything around the shopping experience amazing. Make the service amazing.
Let's have amazing experiences. Don't even talk about the product. Just get them in to have a good time. Make them feel like they're at home and the sales will come. They'll buy the stuff because they'll be comfortable and they'll just go for it and they'll be more inclined to do it. And it's just interesting to hear that applied in this context. Very cool. Alan, I'll step back for one of your million questions. What do you got? I like that we're taking a step out of sales or customer service to sales in the broader world. We started with nurses and triaging conversations. It makes me wonder, what does the psychology say about what are the signals and indicators? I'm curious how it compares in these different domains where the psychology doesn't usually study customer service calls, doesn't usually study sales calls, but in general interactions, what are the big things? Antiphonal laughter, let's say. People laughing together. Huge sign of whether they could be friends. Relationships, do you see that in customer service and sales as well? No doubt. And sort of joint laughter. So we even have a nudge because part of what we do is we're trying to not just change customer service representatives' behavior. We're also trying to encourage them and make their lives better, make their jobs better and more fun. It's not easy as I think you guys said at the start. It's not the world's easiest job. So when we see really positive moments in an interaction, we'll give somebody a nudge, which is a visual equivalent of a high five. Well done, right? Yeah. And we absolutely look at those moments of joint activity and joint laughter. Totally. And then you see people... Well, frustration and all the speech positive stuff I think is totally understudied in psychology. But looking at the literature, you would see little digs or people not really reacting to each other's critiques in the right way. And so the way that critiques are often delivered is like, to be polite, you're kind of teasing. It's kind of humorous when you want to deliver negative information in a way that's polite. But a really big sign of whether a relationship is going to fall apart, and I don't know if this is true for customer service as well, is...
I'm curious if you see that as well. It feels like a very personal example you gave there, Alan. Are you okay? Are you good? Yeah, I know. People tease me all the time, and I view that as a good thing. That's the key thing. Very good. I didn't mean to interrupt your actual intelligent question. I just had to make fun of you a little bit. Well, it is a good question. I think this probably speaks to I think, almost like the gap between what's possible commercially with technology and what we aspire to get to. Because some of these are subtleties that I think probably still a way away for a company like you. And this is all we do. We just do this. This is like our whole world. I've got to come back to my boundaries I've created for myself. I have to be able to hear it. I have to be able to get a whole bunch of smart people to agree that they can hear it for me to trust that it exists. It has to be repeatable. It has to be something that I can take across millions of interactions and work. And then I have to be able to resolve it into not just being aware of what's going on, but also an action that I can specifically think of that the agent can take to make a change. So I'm agreeing with you and also saying in some sense, it's like where we would like to get to, but we haven't even had to go to that level of sophistication necessarily to improve conversation so far. Interesting. Just to go back for a second to that car analogy, the thing I love about it so much is it also helps assuage some concerns because you know people hear AI-driven tools and they immediately assume that's it. We're all doomed. Skynet is here. They're taking our jobs, right? And it's like, this is very clearly not a replacement. It's an enhancement. It's an augmentation. But just hearing you talk in that last bit, what is it besides the ethics and our desire to continue to exist as a species, but what is it that stops this from one day reaching a point where it no longer needs to coach humans because it can do the job?
Is that an inevitable thing? Or is that just the realm of science fiction? What do you guys think? I mean, we're getting customer service automation every day, right? More and more. I don't know the statistics. I assume more people need customer service over time. And so there's more roles for actual humans too. But I also feel like a bigger proportion over time is probably automation. And I'm not the expert on that. I would give that to Josh, but I assume that's going to increase over time. Yeah. What do you think, Josh? It's a very important question. I can tell you the data so far. So the data so far says that the number of call center agents that you need in the society goes up with GDP. And it doesn't ever seem to stop no matter how much you invest in self-service. Whatever self-service technology you're using, be it mail order catalogs, chatbots, IVR systems. And one of the reasons, this is my own personal opinion about this now, is that people always want service from other humans. Because societies also get richer. And as they get richer, they also want more service. I want somebody to solve my problem for me. I don't want you to give me a tool, so I solve my problem with your tool. And so it's just sort of like, I think, and that's kind of my opinion. So that's sort of based, it's more like a look back to what I'm giving rather than a look forward in terms of where technology can go. What I will say is that a company like Cogito is primarily oriented around trying to augment the human condition. It's just kind of our whole thing rather than really, we're not the company that's trying to replicate the human. That's just not what we are trying to do as a company. And so really, I think that one of the challenges in terms of replacing human-based context in a reps is one of the points you opened with, which is these conversations are getting much more complicated, much more emotional than they ever were before. That's the problem is how difficult the conversations are not. Because the easy ones are absolutely getting picked off by websites or chatbots, etc, etc, etc. And so what that means is that for me, at least, to get to these really complicated conversations,
I think this would be good just to look at, sort of, you mentioned frustration, I imagine people's frustration when they're talking to an automated agent must be so much higher than humans, just on average, like that must be a huge statistic if you want to. And then obviously, if you've had a poor interaction, you're going to come to the poor human customer service agent even more ticked off, which doesn't make it any easier. Just talking about the difference between a human interaction and interacting with an AI system for the simple ones and whatnot. What happens? Do you ever encounter someone that you're trying to coach or nudge? And I know you're not personally out there coaching them one on one, just for the record. But I'm saying in this whole process, have you ever encountered an individual where you guys, the system's doing what it's meant to do, it's detecting these things, it's giving them the cues, but that person isn't convincingly responding to the cues? It goes, hey, be more empathetic. And they're like, yeah, whatever. They don't know how to do it. Do you ever run into that wall? Is that something you've seen where it's like, you're telling people to try to understand how it feels, but they aren't convincingly doing it, or they're doing it in a way that actually upsets the customer because it sounds like it's not a genuine concern? Is that something you've had to solve for or encountered at all? Yeah, it's a very perceptive question. Yeah. So, the way we think we do this is so we will, basically, we'll put it, we'll detect a need to change a behavior or the equivalent of you're going out of your lane, right? Or you're too close to the car in front of you, right? So, you're getting this nudge that's appearing. And then just like in that car, that's going to stay there until you come back into your lane or you leave sufficient distance from the car in front. So, what that means is that we know to what extent you're taking advantage of that nudge. So, the point is, we can tell. We can tell that some people... We have very good visibility as to essentially to what extent any given agent is taking advantage of the nudges provided to them. And then we can also...
They map that to both outcomes for the call, but also our continuous measure of customer experience. And absolutely, you're right. I mean, we work in very diverse populations of people with all, you know, some people are not built to be customer service reps, but they nevertheless have that job and that will, you know, and we will see that in the data. It speaks to, I mean, some people might not be good customer service agents now, but with the right training, they could become ones. So I was, you know, you talked a lot about sort of real time feedback. I'm wondering how much you also do that's retrospective after the call, you pick up a moment when something went wrong and you show them and you're like, this is what you could have done better. That's right. Yeah, very good point. Well, first thing, and this might be, you know, possibly more of a question for you, Alan, but like, I think we have the understanding that even though that people ability to detect social signals does vary from human to human, and certainly we know it varies within a human according to fatigue levels. There are possibly some people that just don't read social signals very well at all. So that might be the example of not everybody is fully made for that type of role. In terms of post-fact, yes, so absolutely. The thing that's sort of most that people think of first when they think of Kajita, if they know us, is this real time and call guidance, because that's one of the things that we sort of popularized within our little sphere of influence. But the system does a lot more than that. And so it provides visibility for supervisors. It also provides automatic coaching plans as well. So if you're an agent, you can automatically sort of help you identify where you need to improve. It'll then tell you how much you've improved. And it will also align the measures that you get to help you improve across the areas of weakness. So there's like a whole kind of coaching system that comes with the real time and call magic. That's really cool. In terms of improvement, I mean, there aren't that many psychology interventions, honestly, that have been proven to improve empathy. But here's the promising thing is that.
People reliably do get more empathic over time as they age, so we're obviously learning, right? And so, you know, I think we're close to a point where we can start to figure out what is it that people are learning from and then show them more of those examples. And I think that that's going to be a really promising approach. Yeah. Certainly anecdotally, some of the agents have said that they do better with their conversations with their partners and spouses after they use our system. They just get anecdotally. Yeah. Yeah. I was going to say, that's got to be a nice feather in the cap. You got to enjoy that for sure. All right. Well, you know, Josh, keep me honest here. I assume that in order to train your software and enable your coaches to coach, one must first learn, you know, the effective ways and how to provide that support. Did that process yield any major revelations like, you know, what do people tend to care most about or just in general, were there unexpected learnings in this journey of bringing this all and making it as great as it's become? I think it's sort of funny because, you know, I think the path of the company has been a long path. So like the original basic science behind the company, which was created by my co-founder, Professor Sandy Pentland, he did that over 10 years, which culminated in the end of his research period, which was 2007. And that's when I picked it up. And with Sandy and my other co-founder, Ali, through DARPA, to turn it into a technology and then since we've proven it now commercially. So I think the thing that's always been a surprise is how well it works. Yeah, because we never knew, like we never knew when we started, right, there's experimental results on MIT students and others, but, you know, like that's university studies. And then, you know, then we find out that, you know, we can do it on a specialized population and now we run on, like I said, more than a million calls a day, right? So I think that's always been the biggest aha is the power of social signals and how much they influence us and how little we realize it. And also how little, like how surprised people are still are when we talk about this, right? Really? I have another communication channel and it's incredibly influential in terms of my attitude to what just happened to an interaction I just had, it's just still a...
It's not a well-understood thing, I think, but now it's proven at a really large scale that it's the case. That's amazing. This is flying by, by the way. Believe it or not, we're almost done. I'm blown away by how quickly this went. This has been so much fun. We're coming in the home stretch. Alan, you and I just went off on a tangent an episode or two ago about how important the multiple points of data have been and how you've been able to leverage all these different things to the ticks and visual cues in association with the sounds of our voice and vocal bursts. I don't know how we talked about it. I tried to formulate an intelligent question about how he's managed to pull all of this from just the audio. I wonder if you have a better way of phrasing that or proposing that, or if that alone is a great question. Josh, you've done a great job of telling us about how we had to find out that we could hear it and then prove that other people could hear it and that it worked. That part still blows my mind, especially coming out of a conversation about what we can do with so many data points. It's like, look what he's doing with one, with just the voice. Just the signal. Not even just the voice, but just the nonverbal parts seem to be really interesting. Really powerful. Really powerful. It's fascinating. I want to be clear, apart from the LCX score, we do look at both content and lexical and nonlexical signals. But it is incredible how much the nonverbal ones are powerful. I'll answer the question about, I guess, multiple signals. One of our original studies we did when we were doing the data phase, the applied technology development phase, we did a study and we looked at what would happen if we took a whole bunch of other signals and we put it together. What we found, this is our own study, so maybe others subsequent to this have had different results, but ours was that it's definitely helpful to have, for example, visual and audio together. That's a good thing, right? But if you have audio, it doesn't add that much. That's just what we found. We found that we were pretty good with just audio. And then one of the things that, of course, is interesting is that we do a lot of stuff on phone calls. So on phone calls, we have all learned.
It's a great way to send out social signals through the phone, right? So it is there, right? So, you know, to the extent possible. So that's what we found. And that's in terms of characterizing or measuring how well a conversation is going. And my own opinion on this, again, is, you know, in the world of Josh's opinion, is that one of the great things about voice is that it is a communication that we're using, right? Like, you know, I mean, yes, it is also a communication mechanism, but like, we really, this is like a really sophisticated one that we've evolved over a really long time. So it makes sense that it's rich and that there's a lot of signal in it. In terms of, you know, context, it really matters. Like if people are reacting to videos, typically they're going to show most of their reaction in their face and not too much in their voice. So that sometimes people laugh out loud and so forth. And then if there's, you know, people are listening to a presentation, then they don't really have the opportunity to use their voice as much. So it really does depend on context. But while people are talking, there is so much information in their voice. Of course, you might want to know whether there's contrasts between what their voice is doing and what their face is doing. For example, when people are sarcastic, then there's contrasts. And that's not just between the voice and the face or their speech prosody and the face, but between speech, like the tone of what they're saying, and also what they're actually saying, like the semantics. If you get a contrast between the semantics and the tone, there's probably sarcasm. That's, you know, all of these things are really nuanced and difficult to pick up on. And I don't think people have good embeddings of the individual signals that are good enough to really make these higher level inferences until recently or mix them together appropriately until recently. I think for facial expression, people have focused on really out, like really strong, simplistic categories of expression, like anger, the six basics, anger, sadness, happiness, surprise, disgust, and fear. And those expressions are not ones you see very much in conversation, except for maybe happy, right? But, you know, they don't, people look at now confusion, boredom, and we know that these are different expressions that don't look like.
and empathy, and compassion into ubiquitous artificial intelligence systems. and empathy, and compassion into ubiquitous artificial intelligence systems. and empathy, and compassion into ubiquitous artificial intelligence systems. Once you get into the granularity of it it actually becomes more interesting to look at the face and it becomes more informative to mix different modalities is what we find. That makes total sense. I believe that. Yeah, I mean, when we were doing, you know, back in my data days a little while back, again, some of the face recognition stuff wasn't just wasn't sophisticated. So we were, you know, very, what we were looking at well was just trying to figure out agitation and, you know, overall excitement. So we're really looking at gross movement as something that, you know, it definitely added by the way, like just doing that was good. Yeah. I just, you just didn't need to, you didn't have to have it. Let me ask you this as we're coming into the home stretch. One of the things I love to do towards the end of the episode is, is kind of look a little further down the road, blue sky, imagine, you know, the brightest of bright futures. And as we're talking about these different points of data that we can pull from, you know, Josh, you, you, you mentioned, I forget if it was that one article, I read a bunch of articles. I can't remember which one I saw on him, but the dream being to take advantage of this for all kinds of conversations, negotiations, meetings, dating experiences, things like that. And in general we've all transitioned to a more remote world with a lot of people finding themselves, not just on phone calls, but spending a majority of their day in video conferences where now more so than ever before, there is a way to sort of pull this data and see it. And I'm curious you know, has that led to conversations at Cogito? I know you've said, you know, this is what we're doing right now, but have you guys sat around and thought like, hmm, well, how could we push this out even further? You know, and again, I'm, I'm, I'm basically asking you to tell us your secret roadmap, but I mean, what can you, what can you say, or what can you just, as Josh, just talk about you'd like to see and like new potential use cases and things you'd want to explore to help make that dream real? Oh yeah. Another great question. So I'll tell you about our near-term, like a near-term big dream, and then maybe I'll clear the big dream. So our near-term...
Big Dream, I sort of think of it as the emotionally intelligent organization or the empathic organization. And so that's really the idea that it's actually using this type of data to improve the practice of management because what I see is that you have – this is actually why I founded the company in the first place. You have these huge organizations that have the best of intentions, right? The CEOs of those organizations, they want the best for the people. They want the best for their customers. They want the best for their shareholders as well. They're very genuine, right? There's not the capability to bring the human factor into a large organization. And so my first big focus is how can you – if you can bring what I've referred to as human data, which is basically information about psychological state, and inject it in, then you can manage people much better. And that comes to the very simple ideas of if somebody's tired and they've had 5 calls with a frustrated customer, give them a rest. It's not that complicated, right? Right. And then what we discovered is that you can deliver that data. One of the great ways to deliver that data, which saves you the whole management overhead of having to coach somebody by sitting down beside them 2 or 3 hours a week to have the AI do it for you. So for me, that's the first thing. And I don't want to – I believe the impact of doing that will be absolutely profound because we spend a lot of our time working. And organizations, big organizations are only getting bigger from what I can see, right? They're only getting bigger. So if these organizations that are really important in society are better at managing their own people because they have access to human data, and they're more pleasurable and positive to interact with, as a customer of those organizations, then the overall happiness must increase. So for me, that's the big immediate focus. And that's what I wake up in the morning and think about. How do we get from here to that ultimate, nice, near-term goal? Beyond that, so now outside the world of work, I let myself be a bit guided by what I think is appropriate in terms of what society is ready for. So I'll give you a classic example, right? And we – one of the – the very first thing we did at this company was we tried to detect depression from the
Actually, we didn't do the hardest thing, but we did the easiest thing, which is really dumb, but that's what we did. And we did that. And by the way, we were really successful, right? It really, really works, right? And not in every case, because everything's not always expressed in the voice, but where those symptoms are expressed in the voice, we can detect them very effectively. But it turns out that deploying something like that is a minefield of what's socially acceptable, right? And I can come up with a lot of ideas. Is it a good thing to detect depression in a patient with chronic disease and then help them so they don't get really, really sick? Yes, of course it is. But how are you going to do that in a way that's socially acceptable, right? And it's not clear, right, how to do these things well, especially 10 years ago when we tried to do it, right? And so for me, a lot of the applications of what we do, all the other sort of social behavioral sort of approaches to try to understand humans is what are we ready for? Because I'm not clear. We did dating in the lab, again, 15 years ago, right? And it's really effective. You can tell if somebody's going to exchange phone numbers by the way they interact. This has been really well-showed, right? But do you want that along with you on your date? I don't know, right? And that's really, I think, what's actually coming out of it. I often refer to that as the slipperiest of slippery slopes on this show. As you were talking about, Justin, just like, okay, you can see one of your employees is tired. Give them a break. And my mind immediately extrapolates, okay, if I got a team of like 100 people and my little indicator shows me 10 of them are tired, I didn't have to walk around, observe 100 people and find the 10. My machine told me they're tired. I can signal to them to get a break. I was like, that's pretty cool. And then I kept going. And I was like, well, everyone, nobody wants to go back to the office. We're all working remotely. And all the managers are complaining that they can't manage appropriately from a distance. Like, well, now you could. But then I went, right. But then is that a surveillance state? Are they watching everything I do? Exactly right. And I was like, wow, a slippery slope is back. And so it's like a juggling act. You can. Like, I always say, like, you know, one of the things you can monitor from voice, you know, you might be able to guess that it's something like wellness, right? But you definitely don't want to monitor somebody's wellness, right? Because that's their personal private information, right? And so what really we might want to do is monitor whether they're having stressful.
It is also a platform for people to share their personal experiences externally imposed on them, and I think that might be okay. That's interesting. That might be okay. Yeah. I mean, when you're delivering feedback, and I think this is the challenge, is how do you take something like that and actually give somebody an actionable item that they can, you know, and intervene in real time? It's going to sound really creepy and invasive a lot of the time. But I also think there's like a shift in sort of history happening right now where these measures of wellness are not meant for immediate feedback as an input, but meant for as an output, right? Because we can actually optimize for abstract things with AI and with technology now, totally different world, right? Now we can do this non-invasively, and because we're not giving any feedback, nobody's going to necessarily know that, you know, that like there's something that is tracking you and it's not going to leak out. Like if you give feedback, then that destroys the privacy, right? That somebody can see that feedback. If you do it without giving feedback and you anonymize it and you aggregate it, you can now have this metric that is used as an output, as something that is totally optimizable, right? And only now, because we have AI systems that can optimize for abstract objectives like that. So I think the world is changing there, and I think that wellness is something we can really look into, and that's part of our goal. Well, absolutely, right. And I think, again, it's two things. It's like what's technically possible, and I think what's been technically possible has been way ahead of what's socially acceptable for a very long time in this particular field. And then how do you come up with like practical ways that you can benefit like society at large scale, right? Which is what you're ultimately trying to do. And so that, I mean, the perfect example, it might be completely not acceptable to measure somebody's individual wellness, but it may be totally fine to say this region of the country is really not well. I don't know who specifically it is, but like that's a problem. And so I think that that point about finding the practical, acceptable.
And the work that I've done in the last year or so is just about it. In a lot of ways, just about as hard as coming up with a model in my experience. Yeah. Wow. I don't need a whole lot of there's an entire region of the country that I have a personal opinion is not that well, but we don't have to go to different conversations. Those are my thoughts, not anybody else's. All right. I got this was the fastest 52 minutes I've ever had on the show. Josh, so much fun and such a great conversation. I can't thank you enough for making the time to hang out with us today, tonight and just being here on the show. Such a treat to have you here. Thank you. Truly appreciate it. I mean, everybody, do yourself a favor. Check out Cogito Corp dot com, C-O-G-I-T-O-C-O-R-P dot com for a bunch more information. We scratch the surface of all the really cool stuff they do over there and go take a look and be wowed just like I was. Thank you, of course, to my co-host and friend, Dr. Alan Cowen, for another great conversation. Thank you, Alan. Always a pleasure. And of course. And lastly, you know, it's coming. That's right. Get ready. Here it is. Thank you to you. World's greatest podcast listener. I appreciate you coming back for another round. I look forward to doing many more with you down the road. Always a treat with you. And hey, if I'm doing the outro, it must be time for me to tell you that we have an email address and I'd like you to send some questions. Send them all this way. Thoughts, comments, whatever it is. You can find us at the Feelings Lab at Hume.ai. That's T-H-E-F-E-E-L-I-N-G-S-L-A-B. A little at, squiggly, Hume, H-U-M-E, dot, like a period, not the word dot, and the letters A-I. Make it a great question and it just might make it into our next listener questions episode. No promises, but it's a very distinct possibility. That's going to do it. Farewell for now from all of us at the Feelings Lab. I'm Matt Forte. Thanks again, everybody. And please stay safe out there. ♪
