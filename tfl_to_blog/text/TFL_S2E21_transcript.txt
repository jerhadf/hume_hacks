Hello, world. What is up? Welcome back to the Feelings Lab. I'm your host, Matt Forte, and on today's episode, we're talking to the founder of Wisdom 2.0, Soren Korthammer. That's our first show of 2023, and there is certainly no shortage of topics for us to tackle here in the lab as we enter our third year. Go us. Dearest listener, in the few short months since we last met, a lot has gone down. Public opinion on AI has gotten complicated. New groundbreaking technologies have sprung forth. The metaverse still really isn't much of a thing yet. Twitter is also complicated. And science, here's some good news, may have finally answered one of the most important questions ever asked. Are dogs left or right-handed just like us? If I get my way, that last one's going to get a three-episode arc here on the Feelings Lab. You better believe it. Anyway, when we were fortunate enough to land today's guest, the team got together, as we like to do, to figure out an appropriate topic. Should we talk about the relationship between mindfulness and current technology? Sure. Obvious one, of course. Should we deep dive into the role AI may play in our ability to truly know oneself? Of course, let's get into that. What about taking a closer look to see if social media has actually brought us together or driven us farther apart? If there's time, great. Why not? Ultimately, we want to ask all of these questions and a bunch more. So why limit ourselves with a single topic, right? Let's go ahead and leave the door wide open. And who better to casually stroll through that door with us than today's guest? He has a wealth of experience in not just practicing mindfulness, of course, but in coaching others and helping them on their journey to find balance between their inner, outer selves and technology. He's built incredible communities from scratch, worked with individuals of all ages and economic backgrounds. In fact, his work has afforded him a front row seat to observe and discuss the things that occupy the minds of everybody from those in Juvenile Hall to some of the world's most wealthy CEOs and execs. Pretty remarkable stuff. Now, I think it's fair to say everyone out there has intrusive thoughts or trauma or fears or anxieties or something that we're working with. Our phones tend to provide one of the most effective distractions man's ever created. But though that particular experience feels universal, what about...
The actual thoughts themselves. Are we all running from the same things? Are we all running? You know, as we now feel more divided than ever, are there things we're all quietly fighting inside that we don't even realize may actually unify us all? A lot of big questions. And to be clear, our guest has never once claimed to have all the answers. In fact, I like to consider them a bit of a kindred spirit, not only in their willingness to let you know that we don't know, but also our shared enthusiasm for learning and finding things out together. Uh, that's why we're all here, not just on the show, but in general, I think that's why we're all here to learn and, and figure things out together. Uh, I'm very, apparently so wildly excited to dig into what they've picked up along their incredible journey. But first speaking of incredible journeys, my cohost and friend, Dr. Alan Cowen has traversed the choppy, unforgiving waters of the fundraising seas, and I'm happy to report that he and his fearless crew have returned victorious. Uh, typically I congratulate him for just having good hair. But today I say, well done, sir. Congrats on the Reason Series A announcement, Alan. That's huge news for Hume AI and an awfully big feather in the cap. Welcome back to the lab. How are you doing, man? I got to imagine things are pretty good over there right now. I appreciate it. Yeah, no, it's been great. We're growing. Sorin had something to do with that. Most of the investors participated. So yeah, it's been great. Oh, it's fantastic. I'm happy to hear it. All right, let's do this. Today's guest first and foremost, a full disclosure as may have been alluded to just there is an investor in Hume AI, but that's far from why we've asked them to join us here today. Uh, he's been featured in various media, including GQ magazine, newsweek.com, a former project director for Richard Gere's public charity healing that divide, uh, they've organized the healing through great difficulty conference with his holiness, the Dalai Lama. That's pretty cool. Uh, over a decade ago, he wrote a book wisdom 2.0 addressing the great challenge of our age to not only live connected to one another through technology, but to do so in ways that are beneficial to our own wellbeing. Well, that book would later evolve into a wildly successful series of conferences, meetups, and workshops, bringing the conversation to the world in an accessible, innovative, and inclusive way with their annual flagship event, drawing massive crowds. I've had thousands of guests from over 24 countries all over the world. Uh, and over the years they have done mountains of work with individuals and groups on ways to live with less stress and more effectiveness in our technology rich lives. And on a podcast about emotions and technology, man, I dare you. Go find a better guest. You won't please welcome to the show founder of wisdom 2.0. The great Soren Gordham.
I'm here with a Sorin. What a treat. Thank you so much for being here. And I do want to do as podcasts typically do at the beginning and go a little bit back in time. I've listened to a ton of the stuff that you've done out there, Sorin, so I'm a little familiar with your story and I think it's phenomenal. And if you will indulge, I just want to go back and talk a little bit about the early start of your journey. And I mean, like way back, you know, we go all the way to when you were a little kid. It starts in kind of a difficult place. You come from a big family at an early age. You guys move out to Lubbock, Texas. Your parents split and divorce. And then I've heard you say how you felt alienated at school. You swore off dating and socializing. Things got really challenging, really dark. And then your father, in an attempt to sort of provide you some tools, I suppose, one day he leaves you books. He leaves you a pile of books, Ram Dass, things of this nature by your door. And that's a real pivotal moment for you, right? Receiving that pile of literature. Yeah. Yeah. So it's funny. You know, I think the two things that were outside my door were sex anatomy books and spiritual books. I think it was the two things. It was really all you need. We were clearing all the time. That pretty much answered all my problems. He left books outside my door and hoped that I would pick some up and he wouldn't have a talk. He wouldn't have to talk to me about how sex works. Yeah. He wouldn't have to talk to me necessarily about kind of what my own pain was. And he could reach me in a more subtle way because I was very lonely and isolated. I didn't want to talk to anybody. And I felt a lot of shame at the time. Our family was one that did not go to church and just about like ninety nine percent of everybody else in Texas at the time. And that sounded like the church didn't go to church. So when the divorce happened, I felt like it was kind of a indication that somehow we were wrong. There was something was wrong with our family. And, you know, kids would tell us, oh, you're going to hell and you're not going to church. So there's a lot of confusion growing up about what in the hell is religion and what is spirituality. So the beautiful aspect of that was I was kind of thrust into knowing or to exploring like what really matters and what is what is truth and what is spirituality from a different from a young age, because it was kind of thrust upon me. And I think when when I went through that pain, you know, I used to play athletics. I just love to win and just putting the ball through the hoop or the soccer kick. I just loved it. And then when that that grief happened, that pain happened, it no longer felt as satisfying to win the basketball game or to win the soccer game. Everything kind of took on a different context. And I realized looking back, like, oh, that was like an introduction to kind of like a spiritual oriented.
We're all the things that the society kind of like saw as important, or I saw as important, actually no longer fed me in a way. So I had to then go and explore like, all right, what do I do with this pain in my heart? And then Buddhism had this word suffering, dukkha. And I was like, oh shit, I think that's what I'm, I think that's what I'm feeling. And teachers like Ram Dass and others, I'd listen to their tapes and read their books. I was kind of being introduced into, oh, there's this thing called compassion. There's suffering, but there's also this other way of meeting suffering that actually breeds compassion. And so that became kind of like the door that I began to explore. And how do I actually foster that and live with that? And it's not about necessarily getting rid of the pain per se or the traumatic experience. It's about relating to it in a different way that actually builds empathy. I'm a parent, I'm a 20 year old, and I noticed myself like, I don't want him to go through difficulty or pain. And yet I know that that's often what builds compassion, right? Imagine a child who never suffers, like how are they supposed to learn empathy and compassion? So there's some kind of balance there between providing a context for our people to go through suffering, but not to stay in suffering. And does that suffering, can that suffering expand into empathy and compassion? One of the things that was super interesting that I heard you say is describing it in terms of thrusted into this world. Because the way I was interpreting it, and I was way off, I guess I was seeing it through your dad's eyes of like, he acknowledges you're having this tough time, you're clearly struggling, he wants to reach you, but he's not sitting you down and having a stern talking to you. He's not threatening, he's not doing anything, he's not, I'm not going to send you away if you can't sort of... No, he just left a pile of books outside the door, and he just kind of nudged you. And I had interpreted that action as sort of him kind of just trusting that that was enough, right? That he knows this is a lot, but he trusts just making this available. Soren will find his way, hopefully. And I think that's like a gutsy move to not get more involved when your son's having such a hard time. And it's interesting to hear you phrase it as thrusted, but I think you meant it in a slightly different context. I don't know. Life was pushing me in a direction that was different from the old world that I was living in, where certain things mattered. And now in this new world, a different thing mattered. And Ram Dass said this beautiful quote, and I'm not going to get it perfectly right, but he said, his job isn't to tell people what to do or to push them in a direction. It's to provide a container that if they do want to awaken or see something, there's nothing in him that's deterring them from...
And we're going to be talking about how to create containers that are optimum for growth without telling people grow, you know, mature, like, like do this action. But there's a container that we can create with our friends, our family, our loved ones that kind of create some more conducive learning environment by asking the right questions, by putting the right books out. But I do think you're right. I think that there's a spacious, it's like the yin and yang. You need to have thrown some push forward, but if you push too hard forward, you get resistance. So there's a dance with that, that I... Your dad, he was a professor of psychology at the local university in Lubbock, Texas, Texas Tech. Yeah. Wonderful human being. He's still around. He's 82 and just... Good for him. I wonder if you guys, have you ever talked, was he, was that intentional on his part? Was he aware of the world kind of pushing you in one direction? Maybe that's why he took that approach because he seems like a dude that would be really dialed into that if that's like his domain. That would be my guy. Yeah. He felt like he was, his job was to kind of offer us a direction and kind of the spiritual world and because we weren't going to church, he wanted to introduce us. So I remember there was this one time we had this woman, a colleague of his come over and give us a talk on saints and the kids. And there was a Ramana Maharishi and all these kind of amazing saints. And she gave a talk on saints and he would kind of quote different teachers to us. And I think she was trying to provide his own version of some kind of spiritual reality that we didn't have within the cultural framework. Amazing. Real quick, Ellen, I don't know that I've ever... Do you have a books by the door story? Do you have like a moment that you can pinpoint that set you kind of in the direction that you headed in? Do you remember anything like that from when you were little or something that said, this is that sparked it all for you? I did. Now that you mentioned it, there was... My dad gave me a lot of philosophy books. Really? Shocking. And I literally read this... Well, I had this mini version of Plato's Republic, it's like tiny little book that you could carry around. And I literally read that. I didn't know it was just supposed to be like a kind of gimmicky thing. But I actually... Ellen was five, by the way, listeners, this is when Ellen was five, not how many. I was in third grade. Wow. That's a totally young for that to happen. But I think the reason that I was drawn to that was that I was in a Jewish school and I just... 
And we're going to be talking about how to build equity in a way that's not just about the human mind, but also about the human mind as a whole. So, let's get started. So, I decided very early on, well, what happened was like in second or third grade, I was told that Jews were not like the majority of the world. Most people were not Jewish. And I was like, wait a second. Everybody else is Jewish. Yeah. Like, if that's true, then how come like, I'm only learning this one perspective, right? The third Ninja Turtles movie didn't live up to my expectations. That's what I think I was doing in third grade. That's amazing. Yeah. When you decided to kind of like the technology was fascinated, but you wanted to put this empathy side to it, or you wanted to kind of do a kind of human betterment side to it. Was there a moment where you're like, huh? That came way later. So, um, when I was in fourth grade, that was, yeah, yeah. It was, uh, during my PhD, when I was working with Docker and we started consulting with companies because they were reaching out to us thinking, you know, saying, Hey, you're publishing on human expression. We want to do that. We want to build technology that sort of understands people a little better. And, um, working with the people at these tech companies who are interested in that, most of them, uh, had a very, um, had really good intent. And a lot of them, um, wanted to build technology that understood people's wellbeing and could optimize people's wellbeing. Literally there was a wellbeing team that was the protecting care team. Um, things have sort of gotten reorganized, but it was, there was an active engagement with the fact that the technology of the day was optimized for engagement in many ways that were almost explicitly antithetical to mindfulness, like pull us in, make us distracted, make us forget why we opened the app in the first place. Um, and then we, you know, try to get us to stay in the app. Um, and so, you know, that's where I was drawn into how do we, how do we apply what we know in psychology to prevent this, even though this is kind of the default for technology. If you're just going to optimize for the signal that you have, which is people using the technology, seemingly that's the right signal to optimize for, because you're building a technology and you want people to use it. It has this negative consequence. Um, and so that's where I realized that psychology had a big role to play in the development of AI. Cool. Interesting. Super interesting. Yeah. Um, thank you both of you for.
Thank you for sharing those stories and letting us hear a little bit about your past and what that was like. I appreciate that. Let's keep moving down the timeline for you, Soren. I want to flash forward now a lot. It's 2008, nine-ish, and you write Wisdom 2.0, the book. This is your sort of first attempt, I think, that I can tell, to reconcile on paper the ancient ideas that you've been reading about, pursuing and practicing. And then, of course, what you observed at the time as this increasingly invasive digital lifestyle. I had no idea where we were going at the time, but yeah, it seemed increasingly... Well, that's just it, right? It's so amazing that you get onto this track in 08, 09, which it doesn't sound like that long ago, but it really is. It's another planet. And there's a bunch of questions I want to ask, but since we're here with it now, at that time, what were some of the red flags that you were seeing that said, do you shine a light on this? Let's start a conversation now. This is big or this is going to be big. Nevermind the fact that you couldn't predict it. It's a great question. I think some of it was instincts at the time. I was kind of seeing the trend in me and noticing the trend in other people, and I was trying to kind of decipher or see if I can put together these two really strong interests I had. One was in the power of technology and seeing how it opened up channels of communication and channels of information that you cannot deny. I mean, the fact that you can now have access to all these videos and all these websites and all these apps, there's this incredible information now at our fingertips. And as somebody who grew up in a small town in West Texas, if I had the internet, wow, I could learn so much, right? So there's that part of technology that I love, but then I also love silence and being in nature and being in quiet and understanding myself. And I would be kind of with my kind of spiritual friends that would be in this domain or be with my tech friends. But I was like, there must be a group of people who's interested in both, but I can't really find them. But there must be some people who are interested in the intersection of those two. And I think I just sensed at the time that there was no doubt that the external technologies of our age were going to get faster and cooler and niftier and more amazing. And that what was uncertain, it was kind of like the real question of our time would be whether the internal technologies of compassion, wisdom, mindfulness, would those grow as this grew or would as this grew, would this kind of stifle this? Yeah. I really felt like that's, you know, compassion is kind of the glue that keeps a culture together.
All this billions of dollars are going into how to increase this, and this is getting less and less attention. And so I felt just very compelled to do my part to see if we could lift up this. But it's really important for me to not to do it in a divisive way. So when we did our first conferences, we invited, you know, the CEOs of Twitter and Facebook and whatever companies, because we're like, join the conversation with us. This isn't about like, drop out, tune out, you know, get rid of this. But there's a danger and the algorithms are kind of set up to kind of create more and more engagement, as you said. And that can have some positive benefits, but also has some really negative benefits. And who's looking out for that other side? Like who's looking out for our well-being? You know, like Netflix, I think it's like four seconds before one video ends, before it auto plays, because they don't, they don't like, it appears anyways, not to trash Netflix, but it appears anyway, that us thinking about how to best spend the next hour, it's like, it's like the challenge that you're trying to solve. Like, we don't want this person thinking what they, how best to spend the next hour. Maybe they need to go for a walk. Maybe they need to have some tea, maybe they do some yoga. So it's like, there's, there's more and less and less time built into technology to actually sit for a moment and be contemplative, connect with our body, connect with our heart, connect with other people. And it's nothing against Netflix per se, it's just a trend of technology, right? It's like, you don't want to lose the attention, so you keep fostering that attention forward. And so I felt like, well, well, the question is not to push that away and, and like tell that that they're wrong. So we have to become more and more conscious. We have to build our own inner strength to be able to manage this in a way that actually serves us. So we can actually sleep at night and we can actually have a conversation across the table with somebody and our kids can like know how to like share their feelings with us. Anyway, so I feel very, which I still do, I feel very passionate about the need for this other dimension so that the incredible, incredible power of technology is used in a way that hopefully it's of service. And wisdom Ventures that Alan had mentioned earlier is a small venture capital company that a number of us created so that we could, you know, support and fund and invest in companies that kind of shine a light in that direction. And part of our, it's the same inspiration where like, there's like gazillions of venture capital companies that anything addictive that like has a high return, you know, they're like, cool, we're in. And there were, there aren't as many, and that's starting to change the more and more moving in direction, but there were.
Nearly as much that says, you know, what matters to us is that we create a world that my children, my grandchildren can enjoy. And we want to find companies and support companies that have that as their goal and make a profit. And we have to figure out a way to do that. There's just no other way. Like people's like, oh, that's not possible. I'm like, it has to be possible or we're screwed. Like there's companies that we can do this, we can make a decent profit and we can be of service in a way. And that's kind of been a lot of my life. It's been trying to tackle that in a way, you know, it's not like the 60s and the 60s. I think people were like, oh, if you're this way or you're that way, you're not a part of the movement. I'm like, everyone's a part of the movement. Like we're all on the same boat. We're all on spaceship earth. And we're all like trying to figure stuff out. We all bring talents to the thing. But if you look at the loneliness in our culture right now, the levels of loneliness level, like people who need medicine pills to go to sleep every night, who can't really focus on anything for very long. There's a lot of children, mental health, there's a lot of signals that there's an imbalance. And the longing, I think, for people to find a way to learn how to sit silently with themselves and harness kind of an inner strength and inner power so they know how to engage more thoughtfully. And I want to tap into that little bit right there, harnessing your inner strength, the inner power. And one, God, I love listening to you talk, man, the enthusiasm and the passion. And it speaks to the point that I'm about to bring up. This was an important, a life or death, man. You saw the writing on the wall and you felt compelled. This is the mission. This is what we have to do. You put everything into this book, right? And then the book comes out. And in your words, how did it... Crickets, I think. Crickets. Crickets. And I was reminded of like the climate scientists in the 80s and 90s screaming for us to listen, like, please pay attention to this. And it's like, that had to sting, right? That is, you worked so hard. This was so important. This was a social, a societal imperative. And then it comes out and crickets. And I think, you know, and I'm not, but I'm not salt in the womb. There's something really important here. I want to get to in your experience there. I may be out of my time. We may never know. Well, I would think so. I think ahead of your time, but also that moment, I want to talk about your emotions in that moment when something like that happens, you know, it's impossible to see then and there how that step may be necessary, how that's part of it, right? I don't know a way to reduce the sting of something like that as it's happening, but I want to know, as we talk...
Let's talk about people developing the inner strength and learning the tools. Did you allow yourself to sit in that for a minute or did you keep pushing like, okay, the book didn't work. What else can we do? How did you navigate that moment? Those crickets. I think anybody who, who works on a project for years, like a book is, lives in a little bit of a delusion because it needs to help them motivate entrepreneurs too. There's a certain level of delusion that's like pushing you forward, right? This is going to be amazing. Oprah is going to love this and things like that. Like there's a little bit of delusion in a lot of cases anyways, and definitely in my case, that's pushing forward that you think that, oh, this is just going to be so well received so instantly. And so there was definitely a certain level of disappointment and a certain level of frustration and a certain level of like, shit, was I, I thought like it felt like, was I, am I off? Am I misreading what I'm supposed to do? And I think I kind of had some months of really looking into that. And the answer I got when I tuned in was like, no, this is, this was like your business card to get you into the room. So when I went and talked to people, the fact that I'd written a book really, really mattered. It showed it wasn't an idea I got yesterday. I was committed to the cause. I had a book that they could read. Like it felt like it was, it was really like a business card to kind of go into what, what, what came into a conference. And so I look back at it now, I was like, oh, I thought I was writing a book to kind of reach millions of people. It turns out I was writing a book for a whole different purpose. And, and, you know, the beauty of that is I think had that gone differently, I might have gotten a little more egoic and thinking I had the answers and thinking like, oh, everyone loves me. And I just need to be talking to everybody. And this kind of forced me or invited me to form a community around it, right. To bring other people in, to bring other voices in. And I think that's kind of what the world needed. It didn't need like somebody who had the answers, it needed a community. And so I hope that I've been able to follow that. But, but I look back at that. I'm really glad that that unfolded. I wasn't at the time necessarily, but I can see the wisdom of that because now there's such a strong community of people who care about this. And I don't know if that would have happened if it would have been, you know, just a book with me as the author and me sharing my opinion and my views, like, I think it would have been limited. Yeah. Wow. Fascinating to hear that that's also, that's another, well, obviously it's a pivotal moment for you. It leads to the kind of the evolution of that becomes the Wisdom 2.0 conferences and all that. But just also too, that that's the moment where you learned to put like the...
Let the ego take a backseat, or at least that's the moment we started to figure out the community is key here and sort of learning from that, which makes sense because a book can be an isolating experience. You're working on your own when you're doing the book. And now it's like, I need, it takes a village now. Yeah. When you try to fight life, it's very hard. This shouldn't be happening. There's a mistake. The publisher's wrong, the time, whatever, versus just like, wow, this is happening. It's not what I thought was happening. This is what's happening. What is the teaching that I can take from this and continue to move forward versus get stuck in blame and shame and that kind of energetics? And I think we all get invited into that almost every day. There's an argument with our partner of like, why is our partner acting this stupid whatever and versus like, okay, maybe there's a reason he or she or they are acting that way. Maybe I get curious about them. Like, honey, could you tell me a little bit more about what's going on with you versus condemning them for having whatever experience or judging them. It's just like trying to invite. And I try to really spend my life as much as I can. Of course, I resist certain things at times, but as much as I can, seeing things that are emergent and be like, oh, there's intelligence here, right? There's something here. And I've tried to do that with technology and the things that are emerging in our world. Like there's an intelligence here. There's a reason that AI is now kind of having some of its need and attention directed to it. There's something that we can learn from here. And so what does it mean to kind of engage that in a thoughtful way? But I feel like going with life instead of fighting life as best we can is the way to go. Yeah. I couldn't agree more. Alan, are you about to say something to cut you off? Yeah. No, that seems totally in line with how a lot of startups have pivoted to AI recently, but a lot of them did something completely different before. So I spent like years launching a product, right? AI comes along and they're like, well, we can actually build something completely different with this, but we have the right team at least. So that's the experience a lot of startups seems to have. I do think that from what I've noticed, I don't know if you've noticed this, Sal, like life just kind of, it can easily beat you down if you don't really love something. If you're kind of in it for the wrong reasons, eventually everything becomes seen. You might be able to hide something for a while, but eventually everything becomes seen. My hope is that the people who really, really care about a topic, that's a different level of motivation than the person who wants a quick exit or who wants the notoriety or fame.
And I see more and more people who are coming forward, who, of course, they would love a great return, but they're also really committed to a cause. And that's what that's that always excites me, inspires me. Well, it's really cool because right now you can optimize technology for something else where AI is showing us that you can, you have levers that you can pull that aren't just like getting people to use the product more, you know, that's like the traditional metric, because you can measure more, you can, you can literally have a product that talks to people and ask them what they want. So it's a different world and those different possibilities really open up the possibility of being more kind of mission driven and more focused on the, how you're affecting people with your technology and able to measure that and optimize for it, which is what we're focused on. Have you had a podcast as Chad GPT came out and how are you seeing the movement, all the, it feels like everyone kind of like AI was kind of like over here, over here. And that was like, everyone's pitch turned over. Wow. Look at that. I'm like, it's kind of all attention. I think Google's market cap went down with a hundred billion dollars because their chat box did before chat AI didn't work so well or made a mistake. So there's, it's like, there's a really interesting shift in that direction. I don't know, just know if you have thoughts on that or whether that's something that it's kind of inevitable in any process. Well, it's a really fascinating time. I mean, things have been like technology has passed the Turing test, right? People notice that, and we don't talk about it explicitly, but that's really what happens. Suddenly you can talk to something and it really understands you. And that's just a whole different way of experiencing technology. And as soon as you experience it, you want way more of it. Give me more of this. And, and the problem is it still has some flaws. And I think we can get a little bit overexcited about it. You know, for example, I think with Google, they've been focused on the backend, but they're, they've been integrating AI into it for many years. Right. And a lot of it's very similar, but it's really just driving backends and the front end looks the same to you. It feels better. You don't realize how much better it feels like if you went back to like 2010 Google, it would feel like it wasn't working very well. But, you know, so people get excited about the chat, GBT stuff, and then they're like, well, why isn't search a little bit more like lists? But what you forget is that you actually want to hear from people.
Humans most of the time and you want to see real images and not and not artificial images most of the time. And so I do think that there's a place for a search bar that doesn't have a chat GPT in it. Alan, can you elaborate on what you mean by you want to see real images and you want to see a human sometimes? What do you mean by that? Well, when you're hearing from an AI, there's no expertise behind it and you don't know who it is. And so it's like this misrepresentation of potentially of what a human really is. And so you don't really inherently trust it. Most of the time when you're looking for information, you want to know something about where that information is coming from. And chat GPT is just not that even if it were referenced. What actually is most exciting about how this technology can change search is not really changing the interface, but changing things like the meta descriptions on search results so that they're much more accurate as to referring to what the page really says and how it directly answers your question. So you could have a meta description that's like, this is the answer to the question that you have on this page. And this is the paraphrasing of it. Like that's a really cool thing where you wouldn't even need to change the interface really at all. And I think that Microsoft is capitalizing on the excitement for good reason of chat GPT. But the way they've changed the interface is they've just added another thing that is unrelated to the search bar. And I don't think ultimately that's what people want. They want everything to be in the search bar. They don't want to be like searching and then have to go through some other chat interface to get other kinds of information. It's just kind of unintuitive. And Google has known this for a long time that people like this really simple interface with just one thing that you type something in press enter. And you don't have to ask yourself how to use this tool. And so I think that's going to persist in that. I don't think it's going to turn Google upside down or anything like that. But that's just my opinion. I think what's really cool though, about chat GPT is you can actually get it to act like any kind of expert that you want. You can literally make it into your personal stage. And I think that the opportunity there is probably not in search, but in some other interface that's more similar to digital assistance. And I think it's going to talk to you and it should talk to you. It acts like a.
And that's where it's going to see a lot of success and could potentially change technology. So without revealing too much, has Hume.ai shifted at all? Or how do you see yourself in the next years engaging in areas or not in certain areas? Do you have a sense of like that, that, that direction that kind of like it's your North Star and, and you'll kind of be guided by that as, as so many different opportunities appear? Yeah, I totally, I think that the generative AI interfaces really change what you can build. And we want to add to that and make what we're building totally complimentary to that. And what's really exciting is that, well, two things, one, we can build something that talks and understands people and, and that's, that can use chat GBT, they can use other large language models, whatever comes out. And so we're not trying to rebuild the wheel, but the fact that you have access to that as a tool is incredibly important. And the second thing is that the way that chat GBT is developed is sort of with a pseudo psychology experiment, right? And that has so much room for improvement, which is reinforcement learning from human feedback. So basically they get people to rate a bunch of GPT three responses, or say this one's better than that one. And then they reinforce, they use reinforcement learning to fine tune GPT, GPT three with those responses. And that's how you get chat GPT, but the ratings are a kind of crude psychological measure. You can do so much better than that. And so it gives us the opportunity to step in and say, this is a better measure to use as potentially that, you know, people's ratings, but also what they're expressing and multiple dimensions of that and have it learned passively from every user and not just the set of raters who you've hired. And so there's so much opportunity there to improve the way that chat GPT works and not just that, but a model for how all AI can learn and be reinforced and fine tuned. So chat GPT is just an interface and you get people's responses, but you could do the same thing with anything that has, it's undergirded by an AI model that can learn from people's responses and that we're measuring. So it's a huge opportunity for us, I think, and a way to really accomplish our mission that we've had from day one. And there's no visual or auditory in that dimension games.
There's no auditory dimension to chat GPT. It's just a chat interface, but it shouldn't be just a chat interface. I think people want to talk to something and they want it to be able to speak back to them like it's a human and not like it doesn't want to, they don't want something that sounds like Alexa. Like if you just hooked it up to Alexa, nobody would use it, right? It sounds so frustrating to interact with, but imagine if it actually sounded like a human. And on top of that, did the things that humans do, which is kind of picked up your tone of voice and understood feedback that you were delivering through, not explicitly, but through your tone of voice and not actually having to say that was a bad answer and adjusting the way that it responded the next time and integrating that and becoming a personalized model for yourself. Like that's the big opportunity, I think. Yeah. The science fiction has promised us this for years. Kit the Talking Car, Jarvis from Iron Man, there are countless examples. How many years Alan, ballpark, do you think until such a thing starts making its way to mainstream? How far out do you think we are? For the digital assistant world, which can just build on chat GPT plus a voice interface, plus what we're building right now at Hume, I think that that's literally less than a year away. Wow. Wow. There's already really cool text to voice stuff coming out, but the text to speech and text to voice technology is built in a very similar way to GPT three, where it's not optimized for your experiences. It's just optimized to sound realistic and that's step one, but then you can build it in a way that chat GPT is built, where it's actually optimized for your experience, how you respond to something. And then you could have a chat interface that speaks and speaks in a way that actually is meant to sound friendlier and sound better and create more and make sure it understands you and be optimized for all of these things, which is the next step, the next generation. But, but all of that is, is based on technology that is either available today or just months away. Just needs to be put together. You would need to give access to the camera or else have some kind of robot entity, right? Because if you're, if you're working with visuals, at least. Yeah. I think most of the interfaces are going to just be auditory, especially at first, unless you're talking about a mental health context where you have.
I think the voice is much richer than language is what we're finding. It's interesting because I, a little bit of a sidebar, but you know, when TikTok started becoming more and more popular, I was just curious about it. So I like went there and my first impression was like, wow, it's so interesting. The algorithm is the default. I'd never actually seen that before in a social network. The algorithm is a default and that I didn't seem to need to tell it. I didn't need to like anything. It just knew by how long I was watching something, whether I liked it and whether to feed that back to me again in order if I did some action. And I was like, oh, the algorithm, and I don't know if you guys have different views of it, but they're one upping Instagram and these other places that you go follow and you like, and you do all these comments. It's like, oh, that's the data source to determine what we should kind of give you versus like, I just live my life and I do this in two seconds or five seconds and they have all the data they need to know where that should go. There's positive and negatives. But it was, it was kind of an insight for me of like, wow, this is a different level of algorithmic direction than what I felt like was before, where there was these likes and comments and follows. It's scary a little bit because it's such a one dimensional view of your behavior that it's optimizing for. And that's the beauty of TikTok. It keeps you on one video at a time. So it knows that the longer you dwell on that video, the longer you're watching it. That's how it's so information rich, the signal that they have. And from just watching a thousand videos on TikTok, suddenly they have a picture of like, what is it that you like dwelling on? Basically, what are the kind of voices that you like? But how you respond, whether you're happy or not at the end of the watching it for two hours or four hours, or kids these days, many of them watching it for six hours a day. There's nothing in the algorithm that tells you whether that's good for the person. That's the scary thing. And so that's why we need more multidimensional signals.
And it tells them that because, and this is the part where I'm told I'm cynical, but, because that doesn't make them extra money. They don't need, they're not incentivized to do that, right? So how do we incentivize them beyond it would be objectively better for humanity? I'm not saying how do we monetize it, but what, how do we find a path towards that? Because that is a necessary piece that is missing and we are starting to see the repercussions of that. And so it's like, how do you solve for that problem? So I think that there is, you're right, that there is a business incentive in the short term to get people to just stay on the app longer, because that's how they make money is long. You stay on the app, the more ads you see, the more ads you see, the more money they get from their ad partners. And that's in the short term though. And then you, in the longterm, there's only a limited number of hours in the day. And so you have companies competing for attention. And if everyone just uses that model of like, let's try to steal attention away from the other apps to the degree possible, then we're going to run out of hours to do other things in the day. And that's already happening with kids. You already have kids spending six hours a day on average on social media. And then there's a societal response. There's a response from parents, there's a response from legislators. It's negative to say the least. And so how are these apps going to survive in a regulatory environment? And then how are they going to survive when parents want to take it away from their kids? How are they going to survive when kids are having mental health issues and the solution is you have to get off the app? I think ultimately their business interests will be aligned with, sure, you can try to optimize for people spending time on the app, but make sure it's quality time and that they're better off afterward than they would have otherwise been. If you have that as your business model, then that avoids a lot of those issues long-term. What do you think about partnering with a wearable that actually takes other readings, whether it's heart rate variability or gallbladder skin response, electrical activity, like different things that might help actually determine what the relationship is in that moment with a certain technology? Or do you feel like you can actually get that through other means versus a wearable that gives other data in terms of what level of stress they might be experiencing in a given day?
The first is for wearables. It doesn't really tell you about stress though, because remember, the wearable is picking up on things like heart rate and respiration and galvanic skin response. And all of these can be good or bad. We consider it stress when it's negative, but the same physiological signals can resemble something positive when it's excitement or flow, or the body responding in a beneficial way to challenges that you feel better when you have those challenges and when you meet them. So I think that the physiological signals are kind of one dimensional right now. It would seem though that if I'm experiencing stress or I'm experiencing happiness, my body must be communicating that I'm doing one or the other, and there must be some way to determine that. And maybe just the wearables aren't as developed yet or the technologies aren't as developed yet, but it would seem to me that the body would have different indicators and that there'd be a way of assessing which indicator they wouldn't be. My body wouldn't be indicating the same thing that I'm scared shitless and I'm super excited. It would be odd to me that you're like, oh, well, the readings are kind of similar, so it's hard to know. I think that there's a way to do that, but that's my take. It's a limitation of the measures really that we can't do that now. I mean, obviously that's in our brain, right? Experience is represented somewhere in your brain activity. The measures are of heart rate and respiration and so forth. And you can get salivary cortisol, which is more closely related to negative stress, but you can't get it from a wearable right now. And so there's not that many measures you can get from just something that's on your wrist that will tell you whether you're having a positive or negative experience. I mean, maybe in someday there will be, but right now I think it's much more in the voice and in what your body is doing. So more the voice and visuals for you, even now. I would say that they're both really important and that particularly facial expression is something that is with you at all times and you're not always speaking. And it really depends on the situation. Not that you should be recorded at all times, right? So that if the data exists, the facial expression can be more informative. But I think most, a lot of the time, the data that you're transmitting is through the voice. And that's why I think sometimes it's more interesting. So I want to go just take it back to the Wisdom 2.0 conference for a second and tie it into everything that we're discussing right now.
Right now, you know, we were talking just before we went and hit record in this podcast, we were just kind of going through the lineup and just the eclectic roster of amazing speakers. There's so many people on there. One of them, of course, Sam Altman, the co-founder and CEO of OpenAI, which is very exciting. And Soren, I'm curious, just listening to some of your questions, I can tell your brain is firing on all cylinders and you're absorbing everything you can about what's going on out there. And I would love to know your process internally of the inclusion of AI in a conversation about mindfulness. You know, what do you see as the significance of having that as part of this conversation? You know, the beautiful thing about a conference is you can have conversations without answers. And so, you know, love it. There's a lot of things where I feel like we need to foster the conversation. And I have no idea what the answer is, but I know that the more of us putting our attention on it and the more of us saying this matters and more of us starting companies that have that as part of our mission and part of our orientation, we have such a better chance of creating a better world with that as part of our intention. And so when I bring people in, I don't necessarily expect them to have answers, but I expect that it fosters an energy and an attention to this. So when I asked Sam to be, I've never met actually Sam in person, but when I invited him in, it was before they had launched Chai TPT. I knew they were working on something. I didn't know what they were working on, but I knew he was interested in this domain. He's interested in mindfulness and he's also interested in, and of course, deep into AI and Jack Kornfield, who's a kind of well-known meditation teacher, but it's going to be with him and they know each other. So there's like a, there's a commonality, I think, of the two of them appreciating each other kind of worlds. And I'll be super curious how that gets, what emerges from both of them kind of holding the space. And I get the sense, and I don't know, this has been true of other people. I get the sense sometimes a CEO actually has a bigger, deeper vision and they've been to other interviews at other tech conferences and the tech conference is asking them more of competitive advantage and how are you going to tackle this? And how do you compare with Google? And they don't actually talk to the person about what's really inspiring them and what their real vision is and what is kind of their heart's purpose for doing what they're doing. So at Wizard 2.0, we try to kind of get to that human element of what is the, what's the human person that's doing this? And so that's my
And I think hope in that conversation is that Jack will present kind of his own views on if we looked at AI from a kind of a Buddhist or spiritual view or wisdom view, what are the questions that we should be asking? And also to kind of hear from Sam, like what's his ultimate vision for Jack GPT? Like what is it, is it, is it, how does he see it helping humanity in different ways? And what's the vision for it being a humanity supportive? And I'm guessing he has that. And maybe he's talked somewhat about that in the past, but I'm super excited to just see what develops from that, because I feel like that's where change happens. We need, we need people on a mission for that's about the we, it's not about the me, right? And so, so, but, but it was kind of just random that they just happened to become, I didn't know they were launching, I just kind of knew he was interested in these two different domains. And then all of a sudden they launched it. I was like, oh, fascinating. That should be fun. Well, Pat Tauss, I assume for that conversation, it's going to be a lot of eyes on that. One to a lot of people curious about that. Like anything, it could be flat or it could be amazing. I just, I know that, you know, I love to put people together like that. Like you have like one of the most well-respected Buddhist meditation teachers, and then you also have like AI kind of champion and, and the two of them, like, like they could be really a whole thing, or it could also be amazing. And that's kind of the spirit of wisdom too, but it was, we need both, we need actually the deep wisdom. And I know, you know, you working with Dr. Allen and your values and stuff probably also has speech to that, but like, we need the deep, deep wisdom. And we also need the savvy, incredible engineer, visionary technology leader. One left on their own. They can't really solve it in my view, but together, bringing both together, there's a much better chance that things can emerge that, that actually create the world that we want to see for our children and grandchildren and cousins and nephews and everyone else. So that's the spirit of that conversation is let's explore together the inter-dimension and how might that get expressed in, in some of these new technologies. Yeah. I think there's a role for psychology and intermediating that too. I mean, Dacca is really good, as you said, at pulling up on ancient wisdom is very well read in the literature and actually turning it into data and like, let's make a hypothesis based on this ancient wisdom. Let's gather the data. Let's test these questions. And then, you know, I joined Dacca's lab back in like 2015.
And we realized that there wasn't actually enough data to really train the models or to ask the statistical questions. And that's what we did. We just took that same approach and we basically multiplied it by a thousand and then we multiplied it by a thousand again, but we have these massive data sets. But I think that intermediating between the inner technology of ancient wisdom and AI is the need to find examples and turn the wisdom into data to train the AI. That's really sort of what we're trying to do. That's beautiful. And yeah, and that's cutting edge frontier, right? And I think sometimes people think like, if I could just get this technology out, if I could just get this out, then it gets out, it has totally different repercussions than they thought, right? They were just focused on like, I just want to get this out. And I think what we're seeing now is people who come at it from a much more thoughtful perspective. And I love that Native Americans kind of think seven generations down the line, supposedly. And I love that there's more of a thoughtfulness about like, okay, this is going to come out and this can come out in a lot of different ways. Some of it we can't control whether somebody uses one of these, but we can do our very, very, very best to give it the best shot at having a positive impact. And I've talked to people who've started some of these major social media companies and privately, they're like, boy, we just don't know how this company, you know, like nobody kind of foresaw how Trump would use social media or, you know, like, they're just like trying to figure out how to like create ways for people to communicate. And the same with most, I think, great inventions, right? Like, there's often not a lot of thought on impact and some of that it's out of our control, but I think we can also do a much, much better job of doing our best to create the conditions that increase the likelihood that for the most part, it's going to be positive. There's going to be things that are not positive, but for the most part, the impact is going to be positive. Yeah, totally. I think OpenAI is doing a great job of like putting it out there gradually, giving people a chance to experiment with it before it really is in its most transformative and like powerful form. And I think that that's been really cool and it's given people a chance to think about these questions. We're coming into the home stretch and so we're going to wrap things up in a little bit, but there was some stuff that I really wanted to get to, especially as we've been talking so much about the potential of, is it another device? Is it more data? Is it more of these things? And, you know, we mentioned early on in the conversation,
I brought up how I kind of loved the idea of your father trusting the universe and trusting the system. And then Soren, you've told the story on another podcast I was listening to a while ago about where you've learned, you learned a lot about trust and kind of reframed what trust meant to you. And you were on your walking journey across the world and you were somebody who had, you know, overplanned and packed his pack and had rations in this fridge truck. And then you came across some dudes that were just literally taking it one day at a time and just sort of trusting the energy of the universe and trusting that what they were putting out in some way would eventually find its way back to them because that's what they're putting in. They're just trusting in the way of the world. Does it get trickier, okay, when it comes to all of the technology that we're allowing to permeate into every second and ounce of our lives and attention, what are we trusting at that point? Right? Because it's one thing to believe the universe is this massive thing that we're all a part of something much bigger than we can even understand. But this tech for the most part is of our own design. So do we need to be more cautious? Do we need to reevaluate what it means to trust? What does it do to that? I was listening to Yuval Harari speak a while back ago and he was kind of suggesting, at least from my interpretation, he was suggesting that we can't really trust ourselves because we've been conditioned with 10 bazillion, you know, ads and images and stuff. And so what's motivating us is influenced by all these different factors. He used to say what a genuine intention is, intent is. And I hold kind of the orientation that when we, most of us sit quietly and we connect with something deeper in ourselves, we can feel the difference between something that's conditioned by our parents, our society, our family, and something that's truly coming from inside us that's more of a, it's not a should, it's like a must, right? Like this is where I must go. This is where my energy wants to go. And I think that there's no way that that can ever be taken away from us, right? It's like the sun is always shining. There might be tons of clouds that deter it for a while, but there's nothing that can kill that, that exists in each one of us. And that the real challenge of life is to live closer and closer in touch with that. And I'm a strong believer in some kind of contemplative practice every day. If we can, it doesn't have to be meditating. It doesn't have to be, it could be singing, dancing, sitting in nature or going for whatever. It kind of reminds us that we're not this isolated cog in this great, crazy universe, right? That there was this.
There were, you know, something smaller than an atom, if the story is true, and that some energetic force comes into that atom, and then all of a sudden, a hundred billion stars and a billion galaxies, like something emerged that we are also that. We are the energy. The Big Bang didn't just happen, we're remnants of the Big Bang. We're the intelligence that started that, not to get too far out. But what else would we be like? We are that energetic force, and we're taking these forms or these bodies. And so can we tap into that as an energy source? And kind of like that to me is, I feel like it's kind of wisdom, right? It's trying to spend some time where we kind of limit some of the external influences and impact and stories and things coming our way. We can just kind of like stop and settle and just kind of like listen to and attend to what is in our inner world that needs attention. And I feel like the more that we can do that, the more that our actions can be guided by it's like more of an inner direction, inner light. And we've all met people, we've all been in that space at times, and you meet people who are harnessing that. And you're like, wow, they're supercharged, you know, like you see people, there's a super chargedness to having some vision and mission beyond the me. And I feel like that's really our invitation. And it's so, so important. And the beautiful thing now is like, maybe in the past, it was kind of a nice to have. But now I feel like it's like we're almost forced in order to have any kind of sense of the world and going to sleep at night and be able to pay attention, like we need to understand that we're bigger than these isolated cogs in a system, like we're a part of a deeper universe intelligence. And that meditation or connected with the woods or connected with anything that reminds us of that is it's almost like a necessary medicine for our time. And I think all this interest in psychedelics and healing trauma is like part of that, like wanting to rediscover who are we beyond these names and forms and identities and all these things that we got to play with in society, that maybe there's a different dimension that we can also harness. And it's exciting, but I hope that's not too far out. But that's actually what I feel and sense that if we can tap into that, it's no longer Soren trying to do something or Alan trying to do or any of us trying to do something. It's something deeper than us that's moving. Yeah. Kind of what I learned when I did this long walk across the world for a while, you know, that is everywhere. I can't. 
I don't access it a lot of the time, but I can sometimes, and I know it's there. And I know when people do that, amazing things happen. Yeah. Okay. I'm going to wrap it up. I promise. But there was one last thing, and usually I end the show, as Alan knows, I go, let's look ahead. Let's talk about what's coming down the road. But we already kind of did that. And there was one last thing, Soren, that I really wanted to ask you, because your whole mission is this coexistence of the technology and the wisdom and the ancient wisdom, the inner self. And a lot of the conversation from a lot of external sources is finding a balance between the both, but they are separate. We have to balance, but we keep them separate. And I'm curious, have you in your journeys, in this journey, in your travels come across, can you think of an instance where instead of needing to keep it separate, you actually observed the technology opening up a door that perhaps was inaccessible for us prior, in much of the same way, not to be too oversimplified, but a stool in the kitchen allows me to get to the higher shelf. Was there a moment where the technology wasn't a hindrance, but it actually allowed someone to quote, be a little bit taller, so to speak, and help them get to a place maybe they couldn't? And I'm sure that happens in multiple, multiple ways. And on one level, everything comes from the earth, these technologies, these phones, these computers, it's not like it's come from outside this universe. They're expressions of universal earth elements, right? That just get put into these things. And so it's the earth. We're touching the earth on one level when we're holding our phone. But there's a different vibrational input for me anyways, when I'm holding my phone versus I'm like, I'm touching a tree or holding a baby or holding my lover. Like there's this different, it feels differently, but they, even though they're all from the earth. But one example I had, so when COVID happened, a lot of people were just stuck in their houses and were not quite sure what to do. And there's a teacher and a mentor and a friend of mine named Jon Kabat-Zinn, who's just a very well-respected mindfulness teacher. So every day at 11 a.m. for about three months, we held a free open meditation for people all across the globe. Thousands of people came from like 125 countries and we used Zoom and we meditated together every day. And some people had COVID, some people were, their parent was dying. So we all, and the whole range of things that were going on at that time, but the technology actually allowed us to remember the community that we were all a part of and actually practice.
It's like the technology, like for the first 20 or 30 minutes, we meditate together from like all over the world. And there was a beautiful remembrance of our interconnectedness and our humanity and supporting each other in what was going to be like just a really hard experience. And I look back at that, I'm like, yeah, I could have done that on my own silently, kind of thinking about this world that we're all living in and all the people going through a lot of suffering. But there was something really powerful about meeting with them and seeing them every day and practicing together and connecting together. Amazing community that emerged from that, that I would not have happened without technology. And the information that's through podcasts and things like, boy, that can really, really help so many people. And I think you even see like with Netflix and some of these other companies, like they're starting to, like Netflix now just had my friend's video called Mission Joy up about the Dalai Lama and Desmond Tutu, and they also did How to Change Your Mind with Michael Pollan. Like you see even the traditional companies, like wanting to kind of get on this bandwagon because they realize like people are really interested in the deeper journey. Sure they want to be entertained, but at the end of the day, do we want to die in our deathbed going, I was entertained, I made it, I spent my life entertained. Yeah, I think so. I think like, yeah, I entertain occasionally, but like I live my life in a way that was like true to my values, true to my art. I didn't waste my heartbeats, I used my heartbeats well. And I take that breath knowing that like I did what I was here to do and I did my best to kind of live the values that were inside and live those outside. And I know Alan, you probably met a lot of people, there's brilliant people in the world and I talked to them and they're like, I'm brilliant. My brilliance isn't used in a way that I think is of service. And that's an ache and a pain. And I feel like the best we could do is try to navigate a path where our brilliance and our gifts are used for something beyond us and that has purpose. And it turns out that those people live happily lives, live longer lives, live more meaningful lives. Like there's benefits beyond a paycheck that that supports. And so, and technology I think can be a rich part of that. What a beautiful and perfect sentiment to close things out on. Alan, I don't want to cut you out. If you had any thoughts before I wrap this up and say goodbye, but that was, I mean,
I think people are realizing they can't live in silos, like the psychologists need the need the engineers, the engineers need the spiritual teachers, spiritual teachers need the like social media wizards, like, like, we kind of need each other. And I think there's a beauty in that, that working isolated in some ways, it's as helpful as it is, because we can only know so much. I think if anybody leaves from this podcast, this podcast, it's just like, what is your gift? And then find other people who have complementary gifts, because working alone, we just can't do what we can do when we're in a club that have... Yeah, couldn't agree more. Typically, I'm really bummed when we reach this point, because nothing gold can stay right. But honestly, this was such a great conversation. And Soren, you've been so generous with your time. Thank you. Again, massive thank you. It's been fantastic to have you on. And the door to the Feelings Lab is always open.
The podcast is brought to you by WISDOM 2.0, and by WISDOM 2.0.com, that's WISDOM, W-I-S-D-O-M, the number two summit, S-U-M-M-I-T.com. Alan, any day I get to hang out with you for an hour and change is a good one. Thanks for making time and it's good to see you again. Likewise. Awesome. And to those listening, watching, whatever, thank you. Most of all, as we've said multiple times today, we all have limited heartbeats, right? And you gave us a little bit of yours and spent some time with us today. And I appreciate that. And that means a lot to me and the team here. And so we can't thank you guys enough for hanging out with us and listening wherever you may be in your car, your apartment, whatever, wherever you are right now. Thank you. We acknowledge you and we are appreciative of your time and being here. Lastly, now more than ever, people got questions, send them this way. I want to so desperately convince a bunch of people here to read them and answer them. So send whatever may be on your mind. You can email us at the feelings lab at Hume.ai. That's T-H-E-F-E-E-L-I-N-G-S-L-A-B, the little at symbol, Hume, H-U-M-E-D-A-I. Send us enough and I'll write a song for that. I won't just say it anymore. All right. I will move heaven and earth. I'll get Alan to read it and eventually in time, maybe even answer it. That's going to do it for now. Farewell from all of us at the Feelings Lab. I'm Matt Forte. Thanks again, everybody, and please stay safe out there.
