Hello world, what is up? Welcome back to the Feelings Lab. I'm your host Matt Forte, and for today's episode, we're talking about awe and digital art. And while I'm certainly no Bob Ross, I've totally painted my fair share of happy little trees in my day. Be it through graphic design, creating music, or even my work here on this show, being able to create and explore through those creations has been a vital part of my life. One of the most exciting and scary parts as an artist is releasing your creation into the wild to see what other people think. Because while yes, under the right circumstances, criticism can be helpful and lead to growth, it can also be hard to hear harsh truths about the thing you worked really hard on. So why bother subjecting yourself to the court of public opinion at all? Because the reward of someone connecting to your work, to hearing them sing your lyrics back, to watch them hang your piece on the wall because it resonates with them too, is a remarkable feeling. According to a Wikipedia article titled Art in Emotion, there's recent research that has shown the neurological underpinnings of perceiving art differ from those used in standard object recognition, meaning you quite literally view art through a different lens. We ingest and process art differently than we do the rest of the world. Our response to a piece is a deeply personal and honest one, but what is it that we're responding to? Is it the overall message? The effort that went into its production? How important is the medium? I've cried just as much watching movies and listening to music as I have reading books and wandering museums. So why then are there so many people who have such strong feelings and prefer the original hand-operated Yoda puppet over the new objectively more realistic and agile CGI counterpart? What if the thing you love wasn't made by a human at all? AI-generated music and imagery are not far-off distant possibilities. In fact, they exist today.
And if connecting to a given piece makes you feel seen by the artist or offers an understanding of its creator, what happens when that path leads you back to not an individual, but a machine? Is my human response to a piece any less honest if said piece was born not out of emotion, but rather built based on data? Okay, one more because I got a ton of these, right? See, the other side of that coin is a human had to make the machine that is capable of creating the art. So just because the tools are evolving and the process is changing, does that take away from the end result? Honestly, I don't know. Prepare yourself, guys. For the first time in Feelings Lab history, there's a good chance I'll be repeating some of my introduction questions verbatim once I bring our guest into the fold here because I am deeply invested in today's topic as well as beyond excited to get their thoughts. Joining me as always, another man whose thoughts I simply can't get enough of, my co-host, the great Dr. Alan Cowan is here. Alan, this is going to be a good one, man. I'm super excited. How are you doing today? You excited? Doing great. Really excited, yeah. All right, man, sweet. I'm excited too. Let's get to it. All right, how about today's guest? He's the Industry General Manager for Media and Entertainment at NVIDIA with a career spanning Apple, Lucasfilm, and Amazon. His experience combines driving marketing and product development with a focus on bringing new ideas to life. At Apple, he directed developer relations and managed Final Cut Pro, Logic, and Aperture. At Lucasfilm, he served as CTO, managing research and development, IT, and information services. He's given keynote addresses at GTC, Asia Broadcast, and ChinaJoy Expo, and delivered multiple Apple Worldwide Developer Conference presentations. He currently serves on the Bay Area Board of the Visual Effects Society and is an active member of the Society of Motion Picture and Television Engineers. My goodness. Please welcome to the show, Vice President, Omniverse Platform Development, IGM of M&E at NVIDIA, the one, the only Richard Karras is here. Richard, oh man, what a thrill to have you on the show today. I am visibly so excited you're here. Thank you so much. How are you doing? You doing all right? I'm good. How are you? I'm very good. Thank you for asking, man. It's an absolute treat. I'm really stoked to talk to you tonight, and I'm excited to hear what you and Alan have to think about all my crazy questions.
Let's begin on the emotion science side of things first, real quick. Going back to one of my big questions, when I connect with something, it's typically the content itself, the story being told, a specific lyric maybe, and as I've gained experience and with age, I've developed an appreciation for not only the what, but the how, the exhilaration feeling, the exhilaration of seeing like something new and thinking how'd they do that, right? So scientifically speaking, emotionally speaking, what's going on inside of us, inside of me when I feel affected by art like that? What's happening? Yeah, I mean, you bring up so many good questions my mind is racing, but, you know, it hasn't happened. We actually did just do a study on this. And this is one of the understudied questions in psychology and one of the areas where there's, you know, human nature is so mysterious and art is just such an essential part of culture and essential part of what makes our lives worth living. We just truly don't fully understand it, but we did a preliminary study basically on the feelings that are evoked by visual art, and there was a collaboration with Google Arts and Culture, and we had over a thousand people look at visual art, just respond to them, describe the artworks in terms of how they made them feel, using these really complex terms that people don't necessarily use naturally, but you borrow from sort of art criticism as well as psychology and the study of aesthetic experiences. And what was amazing is that people could actually take these really nuanced feelings and reliably associate them with art. So art has this incredible ability to communicate nuanced feelings, communicate them, evoke them, more than any other kind of stimulus that we've looked at. And people's responses were distinguished among at least 25 different dimensions of feeling that were associated with art. So things like spirituality, psychedelic or cosmic sensations, mystery, dread, all these really kind of nuanced subcategories of emotion. And so it seems like art is specialized in a way for bringing out the complexity of human emotion and in terms of evoking these really nuanced feelings in a transformational way. I think it changes your perspective on reality. It can even bring these complexities of emotion to sort of mundane things, things you encounter in everyday life and transform how you look at them.
There's a lot in there that I want to unpack and I'm making some notes to come back to some things later. But real quick, the art that you guys used or the art that was used in the study, was it all generally speaking, art that's either famous or well known or created by humans? Was any of it AI assisted in its creation? Or was it all traditional art as we would consider it prior to that? Yeah, this is all traditional art from around the world, though. Some of it more ancient, we looked at things even as far back as cave art. And we also looked at modern contemporary art in different countries, a lot of stuff from Korea, a lot of stuff from China, a lot of stuff from non-Western origins. And so it's really a rich array of artworks. Fascinating. We're going to come back to something there in a little bit. Real quick, I want to get into, though, the significance of the human element in the creative process. And talking about animation and AI, there seems to be something intangible that we can sense whenever technology intervenes. And I mentioned in my intro, the affinity for the Yoda puppet versus CGI Yoda. But specifically with animation, I think you can go all the way back to the Fleishers who were the first to rotoscope and trace video and images to get a more realistic look to their animation. But if you look at that versus something with more of like a squash and stretch, there's a tangible difference between the two, right? And if digitally assisted is objectively more realistic, why do some people still prefer or romanticize things like practical visual effects and handcrafted and stuff like that? What is it that we're connecting to that we some people go, that's the better thing? And I'd love to hear both of your thoughts on this. I'll start having been in that world and listen to people complain about some of the issues and other things that I won't delve into the specifics on. But I think people get a comfort level when they see something for that first time or something and they like to hold on to it. It's meaningful to them. And so, when somebody then changes it or modifies it or it becomes in its next generation, something maybe all digital, things like that, their inner sense is to reject it, but they may not understand.
If somebody didn't tell them that, would they know? Right. You know, I mean, in the original Jurassic Park, there was supposed to be way more puppetry. But when the digital dinosaurs were proven to Stephen to actually work and work really well, that's what they went with. But did people go, oh, I preferred the puppetry better? No, you want the impact of what that scene was supposed to get. And believe me, we all remember those early times of seeing it, you know, the shock value and everything else. Would you have had that if it was, you know, stop saying from a King Kong? I don't think you would have. I think it's just a different kind of emotional attachment that you get to something. I mean, look, there's it happens in all kinds of art. Oh, I prefer records. I prefer vinyl over CDs. I prefer to listen to the vinyl and all of that kind of stuff. And friends, oh, you're just you know, it's better if it's in this if it's in flack or it's in that. I don't care. I just know what I like. And that's all that matters. Right? Yeah. And I think it's the same way in all kinds of art. Like, well, I prefer the that the puppetry versus the digital. That's great. You have every right to. It's your prerogative. You don't have to watch the digital if you don't want to. But I bet you they did. Yeah, I totally agree with that. I mean, probably where I did for most is that people are probably willing to forgive the imperfections of a puppet more than a digital rendering for various reasons. I think there's there's something almost nostalgic about it, too. But I don't even think that's an issue anymore, just because the digital renderings have gotten so realistic and so incredible that I don't even I don't even think it looks there's anything about it that's imperfect. Most people don't know the digital stuff that's in feature films and TV today, and they haven't for a dozen years. That's just it. It's gotten to a point where that line very much is blurred. I was thinking about Favreau and the work they're doing with The Mandalorian. I bring them up because they have this incredible technology, the volume, where it's this giant living digital set. But they accompany it with physical sets that are in place and makeup and prosthetics. It's not necessarily one is better than the other. It's not like practical versus digital. It's more just about creating a seamless illusion.
And it gives them more creativity, more flexibility because they can do multiple scenes in the same day simply by relighting the environment by, you know, reinstalling a different scene and stuff like that. I think it's fantastic what they're doing there because I think that they've absolutely, you know, taken a bunch of different technologies, brought them together. And to your point, there's a lot of traditional in-camera work. You know, if you look at a lot of that stuff, it harkens back to the days of Hitchcock and others where the effects were in the camera. So you'd look and you'd see and they'd line everything up and they would do the shot like that. That's kind of what's going on now. It just happens to be a big LED screen and it's 3D scenes and it's all, but the director gets to see firsthand what's taking place versus come back in six months when we have the shot done and we'll show you that that creature running down the hallway and stuff like that. So I think it's great for what it does for the creative process. I agree. I agree for sure. And it makes for some really awesome looking television. So there's a lot of people that gut reaction when you talk about AI generated art or AI generated content. The gut reaction is that it's less than or it's lazy because it wasn't done manually and it required less effort, quote unquote. And so I'm curious, Richard, as someone whose goal over there is to enhance and not replace a workflow, what are some of the ways you guys envision AI becoming a tool for visual artists? It already is in a lot of ways. I mean, AI has been around for longer than people realize helping them in the creative process, but it's even more so these days, as you said. As we see the advent of all these virtual worlds coming online and the whole, all that excitement about multi, metaverse, multiverse, all that, blah, blah. What's really taking place is we're going to see this next generation of the web where all these virtual worlds are connected. Well, they're going to need content in those virtual worlds and they're going to need things and stuff. And as we all know, anybody that's ever done 3D, it's not easy. It's hard. And that's why there's a pretty finite set of really expert 3D artists in the world. And they're amazing at what they do, but it's not something that you can just hand off to somebody else.
AI comes into play and allows you to do things like you can use your phone and scan an area and it's a LiDAR scanner, and now you have a 3D scene that can bring it in. I can do things like train the computer to know a bunch of photos that might be something I want. That's a car. Oh, that photo, I'm going to make a 3D car, just like that. So you're using AI as an arrow in the quiver and you're able to do things and use it to tell your story or to create your image or things like that. Systems have been doing things like that, sampling sounds and such for quite a while. I think it's more in line with that. It's a means to the end. It's not a replacement of the artist, you know. Can you use it to create art? Yes, you can use it to create backgrounds and things like that. What are you going to do with that? Well, that's the part of the artist. That's the part of the storyteller. That's the part of the director. So it's another tool. Those specific questions or conversations that you guys were asking and having when you were putting things together of like, how much AI is enough or how much is too much? Because I think of like, I was watching the audio to face. Actually, let's start with an easy one. How do you say audio to face? Is it audio to face? Is it audio to face? Where do you emphasize? Audio to face. Audio to face. There we go. We nailed it. All right. So I was watching the awesome demo for audio to face. And what struck me is it says like, oh, now you set the expression and the intensity. Your character can express anger or excitement. Is that a case where it was a limitation of AI at work and that it can't yet necessarily detect the emotion if I'm scared or I'm angry from the soundbite? Or was that a deliberate choice to put that control in the artist's hands? It was first things first, really. Just to be able to democratize something as complex as facial animation with your camera and a dialogue, that was the first revolutionary big step. Because a lot of people want to do that, whether they're telling a story, they're creating content for these worlds, as I said, and things like that. And wherever we can, if we can remove some of those barriers so that more people can access the tools, the better. Well, as we evolve that over time, then we can do more things with it, like emotions, like full body. You know, use your camera to drive character animations and things like that. Crowds. There's lots of different things. And you'll see a bunch in a few weeks.
We look at problems and we want to solve those problems so that people can be creative and productive with the tools. I can't wait for the things that are coming up there at GTC. Alan, I got a question for you, man. What would be, so to that end, what would be the, because we have mocap, right, and we've seen the suits and now audio to face, they can analyze a VO and detect mouth shapes and do that. So what would be the motion capture ping pong ball suit equivalent for emotion? What would you say is the key to creating an AI or a system that can accurately detect and interpret human emotions? Yeah. I mean, it doesn't really have to interpret them, right? First of all, you can detect them. It's a matter of, I mean, the motion cap is the face, right? It is your face. Increasingly, we don't even need motion cap, actually. Your whole body can just be interpreted by the machine. It knows where your, the different parts of your limbs are. But with facial expression, what's interesting is that, you know, if you have a facial expression, you don't even need a motion cap, right? You don't even need a face. You don't even need a face. You don't even need a face. You don't even need a face. And so it's very important to be able to pick up on that nuance. And I think, I'm not sure the technology that's being deployed is there. I think there's a lot for, you know, in digital film, there's a TGI, there's a lot of human effort that goes into positioning facial expressions and forming them and a lot of, you know, sort of motion capture. But I think it can be done. And I think that what differentiates a great actor from a not great actor is how they express emotion and the subtlety and how they capture that candidness and authenticity, because it's difficult to fake. And that's what makes acting hard. So I'm actually curious to hear Richard's take on sort of where we are with that at this point. Yeah, I think it's, you know, I hearken back to that music analogy because I think a lot of it comes into the remixing sense, right? If I had faders that I could say, okay, angry, you know, oh, no, no, no, I don't want that. Let me try this fader, like goofy or whatever. And I can mix them around a little bit in the post-process kind of way. It gives me more flexibility as the artist to say what I want that character to be doing in that particular scene or storyline or something like that. The same holds true in music, you know.
Those of us that play music, you know, what you record live or what you record in the studio can be drastically different. In the studio, you can go in and finesse, you can add more, you can turn up one thing louder than the other, you can add effects to it, you can double it, just on and on and on. We'll have similar types scenarios in the mixing and remixing of content that's visual. And I think that's one of the beauties because lots of people can play with the faders and the sliders and all those kinds of things, but they can't create that original part, they can't play that original guitar part, they can't, you know, but look what happened when music got democratized like that. We had inner city music, we had people that, you know, were not sophisticated creating very beautiful music that, you know, all sorts of, you know, variations of things and like it or not, it's the music of today. It crosses all of those ranges where it used to be if you couldn't play the chords or you couldn't play the notes and you weren't a musician. But we've changed all that, you know, a lot of stuff is happening with people sampling sounds and creating beats or stealing beats, lifting beats, hopefully borrowing and paying for beats. But, you know, the same kind of concept that takes place. Now, if we look at that as it, you know, takes itself into the visual context, you know, oh, I love the look of something, I'm going to sample that with my phone or I'm going to drop it into my scene and I'm going to mix that into the background because I like that, stuff like that. I think we'll see lots of things like that and the beauty is, again, it brings it to a wider audience of storytellers and things and artists. Yeah, that's the thing I was kind of pondering in preparing for this is like you think of like, you know, movable type brought knowledge to the masses, right? And that brought information to the masses. So what is going to happen society wise? Like what has our culture going to transform now that everyone has all these tools? Like you mentioned the LiDAR scanning, everyone can make a 3D model now, everyone that has a phone has a 4K camera now. So it's just the law right now, the short term is there's really great looking TikTok videos, but like what's the long term impact of culturally speaking of people having those abilities? And I think we're just barely starting to see the... Yeah, you gotta have something to say and something to share.
And it can be on super great equipment, it can be on cheap equipment, it can be on all kinds of things, everything in between, you know, like Tom Waits, he thrives on making stuff in very lo-fi and, and found sounds and stuff like that. And we adore his work or lots of us do, you know, and then there's others that are very sophisticated and have to have everything pristine and Abbey Road and it's got to be, you know, meticulous and stuff like that. If you've got a story to tell, if you have something to share, you'll find a way. Yeah, that's what it boils down to, right, is it's the technology's eliminated the barriers and eliminated the excuses. Now it's just find your story and tell it is kind of the thing now. Yeah. Let's, I want to chat a little bit more about AI generated content for a second, because you're right. Game developers have been messing around with procedurally generated maps and environments for a while now. It's not brand new, but to my understanding, and this could be ignorance here, it's limited mostly to geographical information. Are they able to generate environments or landscapes based on emotion? Like if I want to, can I say I want a scary, spooky forest or a cozy reading nook or something like that? Or do I have to get the spot and then tweak it myself? Is that where the artistry comes in? Well, right now, I don't know of anything that allows you to say that in the creation of it, but certainly the tools are there to allow it. Like our GAN technology, where you can say, I want to use a few strokes and create a river with water flowing and rocks on the side and simply like that, and you create those strokes and the computer has been trained enough to know what those things mean. And the imagery that resolves itself is that stream with the rocks and the water flowing and stuff. So it's totally conceivable that you can take that same concept and say, give me some emotions or things to mix into it in that way, the way I would mix paint. Yeah. Very, very cool. Very cool thought. Alan, I told you I'd come back to something you said at the top of the show. And I made a note when you mentioned that you did the experiment with all the different types of art, right? So I would assume through that experiment, you have some data that sort of tells you what sort of emotions the different types of work can elicit, right? Like which kinds of art elicit the most dramatic responses and things like that and so on. So I'm wondering, do you think you could take that?
That data, right, feed that into a machine and program it to not just generate imagery or landscapes, but to say, generate something that inspires awe. What do you think of that? Well, I think what's amazing when you look at art and you do that deep dive is that it's almost every level of the form and depiction of the art conveys really nuanced emotions. I mean, down to like the paint stroke, right? So the things that are kind of spiritual, it's shown in the lighting, it's shown as sort of a halo around things and sort of the haziness and the things that are sort of dreamy and similar, but, you know, kind of there's this surreal aspect to it. There's things that evoke kind of awe and dread and all of these things are kind of, you know, Rembrandt probably thought about every single paint stroke, not actively thinking I'm going to convey some specific emotion, but getting a sense of the painting, right? And feeling it as a human and simulating what the human's response is going to be. And humans have this amazing simulation capacity where they can take an unfinished product and sort of imagine the next paint stroke and imagine the next form in it and build something that's deeply evocative of a really complex set of emotions that they're trying to convey with this form. And I think perhaps one thing that AI could use, it could learn from that, like learning from like how you take the minute forms in a computer rendered scene, right? And make them a little bit more spiritual or psychedelic or awe-inspiring. And I'm not sure that's there yet. I think that, you know, somebody still has to go in and sort of draw the texture. What's amazing is that once you draw the texture, the AI can just render it across the whole image, right? Stuff like that. I don't know if you're going to get that lighting right, but I think there could be ways to sort of optimize that, but really focus on taking aspects that might otherwise be ignored and making them more intense or pronounced, I think that'd be really interesting. Would you consider that, and I don't have an answer to this because I think I know what I feel, but would you consider something like that? Is that art at that point, right? Is that a human using a different tool instead of a brush using a computer?
I feel like in my totally non-scientific observations of just browsing the internet, people tend to, or bitter people, I guess, get angry when something is called art, but looks like it was really easy to do. Like if there's a painter who makes these really cool giant canvases, but it's really they just take a paint can and poke it with a screwdriver in the bottom and let it dangle with the can, like on a rope, which is a real example I've seen. It looks amazing, but the comments were like, he's not an artist. He's not doing anything. And it's just like, I don't know what that part of the brain is, why people reject stuff like that. But if someone, if it comes too easily, it's not necessarily perceived as art. If we're not making those decisions to make the line this long, it's not perceived as art. And what is that? Art is a statement. Art is, I mean, John Cage is, you know, recorded, what, 20 some minutes of silence, and he's an artist. Yeah. And what is that? It's a piece of work, right? Banksy did a shredded piece of paper, you know, and it was art. And I mean, there's just, it's about the statement. What do they want to, what is the thing the artist wants to get across? Is it, you know, I want to make a bold statement about the art community, or I want to make a bold statement about this or that. I think it's all in the, you know, the person that's receiving it, as they say, it's in the eyes of the holder, right? Eyes of the holder, yeah, exactly. You know, it's funny when I was, I was Googling, I wanted to see how many years the Fleischer's predated Disney, because I know Disney used the rotoscoping Snow White and all that stuff. And it turns out they, it was like, they, I think the, the, the rotoscoping patent for exclusivity expired in 1934. And so he had a, he had a good headstart on him, right? But what was so funny to me in Googling that is when, you know, you go to Google, you type anything in, there's like the top questions that they get the most often. And like the number one question was, is rotoscoping cheating? And I was like, this thing's been around, this technique has been around for over a hundred years. Exactly. And it's just so funny to me. It's like, all right, no matter how long the techniques around, there's going to be people still asking those questions and doubting it, I suppose. I'm sure there were famous artists back in the day that had their assistants painting the backdrop and they would paint the main character. Yeah. Right. So it's just another barrier that's being removed to create.
The lab is a global organization that makes something easier that was more difficult before. There's a case to be made that film music right now, a lot of it is sort of repetitive. So if you could just imagine what the film music that would accompany a given scene would be, AI might not actually be in any sense less creative than a lot of film music conductors who are basically just recreating something that already has been made. There was something really cool, another cool thing I saw on the Omniverse site. There's a page dedicated to sort of explaining the USD file format and the benefits and why it's been embraced and employed here. And it contains this gorgeous marbles tech demo with real-time physics rendering a game of a rolling glass marble. And it goes through this immaculately detailed art desk environment. We'll put a link to it in the notes. It's really cool. You've got to see it. But what I was curious about watching that is, do we foresee a world where software is able to simulate human and animal behavior with the same level of authenticity that we can currently simulate physics? What do you think about that? Yeah. First on that, on marbles, that was all done in real time too. Yeah. So there was no rendering time taking place. We actually, when we first showed it, people didn't believe it. So there's a second version, the camera pulls out and you see the guy on his computer controlling it and stuff. And it's like, that was all done in real time. So for those of us that have been in the industry for a while, when that actually came out, the first time that came out, we got calls from icons and pioneers in the industry, which actually led to a panel that we did called Pioneers in the Computer Industry that contacted us and said, holy, you guys are doing stuff that we dreamed about 30 years ago. Who would have thought we'd see real time ray tracing happening on a chip, on a laptop? Unbelievable. And one of the most fun things I ever got to do in my time here so far is to be able to take some of my old friends from those early days and connect them to the group that's doing Omniverse today. And we had like this just open session one afternoon, like an online cocktail party and they got war stories back and forth.
Ten minutes to read an image off of the tape and I'm like, really, wow, you know, and just the stories back and forth and the challenges. And then we all, it kind of came around at the end to be, imagine where we're going to be in another 30 years. So yes, I do think that you will see the ability to be indistinguishable from real life when necessary and that'll be stuff that we want for these virtual worlds and stuff. So I can teleport into a, you know, a, you know, a beautiful fantasy place if I want to, and it's all happening at real time, things like that. Why not? Yeah. Very, very cool. Alan, you and I were going back and forth and you had a really, I can't remember the exact way you phrased it, but it had to do with the AI driven actors. If yeah. Do you remember exactly what your question was? The one thing I didn't write down, I feel like an idiot. Well, I mean, so much of like, of, of where graphics is going is it's not just sculpting an environment, but actually simulating something and creating a kind of physics simulator of the world. And that is the next step to unlocking the human imagination. We want to be able to imagine things and then create them. Right. But I think what's really missing, even once you have a physics simulation is you don't have a social simulation, you know, like a psychological simulation, but what you kind of want is to be able to sketch a character and have that character come alive. You want to be able to create a character from a storyboard and then be able to give it direction, the way you give direction to an actor, you know, when you're entering this scene, do it in a way that, you know, conveys that the character is sad and grieving about this and this, everything, you know, all of our movements are imbued with emotion. Like every, every, the way that we walk, the way that we hold ourselves together, how we sit down, how we sort of move objects around in our vicinity. And of course, our expressions and our voice, and I think actors are brilliant at capturing all of that. And I think that's what really gives characters authenticity and makes us want to empathize with them. Like we see that nuance in emotional behavior and it's what makes us feel like we're in this character's shoes and feel the conflicts. And I think if AI is going to generate characters that have that effect, it needs to be able to capture all of those nuances of how people.
It is designed to help people move through the world and express their emotions. It is designed to help people move through the world and express their emotions. learnings over thousands and thousands of clips and images of that actor in different scenarios, combined with what that actor was to be acting like in that film. So, it wasn't just a young De Niro, it was the character in the film dialed younger through CG, through the acting, incredible work on those things. So, we are seeing it take place, but, you know, will we get to the point where you can just sit down on a blank canvas and say, I want this kind of an actor, this kind of an actor? Yeah, it won't be far. I mean, yeah. Go ahead. You still have to have a story. You still have to, you know, have all that kind of stuff and like, wow, what does it do? Nothing. I can't think of anything I want to convey. You have to imagine something that has to come from the human imagination, just unlocking that potential. But I was going to say, another great example is, well, early example is Gollum from Lord of the Rings, where they spent a lot of time kind of transmuting the actor's expressions onto Gollum. But they did it in a way that really brought life to this kind of early 3D rendering that I think was just so incredibly immersive for people. Lots of great stuff going on and has been for a while.
And when you become such a tool in the mix, you're focused on the movie, not on how it's done. The same way you listen to a song, you don't go, oh, is that a cello or is that a violin? It's like, you're engulfed in that experience. Speaking to the opening up and the imagination and sort of having this limitless world where you can create and create all these images. One of the things, and we talked about this in other episodes this season, but when you get into the conversation about the metaverse and these new virtual gathering places where there's the ability to resemble anything, to be anything, and watching the marbles demo, as gorgeous as it was, I was like, the play field for that demo, it could literally be anything. So I'm curious why choose such a detailed and perfect recreation of an existing and familiar physical world, the artist's desk with all those great details. I was just curious about the artistic decision to recreate something familiar as opposed to fantastical and any other kind of environment. Because familiar is harder. If it's something you've seen already and you're familiar with, you're going to see imperfections. If it's something fantasy driven and something you've never seen, you'll be a lot more forgiving. And I think they stepped up to the challenge because, well, a number of the folks on the team liked the game marbles and so it kind of evolved out of that or Rubik's Cube, Rubik's things, and they talked about different scenarios to do. But the thing that I think really made it that they stepped up to the challenge is people have seen it. They've experienced it. So if we get it wrong, it'll stick out. And you know, it'll be like, well, something's not right about that. I can't put my finger on it. But they did it right. And as somebody that gets to talk about their work and showcase their work, you know, it really was one of those times in the history of computer graphics where we will look and say that was a moment. Because everybody looked at that and went, how long did that take to render? Wow. You know, it's like, well, how long is it playing? Yeah. It was just mind boggling. Yeah, it really is. And you mentioned this as well earlier, getting the public to adopt.
AI, VR, and the metaverse, etc. Is democratizing the content creation part of it? You mentioned, you know, LiDAR on the phones and now you have open source software like Blender. There's no price barrier there. Anyone can download and render. So I'm curious how long you think, because you go see a movie now like Spider-Man and the credits roll and you got four to five columns, 25 names each for multiple animation studios. The credits, always pay for the credits. A lot of people work really, really hard on that. Absolutely. All my kids, every time you go to the movies, watch the credits. Absolutely. Put their name there. So to that end, how long till that list gets shorter and shorter? What other tools need to exist before we see a single individual artist able to produce the same kind of effects? Well, that's such a huge question, because, you know, in something like the Spider-Man or the Avengers and stuff, where you literally had thousands of people working on it and, you know, hundreds of locations and all of that, and the grandeur of that, those scenes, you know, that takes a lot. That takes a lot of people to work on it. But, you know, there's films that can be made. There's films that have been made with just a few people and stuff. But to that level of things, I don't think we're close to that yet. There's a lot that goes on there. But the cool thing is, is a lot of the power that those things require used to require you to have that data center in your facility. And you needed to have time on that data center. And so more and more that's moving to the cloud, where you'll just be able to rent time on the cloud and say, you know, I want an hour's worth of 10,000 GPUs to try this project out or something like that. You would have never had, you know, couldn't even comprehend something like that a short time ago. So we will start to see, you know, enormous capabilities in the hands of creators. And I just I love to think, you know, I mean, we're thinking in a traditional sense, that traditional big, grandiose picture. But what happened to those that are thinking in a completely different sense and have that amount of power? What are they going to do with it? We don't know yet. Yeah, I'm sure something's going to be done out there. I know you can't reveal too much or pull the curtain too far back. But what what are some things because we're coming in the homestretch and I always love.
I'm here with Sean Miller, one of the founders of the Equity Lab. Welcome to the show. Thank you for having me. I'm Sean Miller. I'm the co-founder of the Equity Lab, and I'm here to talk about some of the exciting things that we're doing here at the University of Minnesota. So, Sean, I'm going to start with you. What's the future? I'm going to start with you, Sean. What's the future of the Earth? I love to talk about the future. I'm going to start with you, Sean. What's the future of the Earth? What's the future of the Earth? I love to just kind of blue sky and talk about the future with all the amazing stuff you can currently do. What's something, what's the 30 year equivalent, right? been undertaken by the company, building a supercomputer to accurately have a digital twin of the Earth and be able to use it to not only understand climate change and things like that, but to almost have it and understand it in a time machine sense. So what happened to get us to this point? So turn back time, what would it be like if we don't do anything with these emissions and stuff and be able to have that kind of power on a global scale? I think that's going to be, to me, the next big thing that's going to be just, and it's amazing watching the team started to bring it together and all of that kind of stuff. So yeah, I think that's, it's hard for the mind to comprehend. Yeah. That's massive. That's a huge deal. I was thinking like, you know, within the context of the entertainment industry and those confines, but I mean, the global implications of something like that is pretty mind boggling. We're going to go on location. Oh, well, let's just spend some time on the digital twin and we'll go shoot this in Africa. You know, who knows? There's going to be all sorts of things that we're... That's just it. You pair that with something like the volume, right? Where right now, as my understanding of it is they have to create all the different sets for still digitally, you have to create them before they can load them into the volume and then move them around. But like if you had a digital twin of Earth, you could literally, in the same way that we use Google Earth to kind of look around, you could just pull it up as your set, as your location on your stage, on your soundstage. Wild. Alan, what are some things that you're really excited about, man? That's a tough act to follow. That opens up a lot. I hadn't thought of that. I was thinking more in the direction of unlocking the imaginative universe that, you know, unlocking the ability of people to create 3D worlds that evoke emotion, that are immersive, that maybe even personalized for specific people. And so, you know...
Maybe for myself, I'm more into the mild horror movies, the psychological ones. Some people are into the really intense ones. What if the same movie could be manipulated on that scale, just all automatically by an AI, and calibrated for specific people's tastes? I think that would be really amazing. You asked about, are these lists of credits going to get shorter? And I hope they don't. I hope that movies just get more ambitious. What they're doing just completely would blow our mind today in 30 years, and still requires that same number of people. But each person is doing a thousand times more work because of AI. I think that would be an incredible thing to see. Yeah, that does sound incredible, man. God, I say it every week, but I do, I truly mean it. I'm really bummed we're out of time. Before we get out of here, of course, a monumental thank you to Richard Kares. Richard, I have an infinite supply of questions for you, sir, and I recognize how exhausting I can be. So thank you for being here. It's been fun to be here. I'll hold you to it, man. It means a lot that you're here. Thank you so, so much. Sure thing. Alan, a pleasure as always. I wouldn't be here without you, man. I had a lot of fun tonight, and I appreciate you spending your time on the show with me and the gang as well. This was great. Really, really good time. A big old thank you to you, once again. That's right. You, our viewers and listeners, as long as you keep showing up, I promise, so will we. If there's a follow-up question I missed or a thing you hope we get deeper into, let us know. Shoot us your own questions over at thefeelingslabathume.ai. We'll put it right down here on the bottom of the screen. If you're listening, it's T-H-E-F-E-E-L-I-N-G-S-L-A-B-A-T-H-U-E-M-E-DOT-A-I. It's very easy to do. And provided I don't forget to check the inbox or accidentally mark you as spam, there's a really good chance we'll answer it. So go ahead, send us something. That's going to do it for now, my friends. Farewell from the Feelings Lab. I'm Matt Forte. Thanks again, everybody. And please, stay safe out there.
, , , , , , , , , , , ,
