Hello, world, what is up? Welcome back to the Feelings Lab. I'm your host, Matt Forte. And on today's episode, we're talking trust and safety in online conversations. Let's go back a minute. Take this journey with me, will you? 53 years ago, Professor Len Kleinrock and his team of graduate students at UCLA send the letters LO as the very first message via computer network. Apparently, it was supposed to say login, but the network crashed before it could finish sending. So lo and behold, lo it is. There you go. History's made. Fast forward 23 years. Now it's 1992. British engineer Neil Papworth sends the first SMS and writes Merry Christmas. How adorable. Okay, let's jump ahead once more. 30 years later, that's today, present day. On Twitter alone, on average, every second, there are around 6,000 tweets tweeted. That's roughly 350,000 per minute, 500 million in a day, 200 billion tweets per year. That's a lot of tweets. And I'm sure there's more than that, too. Those are just rough numbers, right? Now, as for texts or SMS messages, 6 billion sent every day. 6 billion. All right. And about 4 billion of those have been trying to reach you about your car's extended warranty. The World Wide Web has certainly delivered on the promise set forth by its name. It's connecting everyone, everywhere, all the time, allowing for conversations that span generations, languages, ideologies. Two people who just a couple of decades ago could have lived the entirety of their lives, never knowing either one existed, can now be best friends. Or mortal enemies. It depends. It's a coin flip, really. Now, while it's been thrilling to be alive to witness us fundamentally change the way we communicate as a species, the road thus far has certainly not been without its bumps. I, for one, am not entirely convinced we have a grasp on the true scope of the societal impact present day internet culture will have on us as individuals, so let's not get lost going too far down that rabbit hole.
It is also a research lab that is designed to help you understand the relationship between brands and consumers. Back in the day, all you needed was for Fred Flintstone to say Winston cigarettes were the tastiest money could buy and boom that was it. End of conversation. Done. But nowadays, Nutterbutter is out here tweeting upsetting double entendres and Wendy's and Burger King's twitter rivalry has become the modern day Montague and Capulets of our time. Let that last one sink in because it's both amazing and a huge bummer all at once. Anyway, the point is, as we've evolved the means by which we communicate, so too has the behavior and ways we communicate, introducing a myriad of complexities. Anonymity alone has empowered everyone to really say anything. And thanks to the giant town square that is the internet, one customer's bad experience or negative opinion no longer gets to live and die on an internal use only survey. It can snowball into an entire movement or a boycott even. For better or worse, and believe me, I err on the side of better, the internet has given a voice to the masses, especially those who have historically been voiceless. So how do you navigate all that? How do you engage appropriately? How do you get ahead of controversy? How do you keep your fingers on the pulse so you can strategize appropriately and make the most of your customer interactions? And most importantly of all, how do you do it in an authentic way, right? And for that matter, at scale, because I'm sure if you're a big brand, you've got a couple of million eyeballs on you. So today's guest, I'm sure has a couple of thoughts about how to do exactly that. We'll bring them on in just a minute, but first, the potential for far deeper, more intelligent questions is about to increase exponentially, my friends, because joining me now as always, co-host, compatriot, friend, Dr. Alan Cowan is here. Alan, how are you doing, bud? Doing good. I'm in sunny LA enjoying the summer here. How are you? I'm all right. I'm in equally sunny New York, sweating it out in my attic, but not jealous at all. That sounds wonderful over there. Let's get this show on the rails, man. Today's guest, a lawyer by trade, first recognized the metaphorical minefield brands must navigate now on social media when she came across a case where a brand was sued for harmful comments made on its Facebook page. Flash forward approximately 10 years, and she is the CEO and founder at Brand Bastion, who's...
Its mission is to enable organizations across all industries to create safe conversations and meaningful relationships with their audiences. Their software is being used in 150 countries worldwide and across seven major industries. Brand Bastion has recently won awards such as the Best Use of Conversational AI at this year's Computing AI and Machine Learning Awards. I can't wait to hear her thoughts on today's topic and all these different things. Please welcome to the show, CEO and founder at Brand Bastion, the great Jenny Wolfram is here. Thank you so much for doing this. How are you doing? I'm doing fantastic. Thanks so much for the kind introduction. I'm really excited to be talking about this topic today. It's one of my favorite topics. Well, I'm so thrilled to have you here and I'm looking forward to getting deep into things. Alan's in LA, I'm in New York. Where are you coming from right now? Where are you in the world? Well, usually I would be in LA, but I'm actually currently in Helsinki, Finland. Oh, that's awesome. Fantastic. Wow. Guys, we're really all over the place here. So this is wonderful. All right. Well, I'm excited. Let's dive right in. Before we get too far into the conversation, I love going back in time a little bit, as evidenced in my intro there, but I just like getting a little bit of context. I said founded in 2013. I touched on the cliff notes in my intro, but Jenny, if you'd be so kind, just give us a little bit more about that moment way back when, when you first started to envision the role that Brand Bastion could play in the world and what the company could be. Just give us a little bit of history, please. Yeah, absolutely. So back in 2013, I started researching, I was going through every fortune 500 brand, looking at their Facebook pages. And I saw that the majority of them were getting hundreds, if not thousands of comments across the posts they were making. And people were asking questions. They were giving really valuable feedback. They were also posting, you know, harmful comments. They were spreading spam. They were, you know, bullying each other. And what I saw consistently at the time was that brands, they just didn't have the bandwidth to be able to interact with these comments. So then at the time I was thinking that how, how can brands deal with this? I mean, it requires, you know, a lot of people, a lot of time, a lot of effort. And I reached out to these brands and I was asking them, how are you doing it? And most of them, they were trying to manage it with people. They were trying to manage it with
equations and the truth of the matter is, and was at the time as well, you really need technology to be able to actually interact when there is so many comments coming in across the globe, different time zones, different platforms and so forth. So that was really the thought I had at the time. How can we use technology to help friends address this challenge? And additionally, as well, one of the things we were thinking about was that, you know, social media doesn't have borders. So we really wanted from the start to bring, build something that would be applicable in many languages across the globe. Yeah, amazing. There's a ton in there that we're going to unpack as we go throughout our conversation today. But thank you for giving that little catch up history there and filling us in. You know, I thought it'd be fun in shaping today's conversation. I took a look at the Brand Bastion website, and you guys list right in the main there, the three solutions you kind of outlined. And I thought that'd be a great little format to loosely follow today, tackling safety, care and intelligence, as it were. And so to that end, we'll start with safety. And I'd love to get both of your thoughts, Alan, too, as well on this. When we talk about keeping a brand safe or maintaining safety within a conversation or in a conversation online, just in this context, I'd love to get a better understanding, just not myself, but for our listeners, what we mean when we're saying safety and how we say safe in this context. Alan, you seem to be the one. Let's go with you first. What do you think? I'm happy to take over here. Yeah, no, I've been involved in some of these conversations at social media companies, search engines, and safety is sort of one of the bedrock principles of how you monitor conversations online, how you have productive conversations online, which is obviously so important. And I think your intro really speaks to the fact that this is an era where we can have a free flowing democracy of ideas. And then there's the possibility of subverting that violence coming in, of hate speech coming in. And you want to remove all of that. And I think the bedrock principle of having a productive conversation is everybody needs to feel physically, emotionally safe and be able to have free speech. So it's so important. And I think the threats to that are things like threats of violence, hate speech, toxicity, bullying, harassment.
Jenny, your thoughts. What does it mean to you when we're going to be safe online? Yeah, from a brand perspective, Edelman's Trust Barometer for 2022 shows that 58 percent of consumers, they will buy or advocate for a brand based on their beliefs and values. So consumers, they really expect brands to take a stance on different topics they care about, but also to take action to support their stance. And people, they really associate comments on a brand's social media accounts with the brand itself. And if a brand allows certain things to remain visible, it's often seen as a reflection of that brand's values. So, for example, if a brand is doing a big push to support Pride Month, but then they're leaving homophobic comments visible, then that will really make consumers and the audience feel like they're not serious about the topic. So I think brand safety is a lot about enforcing your values consistently across your social media posts and assets, making sure to remove any kind of content that is contradictory or in direct conflict with these values. I think another important element, it's not only about taking action to remove harmful content. It's also about having alerts in place so that when things happen across your social media.
Essentially, это способ расширения времени или защитить ваша марка. I really want to dig into the idea of removing content and knowing when one of the big things that I was curious about coming into today is gauging and knowing when to engage and how to engage, because my gut says when you're dealing with negativity online, it's always like, well, don't feed the trolls, right, don't respond to leave them alone. Don't give them the intention they so desperately crave. But there are times where left unacknowledged could be a bigger mistake than diving in and engaging. How do you, you know, did you guys, is that something you figured out over time? Is that part of the very core foundation of what you do? How do you know when to engage, when not to engage? And has that been a learning process along the way for you guys? Yeah, that's really a core part of what we do is identifying the situations when it makes sense for a brand to take action and when it doesn't. And it's a clear fact that not everyone will like your brand and that's to be expected. And it's also can be beneficial and authentic to allow for people to as well express their negative opinions and perhaps to respond to them at times, but also at times to just leave it out there. But I think the key thing here is to to really set up a strategy in terms of what you allow as a brand, what you don't and what you want to address and what you don't want to address. So some of the things that we always start with when we start with a new client is really diving into all the engagement and then having a conversation with the brand to to see what their values are and how they want to interact. And then granular categories. That's super important. So we have over 100 different types of categories going from like constructive, negative feedback to, you know, a customer care complaint about, you know, delivery. So there really needs to be a lot of granularity. And then I think the essence is that if someone is making a comment with the intention of causing another user harm, then it's something that you always have to hide and take action upon. Whilst if the comment is from a user that is experiencing a problem, needs help, then, of course, you need to give that person.
It is also about having empathy and really making sure to look and address each comment as a comment on its own and looking at the context as well. One of the things that piques my curiosity, and this was also on my list, you mentioned the categorization of the type of comment, the level of intensity, and the taxonomy of toxic things, if you will. Did you give a number there about how many? You said over a hundred? How many categories? Yeah, we have over a hundred different categories. Yeah. And it also depends a lot about the industry and the vertical the client is in. Now, is that a living list? Like when you started 10 years ago, did you have over a hundred or has it grown over time? You're like, well, that's a new terrible thing. Let's put it on the list. Yeah, it's definitely grown over time. Bummer, but also very cool. Okay, so you've got this massive list. And if I ask anything at any point that is asking you to pull the curtain too far back or you can't disclose, you just let me know. It's not a big deal. We're not live. We can work around that. But I'm super curious about, off the top of your head, of that hundreds of items, what's hanging out in the top 10 or top five? What are the most common toxic or negative things that you guys encounter or see a lot of most frequently? Yeah, I think during especially the pandemic, there were a lot of new, extremely sophisticated scams going around on social. One of them that quite many of our clients saw was where someone would set up an account and pretend to be an employee working for the brand or pretend to be a customer service handle for the brand, where they would offer support to a user, stepping in or giving advice, which then was just the opening of a more elaborate scam. That's something that we saw quite a bit of. And also, I think just with the pandemic and a lot of people struggling with different challenges in their life, there was, of course, a rise in mental health challenges. And that was also reflected on social media, where we did see an increase in just toxic comments or comments that were being extremely hateful.
I'm curious, when we talk about those over 100 categories, is that limited to toxic interactions or does stuff like spam and porn and phishing scams and all that noise, does that fall within those 100 categories? Or are the 100 categories limited to human responses or something I'd associate more with like an attack? Yeah, it just covers the whole spectrum. So there's everything. Yeah. And then we also have, of course, we also have a lot of topical categories because quite often we need that context so that it would have both a topical tag, a specific comment, but also then a category-specific tag depending on if it's harmful or if it's a customer engagement category. That almost feels like you talk about the topical categories, it's a living list, like that's a full-time job in and of itself is just keeping an eye on that and maintaining that. New scams constantly popping up like the ones you mentioned just there. Did you guys, when the company was founded, did you put a mechanism in place to remain agile? Like you knew even 10 years ago, you knew that things were not done growing, so you'd have to be able to stay on top of that and ahead of that. Is that just a whole team that you guys have just keeping their eyes on the terrible things that are happening on the internet? Yeah, I mean that is the kind of bread and butter of what we do, our content classification on social media. So we actually have a really big team of humans that are classifying content around the clock. So we have over 100 humans going through content and that's also how we're consistently making sure that our training data that we use for our AI is up to date because the language is changing, new things pop up all the time. So it really is an ongoing process. We're getting into the fun nitty-gritty stuff. So the humans are part of it.
The humans, they're the best at identifying the new things and spotting the new things. And then once your humans identify that, and I understand that I'm oversimplifying to a great degree, but we'll say the humans identify the new things. That's when the AI steps in to then detect the things the humans found. Am I following that? Is that correct-ish? Right? Yeah. So there's a few different things that play as part of this whole process. So one part of it is of course the training data that we feed to our AI. And there we need humans to accurately tag the data. So that's why we built these huge databases of tagged content. But then another part of it is that there are certain things that just AI in general has a really hard time, as you know, being able to identify. And some of the biggest challenges we have there is of course, context, it's modality, it's referentiality, and it's sarcasm. So there as well, we use a combination where first the comments are run by our AI. And then if the AI doesn't have high enough confidence in these types of situations, then there is a human or several humans that will then kind of weigh in. And ultimately, we can then use that data for training purposes. And then we also have a lot of quality assurance in place because of course, everything on social media is public. So we need to make sure that we maintain the highest possible accuracy at all times when we take actions. So there's a lot of different parts, but ultimately, all the time, it's AI and humans working very closely together. And that's really what we believe is essential to be able to do this well. Yeah, we hear that a lot, especially in the conversations we're having. Alan, and I've asked you a version of this many times in this show's run now, but why is that? Why is the AI hitting a wall? What is the AI struggling with? And why is it struggling with it? And Jenny kind of answered that, but I love when you get deep in the weeds on this for me. And then once you give me that, I want to know, I'll have some follow-ups, but let's start there for the beginning, getting deeper into it. Why do we need the humans? What's going on? I think Jenny hit on a lot of those points, which is, when you have...
I have things like sarcasm. It's a real challenge to build an algorithm that understands that, because it's so contextual. The earliest algorithms to detect things like hate speech and toxicity were basically detecting certain words, like swear words. They were detecting references to ethnicities, that sort of thing, and then feeding that to human moderators. Human moderators had this massive pile of things to go through. As the algorithms have gotten better, and they're still nowhere near human performance, but as they've gotten better, the human moderators have less to do because they've filtered out all the things that definitely aren't toxic, that have good intent behind them and so forth, and narrowed it down to things that are much more likely to be toxic. They can even increase the threshold and say, all right, well, let's take more of those edge cases and have humans look at them. We wouldn't have been able to consider these before, because then we would have just had too many things to moderate. But now we can get more precise. The algorithms are getting better with large language models. I'm curious, for Jenny, how you're incorporating the newest advances in large language models. There's been huge progress in exactly this, taking the context of a conversation and using it to inform predictions as to whether something is hate speech or not. I mean, those are some of the advances. I mean, it's seen a continued increase, right? I think with large language models, also, there's a huge opportunity to advance dialogue systems. Right now, you can emulate how a human would speak, but the interaction between two people, that's something that's still moving forward, too. So that's another thing I'm curious if that's being advanced. Great questions. I don't know. I'm going to let the expert answer that one for you. Yeah. I also was thinking that I could bring forward a couple of concrete examples of when this is a challenge. So when we think about especially the way people speak, if it's an older kind of family man saying this is sick, it's going to have a completely different meaning than if it's a teenager saying this is sick. Or if you.
You use a puking emoji on a fast food chain's Facebook post, it's going to have another meaning than if you use that on a sneaker brand, you know, Instagram or TikTok. Because this is sick means of course for a sneaker brand that it's a really good thing, whilst for a fast food chain you don't want that there and it doesn't mean a good thing. So there's all this kind of nuance. Also, if you're a company operating in the cryptocurrency space, if people are posting across your social media assets, cryptocurrency investment tips, it's going to be completely different than if that's being posted across, you know, an entertainment company where it's most likely going to be spam or scam. So there's a lot of nuance depending on the brand, the audience, the vertical as well to take into account, which is why it's very difficult also for social media platforms to really roll out a one fits all model. And the way people speak, for example, on a war games, social media accounts, it's going to be completely different than a, you know, a brand that is targeting, you know, young mothers. So there is a lot of context to be taken into account as well when talking about brand safety. Fascinated by how siloed everything can be in the, just the puke emoji example is so strong because it really illustrates perfectly how that can be interpreted in two totally different ways. One of the things I was super, and Alan, did you have any follow-ups before I take us off on another tangent? I just want to make sure I don't steamroll you on your ideas because you're the smart one. No, I mean, it's so interesting that all of this comes into play with safety alone, right? And that's sort of the bedrock of like, let's take out the toxic stuff, the stuff with bad intent. But I'm sure it's even more complicated when things are written with good intent and you're trying to establish sort of, what are the principles that you want to embed in this AI or even a human agent that's going to respond? Because you want to facilitate a conversation between, you know, tens of thousands of people, millions of customers potentially, and a sort of single organization that's being embodied in a single conversational agent. Or, you know, so how do you kind of encode those bedrock principles of context into the
I'm really curious about that. Yeah, that's such an important topic and it's something that we've been thinking a lot about. And it's also something that we from the start, we've really been involving our clients actively in these conversations as well as the platforms at large. But there are many situations that also just in a sense remain as a challenge. Like one that we've had numerous discussions with our clients that are in the clothing industry or in e-commerce with is that certain brands, they feel that if someone posts a comment saying, for example, made in a certain country, that should, that's negative comments or that could be even a brand critique. And then the question of, well, which countries are then, you know, positive countries to be made and negative countries to be made. And it very quickly becomes a very loaded question. And those are the kind of things that obviously we have to very much think about when we're training AI and when we're, you know, discussing with brands and so forth. That's an example of something that, you know, comes up and it's very important to address from like many different angles. Playing off that idea of sort of encoding those bedrock principles, it taps into something I was really curious about is not just the principles, but the personality, the tone and tenor. Every brand, historically, their voice and how they speak to their customers is very important. Be it through their print ads, their television ads or whatever, or now more directly through their social media. And, you know, you guys, one of the things you do, you come in, you not just identify all this stuff, but you help respond on behalf of those brands you come in. And I would imagine, just pulling two that were on the site, like NARS Cosmetics and Netflix are going to have two very different voices, different personalities and how they address their customers. Is that another thing where, where like the human role is all the more important or can you, can you get that into the AI? How do you guys account for that?
How do you embody the character, not just the principles, but the voice, the tone, the tenor, so that way they know, or at least the customer or the client feels, oh, I'm talking to Netflix. I'm talking to NARS. This is not somebody on their behalf. Yeah, absolutely. I mean, most brands are nowadays, they're expected more and more to act like humans. They're expected to have opinions. They're expected to have a very distinct voice. So, when we start with a client, understanding the conversations the brand is receiving and looking at historical ways they've been engaging is essential. And then ultimately, what our system will do is to pull in all those conversations and organize it based on topics, looking at what people are asking, what are the key questions the brand is receiving and so forth. The brand would set up up to 30 to 50 variations of a response per specific category. That way, it is the brand that is defining the voice they want to apply. Then basically, we're using then our technology to be able to identify comments that fit into, for example, is it a customer complaint? Is it a fan community? What is it about? Also, to be able to prioritize what has higher urgency and what has lower urgency at scale. But then ultimately, we have humans as well very closely involved. And we also have a human verify every response before it goes out just to make sure that we're not responding to sarcasm. We're not responding to comments that may have some kind of hidden meaning. So, we're not as everything that we're responding is public. We do also have solutions for direct messages or private messages. But most of the time, we're doing public responding, which really means that it has to be extremely accurate. And that requires that combination of technology and humans. Yeah. So interesting, because you're right. People do, especially because of social media, the very nature of it, you expect to communicate with Nike in the same way that you communicate with your friends. And so, there's a person and it's like back in the day, a brand had a mascot. So, that way, when you think...
You thought of the brand, you thought of the mascot, you had the Marlboro man, you had, I don't know why I keep choosing cigarette brands, I know other things. But they have the most impactful mascots, I guess, from back in the day. But like, but now that's less of a thing. It's more about finding your voice and be, Alan, the psychology behind that of why we need to associate this multinational conglomerate with a person. Why don't we think of it as a big entity? Why do we need to think of it as an individual? Do you have any thoughts around that or how that changes the way we communicate and things like that with them? You know, I think that there's a real advantage to that, which is if you can talk to an organization, you can potentially be heard, right? You can actually say, this is my feedback, this is my sentiment, and the organization can respond. And, you know, sometimes it will be to help you. And you can have a, you know, you might want to call Verizon and ask why, you know, something is going wrong with your plan. Or you might want to call the brand, call the organization, it could be a governing body, and actually be able to get information out of it. And the more conversationally that's done, the smoother that experience is going to be. And I think that's the direction we're headed. Particularly with AI, you can now actually have a conversation with an organization, a governing body, a brand, and get real help in response. The other thing I'm sort of curious about, and this I think would be really interesting, is if when users are talking to the brand, are we able to deliver that feedback, their sentiments, to the organization in a way that informs their decision making? Is it a two way conversation? And where's the progress there? And where do we see that going? Yeah, really, really great question. Yeah, I think there are so many examples we have where our clients have been able to even launch new products or launch new features and functionality based on social media conversations. So a big part of what we do is not only issuing responses on behalf of the brands to make sure issues are resolved, but also taking all that feedback and aggregating it and showing brands what people are saying. And we've seen this also very impactful on the advertising and on the marketing.
Right? Then the perception becomes, why am I even talking to them? They don't hear me. There's no point. I'm just screaming into a void. So they have to react to form that bond. Otherwise, they're walling themselves off from the community. And I'm listening to this and I'm like, why do focus groups even exist? Why do customer surveys even exist? You're going to get a more authentic response from what people are just organically saying and doing. And that ties into just bringing it full circle to the three supports, the intelligence part, where you guys help brands strategize and stuff. When you have all of that data, and keep me honest here, but it's unsolicited in that you're just really reading the tea leaves. You're telling them what the community is saying and analyzing that. You're not soliciting feedback, right? You're not sending out surveys and things of that nature. You're just looking at what they're giving you, which is their organic responses. Is that right? Or am I wrong? Is there some survey work in there or something? There's no survey work involved. It's just, yeah. Yeah. That's crazy. So that's so cool to me because that's the holy grail, isn't it? This is what people are just of their own volition, saying, doing, behaving, thinking, and then you guys kind of collect all of that and help them be agile and help them figure out how to use that data.
Yes, absolutely. Jeez. How many people on that team? Cause I was reading, um, I mean, I'm, I'm a half serious with that. I know you can't give me a number, but the reason I brought that up and I was thinking about that is cause you wrote, um, I forget how long ago you wrote. It was a piece that you wrote Jenny for entrepreneur.com about counterfeit fashion accounts on Instagram. And the numbers in that piece blew my mind. You looked at, uh, I wrote them down the 12 top luxury brand accounts and you found 729 comments leading to direct counterfeiting found over a thousand comments that were spam and scams. And then 208 comments that were direct attacks, launching boycotts. And I was like, well, first of all, it's cool that you can pull all that data. But second of all, how do you even begin to combat something like that as a brand? How do you push back on something that to me feels like such a complex, like tapestry of, of negativity and people organized, but the sole intent of undermining the reason those companies exist is getting their stuff for free or leeching their, how do you push back with numbers like that, which I know when you're talking about millions of followers, a thousand comments, isn't that big of a deal, but they, the impact could be huge. Absolutely. Yeah. The impact can be huge. People nowadays, I mean, they use social both for like search and also for discovery where they're actively, if they're looking to buy from a specific luxury brand, they're going into their Instagram, they're going into their TikTok, they're looking at the comments, they're looking at what other people are saying and so forth. So one of the key things that they, these kinds of brands need to make sure of is that they're that it isn't a breeding ground for counterfeit sellers. If Chanel had outside their, you know, their store on Fifth Avenue, a lot of people that were selling fake handbags. I mean, they would go make sure that that wouldn't be taking place, but that's still taking place often on social media. So I think really cutting the distribution channel, making sure you're, you have active moderation in place is key for that part. And then when I think when it comes to the boycotts, I think that's something that is one of the great things I think about social media, where.
Really, consumers can get together and they can be heard. So here, I think for brands, it's important to really listen and really understand like, what is what is the challenge? What are people saying? What do consumers want? And then taking action and then making sure that they communicate the action they've taken. And here we have also seen quite a lot, especially in the luxury space, that there is also campaigns spreading, for example, false information. But we have seen that when brands take an approach where they are responding to this, these kind of accusations, responding to it one on one, it can very quickly as well turn around and people get the right information and and so forth. So it's really about just having a strategy in place, making sure that you are paying attention and then taking action. And then one of the things as well I wanted to mention is just this kind of broken windows syndrome that we see so often on social media, which also goes back to the comments you made about surveys, which is that when people are spreading, you know, harmful content on a brand's account, when they're being extremely negative, we've seen that other people are much more likely to join in and become negative and spread harmful content. So it's really feeding. It's really feeding. The comments are feeding each other like a snowball effect, which really means that when you come in early and you actually actively moderate a conversation, it will essentially just become better for all parties involved. So funny. I was thinking about Alan, when we were talking to Dacher and we were talking about how are things really bad now or do I just think they're really bad now because I see so much news about how bad it is? Like and so I started to wonder, is this a similar thing where are there more mean people on the Internet? Or can I just hear all the mean people? Is that what it is? And that's really interesting to hear the talk about the broken window syndrome. Yeah. You know, do you think the Internet has actually made some people be more mean as well? It sounds like it has in some instances. There's definitely been effects of how algorithms are upregulating certain aspects of conversation that people are picking up on actively. They're saying, well, I'm more likely to get likes if I do this, whether it's conscious or subconscious.
For Twitter, it is controversial, it gets people a little bit angry, people will comment on it, people will reply. It gets the conversation going. I think the challenge for responding to that is how do you surface the response or how do you surface the message that you want to reply with. You hear the anger, you know why they are angry, these are the things they are doing about it so that it actually appears in tandem with the angry comment. I don't think that there's really much of a way of doing that right now, so that's probably one of the big challenges. But yes, no, I do think people that certain emotional tenors do get kind of rewarded by social media, by the way that online conversations are being moderated, and we need to do something about that. Yeah, what, how do we fix that for me, because it is just the worst. If you could just make it only better, if you could do that, I'd appreciate that. I mean, yeah, within these sort of algorithms that are sort of moderating these conversations at the initial level. Right now they're being optimized for engagement to some extent, and they're also being corrected so that they don't to too much upregulate hate speech and toxic forms of conversation. There's a lot being done there. But still, fundamentally, the algorithm is saying, this is something that people want to see. And I know this because they're liking it, because they're commenting. And that can easily be exploited, because trolls are really good at making people outraged, and then they like it or comment on it, it generates a conversation that suddenly that's jumping to the top of your newsfeed. And so it really needs to be embedded in the algorithm, the sense of like, why are people paying attention to this? Is it just because it's making people angry, in which case, you know, that should be appropriately downregulated. So you need to understand, you need to predict what the emotional tenor is, how people are responding emotionally. And I think when you're in an organization that's sort of operating within these mediums and trying to play by their rules, but also be able to mitigate
The lab is a place where we can create and replicate some of those effects, kind of the same thing. If you understand why something is going to be upregulated, you can sort of model that and you can embed a response that sort of adjusts the user's emotions, the consumer's emotions, when they see that comment and speaks to those. This may be a question with no answer or a good question. Is this a losing battle insofar as we have all the technology in the world, but humans just for whatever reason respond more viscerally to the negative thing, even though we all prefer to experience the positive thing, you can't ignore that the negative thing gets more attention. Are we fighting something that's cultural, societal, or is technology, could it help us nudge in the other direction? And again, we may not have an answer, but I'm just curious if you have any thoughts about that. Well, I think you're exactly right. If you're just optimizing for attention, then that engenders these issues. But if you're considering other things, like if you're saying, well, I'm not just going to, I mean, attention is important, engagement is important. I'm not going to say that that's not important to optimize for at some level, but you should also be considering people's wellbeing. You should also be considering whether this person who's reading this is angry in a nonproductive way for the next couple of days. That's not a good response that you want to encourage, even if that's what's driving engagement and attention. Even if you understand, if you can sort of take apart what that engagement is being driven by and optimize for good engagement and good attention and people's good feelings, I think that that's a solution to this problem. But you need to be able to master those things, of course. What I heard is monetize people's wellbeing. Too late. That's what the answer is. Okay. We're coming in the home stretch. Believe it or not, this is flown by. But, you know, one of the things I like to do towards the end, and also let's go ahead and turn this ship around. I'm talking about all this negative stuff. Let's do one of my favorite things to do, which is look ahead and blue sky. Talk about what we hope to see coming ahead, coming down the road.
on the road and how we envision the near to immediate future. So, let's start. Jenny, I'll come back to you. We spent a lot of time talking about what you guys are currently doing, what you're working on. You're celebrating next year, your 10 year anniversary. 2023 is 10 years since you've been founded. What are the types of things, again, without giving away, as I like to say, the 11 urban spices and spoiling any industry secrets, what are the things that you're excited for, that you're looking ahead, that you guys are working on? The thing that's going to take it to the next level, give us a little bit of that blue sky, perfect world. What's the best next five years look like? What do you think? Well, there's so much going on in the space of social media. So, we're really excited about really just helping brands have the best possible conversations at scale and looking as well at the increased competition. There's new brands popping up daily. I think the whole how important comments are and how important user reviews are, it's really increasing importance. And I think also people are thirsty for empathy. They're thirsty for brands to really show their values, to take action. So, it's such a great time right now for brands that are active on social media and for brands that have a social first kind of strategy. So, we're developing tons of new functionality on our platform, really focusing on expanding to as many different platforms as possible. We're also really excited about helping brands really push as well conversations from the public domain to the private domain to have longer, further conversations with their users. And in general, we're excited to expand, looking to have bigger impact, work with more brands, more platforms. And we're growing our team on three different continents. So, in that sense, we're excited for the growth. Thank you. That's awesome. You know, we've talked a ton about text analysis and emoji analysis and things of that nature. I know this is a completely different beast. Alan, you guys have done audio and video analysis in regards for emotion science. Jenny, has anyone over at the Brand Bastion office been like, hey, should we look at video?
I'm curious, is that on the map at all, or is it just a completely different beast, and you'd have to build out a whole different infrastructure? Any thoughts on video analysis and platforms like TikTok and things of that nature? Conversations there? Is that happening? Are you thinking about that at all? Yeah, we are thinking about it, and it's definitely on our radar, but as of this moment, we're mostly focused on the tech side. Yeah. Well, I'd imagine it's a completely different tool set, right? There may be some overlap, but it's almost like from a ground up kind of thing. You know what? Last question, because I mentioned your 10-year anniversary coming up. Let's do a fun one. Biggest difference between when you guys first started 10 years ago and where you are 10 years now. People, companies, anything changes a lot over a decade, and it's hard to feel that year to year. So if you look back on day one and you look at now, what's the biggest difference other than the amount of people or whatever? Yeah, well, I think if any one of us would go back and look at what we posted on Facebook 10 years ago, it's going to be probably very different, hopefully very different to what we're doing today on social media. So there's been a huge, of course, shift in how consumers interact and how people are using social media. There's also much higher consumer expectations today than what was the case 10 years ago. There's also a lot more competition amongst brands and really a bigger need to do well on social. There's also more social media platforms as well to take into account and a lot more happening in the world, of course, as we've seen during the past couple of years. And from a company perspective, I mean, we, of course, have a lot more solutions today than what we had back in the day. We also have over a thousand accounts as clients, but then we also do have some of the same clients that we had as well 10 years ago, which is fun. But yeah, I think, I mean, in looking at just the space we're in, I mean, things changed so much. So it really is. That's a hell of a feather in the cap to have clients stick with you for over a decade. That's amazing, especially in the line of work that you guys are doing. That's kudos to you. That's really cool. That's amazing. Thank you. 
All right, I got to wrap things up. Before I get into the intro here, Alan, anything you want to contribute or say before I say goodbye to everybody and thank everyone for being here? No, I mean, I think this is super exciting. The idea of giving a voice to an organization so that people can talk with it is really the way of the future. And of course, you mentioned going into beyond text, going to voice and video. If you really, really speak to people and make them feel like they're being heard. We've had many conversations about this on the show that, you know, if you can talk to a person that's embodied, that's really helpful. But even just talking to, you know, through text, I think there's there's an amazing opportunity to sort of advance the democracy of ideas, to have organizations be more receptive to feedback and to kind of build. You know, we right now we think of perhaps some people think of kind of brand personalities as being inauthentic, but it doesn't need to be that way. And I think we're correcting that. I think that work is really important, because if we can think of brands personalities as being authentic and receptive and conversational, we can actually, you know, kind of drive improvements and the feedback channels and how those conversations are had. For sure. And Alan, am I misconstruing the work that you guys have done when I talk about audio and video analysis? Because I feel like you do detect similar things that we've been discussing today via text, right? I'm not because I'm not a scientist. Everybody that listens to the show knows that I get lucky most of the time. I don't really know what I'm talking about, but it is similar. There is an overlap in what you guys have been doing. Right. There's certainly an overlap. I mean, we do the kind of basic like let's let's deconstruct this sentence. I mean, we don't look at the semantics because that's kind of being solved by large language models. But what is the kind of hidden emotional intonation? Is there toxicity going on? We do a lot of that. And, you know, taking that and making it multimodal, it's really important to be able to consider what's going on in the language at the same time that you're looking at the way it's being said in terms of their voice and facial expression and body and all of that. So it's yeah, it's really core to what we do. Nice. Well, I'll never miss an opportunity to ask a brilliant person to tell me I'm right. I hate to say we got to wrap it up. Unfortunately, we are out of time. Jenny, before we get out of here, a monumental thank you once again for just taking the time to hang out with us.
Feelings Lab is produced by Hume AI, a research lab and technology company. So I hope you enjoyed today's conversation and that you come back around for another one soon. And hey, if you're a longtime listener and you feel strongly about the relationship you formed by consuming our humble podcast and are ready to take things to the next level, I'm here waving you in. Do it. Send us an email. All right. Ask us a question. Let's get you on the air. I'm sure whatever you got, it's good. And if I'm right, believe it or not, sometimes I am, we'll answer it as part of our next listener questions episode, which is coming up soon. So hurry up. There's still time. So ask us something and send it this way to the Feelings Lab at Hume.AI. That's T-H-E-F-E-E-L-I-N-G-S-L-A-B at, you know, the last squiggly, Hume, H-U-M-E, dot the period, not the word dot, and the letters A-I. That's going to do it. Farewell for now from all of us at the Feelings Lab. I'm Matt Forte. Thanks again, everybody. And please stay safe out there.
