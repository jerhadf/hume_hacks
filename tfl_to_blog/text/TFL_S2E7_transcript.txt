Hello, world. What is up? Welcome back to the Feelings Lab. I'm your host, Matt Forte. And for today's episode, we're talking about empathy and augmented reality. This here marks the seventh episode of season two, which measured in podcast years puts us somewhere between infant and slightly larger infant. But still, it's deep enough in that certain patterns and reoccurring themes are presenting themselves more and more, which led to today's topic. Be it the digital people at sew machines or Moxie, the companion robot for children, or the secret sauce behind Talkify that makes them so good at matching potential mates. For all the fun tangents that our conversations about these unique, cutting edge AI driven technologies take us on, we always seem to at some point arrive at the significance of the human element. For those listening, I did air quotes around the human element. So anyway, the human element, right? That intangible thing that AI is getting better at, but still can't quite replicate. And when we break down that borderline mystical phrase, we find a big part of what we're really talking about is empathy. Empathy comes up a lot, as it should. After all, we are a podcast about emotions. So what could be more important than the ability to sense others' emotions and imagine what someone else might be feeling or experiencing, right? So if it's so important, why haven't we created a perfectly empathic AI yet? What is it about that human element that is so significant in all of these totally different scenarios? Why are some people more empathetic than others? Can you learn to be more empathetic? And if so, is that something you can only learn from other humans or can a machine teach you? We wanted to dig deeper into some of these ideas and explore a bit further, which sets the stage for our guest perfectly. I'll bring him in in just a second. But first, Alan, I have to start with a heartfelt congratulations to you and the entire Hume AI team. You are literally, sir, just off the plane back from Austin, Texas, where you gave a huge presentation as part of South by Southwest 14th annual pitch event. And you guys came back with some hardware. You won best in artificial intelligence.
and voice. What an awesome achievement. What an incredible experience. I'm sure. Can you sum it up in 30 seconds or less? Oh man, it was, it was surreal. I mean, it was like a shark tank in front of 500 people, 300 people, I don't know, multiple hundreds of people in the audience. I heard it was hundreds of thousands is what I've heard. We were in the AI, robotics and voice category where there'd been thousands of applicants who submitted video pitches. So every single one of the top five finalists was super impressive. Actually three of them were pretty empathic related. One was a digital avatar company that was sort of like soul machines, but more cartoony. And there's a lot of room for that. And one was a really cool company that was, you would love, that was labeling cat facial expressions so that you could track your past well-being. Actually really promising. It's amazing. I'm, I mean, I'm a dog person, but an animal person overall. So cat facial, I want to know more about it. I will know more about it. It's only a matter of time. We should do a whole bonus episode of the show where you just get to break down that whole trip for him, man. I'm sure it's amazing. We'll, we'll see if that's something the listeners want. Maybe we'll make that happen. So congratulations again. So excited. I just wanted to bring that up. So proud and I look forward to seeing what other amazing opportunities this brings forward, man. Hey, speaking of amazing opportunities, I'm feeling really lucky today to have the chance to chat with our guests. They are an entrepreneur, researcher, and technology enthusiast with a vision to revolutionize virtual reality training, content, and adoption rates. In 2015, they co-founded immersion. What began as an educational technology venture built upon years of their academic research has since evolved into a virtual reality training platform designed to help unlock human potential immersion uses avatars powered by human reasoning and artificial intelligence to help professionals develop and enhance the essential skills required to be productive, effective, and generally just more successful in high stakes careers. Please welcome to the show, the co-founder and CTO of immersion. It's so cool to have you here. Arjun Nagarjuna is with us. Arjun, thank you so much for being here, sir. How are you doing? Fantastic. Wow. This is amazing. This is one of the funnest topics that, you know, we're going to have a lot of fun talking about. I, Alan, thanks again for the opportunity.
And again, thanks for having me on the show. Please don't mention it, man. We're stoked to have you here. Thank you for making the time in your schedule and coming and hanging out. All right, let's start where most people tend to start at the beginning. Take me back hard into 2015, man, I just want to get a little bit of context for everybody listening at home. I want to talk about the early days of merge and briefly how it all began, the inspiration behind the original idea, and just sort of how it's grown over the past seven or so years. Just like Alan, 30 seconds go. I'm kidding. Yeah, awesome. Before merging launched, I spent a lot of time in academia, I have a background in robotics and we back in my postdoc days and also as an as a research professor, we were trying to seamlessly blend the boundaries between robotics, virtual reality and artificial intelligence. And we, you know, we had this great opportunity where we had to work with, you know, the United States Navy around training Marines on cross-cultural skills. And it was this idea that, you know, you're going to Afghanistan, you've got things that you've got to deal with there that are, you know, cultural norms, we don't quite understand them. How do you train for this when there's people from different cultures and different backgrounds and ultimately all want to achieve, you know, the same sort of goal. And one of the things we did back in the day was combine the technology that we have now, which really forms the core IP of merging to drive robots that were located really far away with, you know, projections on the faces of the robots or think of these as animatronic devices and the animatronic devices would basically, you know, have the culturally appropriate gestures and norms in order to interact with these Marines. So it would give them that physical presence of being an animatronic that was kind of real, but at the same time, a human controlling it from, you know, miles and miles away would add that layer of nuance around, you know, the sorts of language or the sorts of, you know, things that you would say that would pose a resistance to the Marine. And so, of course, we developed that, we used the technology in education and teaching to try and train teachers around the classrooms. There were researchers in the School of Education that were using this platform. And you know, over the course of about five years, we built a lot of the core IP back then. And we almost had like 20. Yeah. Yeah. Yeah. 
already using the system in a research capacity that kind of gave us a lot of confidence that this is something we could actually take from the lab into the real world. And it was that kind of what prompted Mark was my co founder and I to launch immersion in 2015. And we, of course, immediately launched into, you know, the customer service space and, you know, the rest of the sales history. Wow. Absolutely amazing, man. I just, I, as I've mentioned other podcasts before, I'm kind of a theme park nut. And so I know a lot about like Disney's history with animatronics and the first animator and just the amount of work and effort that goes into programming and animating a lifelike cycle for those robots. And the idea of being able to create a system that can sort of pull all of that just from a human performance for miles is very cool, crazy idea that blows my mind. And I want to unpack and talk more about as we go on. We're going to come back. There's a million things I have follow-ups for in that story. But Alan, dumb question. Why is empathy so important again? As I recall, part of Hume's mission statement is like a future with more empathic AI. Why is it important that we steer technology in that direction? Pretend I know nothing. The core thing that empathy does is it makes us understand each other and what we're feeling. Right. So I understand what you're feeling. I understand a little bit about what Arjun is feeling just from what you're saying, how your face is moving from your vocal inflections. And this is just this magical ability. And for most people, it means that I care about your well-being and I'm kind of calibrating my behaviors to make sure they have positive effects on you. Right. And the whole goal is to make sure that empathy is invoked as much as possible when you're dealing with people who are facing hardship. And there's lots of hardship going on in this world. There's quotes about people being reduced to statistics. That means that you understand what's happening, but you don't empathize. And you don't, as a result, have the instinct to make a decision that's going to have a positive effect on those people. So really critical ability and really critical to extend to our community.
Our goal is to restore empathy to situations where AI is making decisions on behalf of a human, and it may not otherwise have access to those really important indicators to tell it how it can make decisions that are positive for you. Right. This is kind of open for everybody here. Why is it that why do we keep running into this idea that we still need to incorporate some level of human input? Not that I'm trying to push anyone out of a job, but why are so many companies finding right now the best solution seem to be this hybrid model of humans and AI working in tandem? I mean, the concern is really that the AI doesn't have empathy, right? And you're optimizing the AI for some objective and it has some input, it has some output, but it might not be considering something. It might not be considering how people actually feel in the way that humans would. And so it makes sense in lieu of empathic AI to make sure that there's always a human in the loop. Of course, humans have biases, right? Sometimes you want to take the human out of the loop. And ultimately, the best solution may be an empathic AI without a human. Yeah. Arjun, did you guys know from the beginning that it was going to be hybrid? Or did you try at first to go strict machine learning, AI driven? And then you were like, we need people here. What was that journey like? Yeah, it's a really good question. I mean, 10 years back, my answer to that question would have been very different from what it is now. So 10 years back, you're in the thick of trying to develop the most automated system you possibly can. And you're younger, you're kind of like fascinated by technology, and you really are doing technology for the sake of technology. And over time, you start to interact with people and you start to realize technology really should be an augmenter of human capabilities, which is we're really good at what we do. We want to use technology in cases where we're not as good as the technology is. And where we can improve, we use technology to augment our existing skills.
Over time, you know, it's, it's one of those things that taught me that conversational AI is in that realm of, you know, there's been progress on it since the 1960s, right? And it's, that's a long period of time, given the advancements in technology and every other aspect, whereas conversational AI doesn't get there. And then you start to question what is it about conversational AI that makes it so hard. And the more you think about this, you start thinking about things like context. And the other day I was driving down my road and 25 miles per hour zone, right? And I saw two elderly gentlemen standing on the road and out of the car, I kind of looked at them. They were off to the side and I immediately saw them stop talking and turn around and glance, you know, 50 meters ahead. And that was a cue for me to say, they are concerned about something that's 50 meters ahead of them. And what could it possibly be? And I couldn't see my line of sight was around the curb road. And sure enough, I drive another 25 meters and there's these two, three year old kids on a bicycle. And they're in the middle of the road and they're playing. It's a quiet street. The grandparents are out there supervising the kids. If you think about, you know, relying on AI and sensors, there is no contextual information for those sensors to say there are two old people on the road looking at two kids and they're afraid for their safety, which means that that self-driving car isn't breaking right there. It's breaking at a point that's much further on when the actual sensor is seeing those kids. And it immediately dawned on me, like, this is exactly the kind of thing that we, as humans possess, which is this extension or this contextual thinking. And that contextual thinking goes years, right? It's everything you learned when you were a kid that, you know, all of a sudden is like, it jogs your memory. You trigger a part of your brain. You've locked that away. It's in cold storage and it comes rushing back. And unless AI and other systems are able, even if they are, to do something like that, relying on them to make the kinds of decisions that humans are making in the real world is, in my opinion, a mistake. Yeah. Yeah. When you think about just like how you...
First of all, the amount of sensors and then the sort of data bank you would need to reference that information for that machine to then know these old, there's just so much, it feels like something that will happen someday, but it's definitely well out of the scope of what I can process and like how you would build that logic tree to get you there to know to do that. When you talk about augmenting, I'm so happy to hear you use that word. One of the things I wanted to kind of figure out since it's in the title of today's episode is sort of how people consider or define augmented reality. For me, the simplest term, of course, I think of like Google Glass or HoloLens or like an overlay over something. I know Apple's been doing a lot with iOS and building AR backbones into there. You look through your phone and you can walk around an environment or see a little character dancing on your desk. That's augmented reality to me. When you talk about augmented reality, how do you think of it, Arjun? How do you define it? Is it just like that, an overlay, or is it more of like a suite of services and things? I'm very curious to your perspective on that, of what augmented reality is to you. Yeah. There is some debate about the terms now only because technologies are maturing so much that there's this cross boundaries between these different... The way I really want to think about this is there's a term called XR, or cross reality or extended reality, which really encompasses the boundaries of the different kinds of things you can do. So there's virtual reality, there's augmented reality, there's mixed reality. And then that spectrum, if you think about it, is kind of under this umbrella and the traditional definition of extended reality or XR or cross reality. Information augmentation, on the other hand, is very different, right? My definition, augmented reality needs a point in the real world to be tracked using a computer vision algorithm. And then somehow that registered point in the real world doesn't really move in space and you're able to overlay information on it, right? Which is your traditional definition of augmented reality. Now that's very different from the kinds of augmentation that we're thinking about now, which is, can we use technology to augment humans thinking, right? And that...
That is providing timely information, almost on-demand information, to the people that are needing that information. And that's kind of how I imagine augmentation, especially from a technological standpoint. It's, I am doing a task, I don't need to register a specific portion in my world in which I need that information displayed. I just contextually, and in that particular moment in time, require that information and the technology is able to provide that information to me in order to make, help me make a better decision than I already would have. So I'll defer to you on other kind of like lines of thinking around this. And I want to be sensitive to not, you know, redefine terms that have already been refined over 30, 40 years. The augmented reality is still augmented reality. It's a podcast, man. There's no rules out here. You can redefine. All right. But I appreciate the sensitivity. Alan, yeah. Let me hear your thoughts. Because I do, I do want to pivot from here in a second over to some stuff, specific dimmersion. But what do you think about that, man? Yeah. I mean, I'm a hundred percent in agreement. I think it's about what we're perceiving. I mean, reality is sort of a misnomer because like, it's always reality, whether it's augmented or virtual or whatever. I mean, it's what you're sensing. What is coming into your eyes. And I think it's about what we're perceiving. I mean, reality is sort of a misnomer because like, it's always reality, whether it's augmented or virtual or whatever. But I think it's about what we're perceiving. I mean, reality is sort of a misnomer because like, it's always reality, whether it's augmented or virtual or whatever. I mean, it's what you're sensing. What is coming into your eyes? What are you hearing? And that allows you to, you know, make high level inferences. But if it's augmented, you can make better inferences to help you think, can help you reason as to what is going on in your physical reality. In a virtual reality setting, your physical reality is actually swept away. There's no physical reality there. Augmented reality is almost the opposite. It's an attempt to bring more perceptual salience to certain things in your actual surroundings that you're sensing and to do some of the cognitive processing of those things to expedite how you're able to interact with the world. Awesome. Yeah, maybe just to add to that word, you've probably heard the term immersion a lot. And at least the way I think about immersion is you have five senses. How much of the five senses can you replace? And the more that you can replace, the more immersed you're going to be.
And if you think about the goggles that we put on, right, which are the virtual reality, you're kind of taking away sight and replacing it with completely something virtual. So that's 100%. So that's 20% of your senses. Then you think about sound, you have noise cancelling headphones, you add that on there. Now you replace 40%. And so as you edge towards, I mean, there's smell and taste, which are much harder. There's people in Japan that are actually working on. I was going to say, what are we trying to tackle next, man? What weird attachment do I have to buy now? It's crazy. You know, there was a, there was one of these, you know, conferences that I was at in 2013, or something like that. And you kind of move to a certain pixel on the screen and you could smell an orange where there was a visual orange and you could move to the other side and smell an apple. And they basically had, you know, the essences on the back end, and they had a control system that kind of tracked you and told you where exactly your nose was and mix the flavors such that between those boundaries, you can either smell an apple or an orange. It's kind of wild, right? You can't think of applications today, but people are thinking about those kinds of things. It's just so funny. For years, like retail spaces, there's so much psychology about like pumping a specific smell into their retail space to provide a certain experience. I, years ago, worked for a major tech retailer. And when the early, early days, they did this, there's like some of the old stores still had shelves built in where the smell machine would live and would pump the official fragrance in. And so whenever we talk about like creating, you know, the replicating smell in VR, I just, I just don't know how we'll ever cross that bridge without like a bunch of like ink tank, like smell cartridges that then have to, you know what I mean? Like there's obviously somebody's trying to crack that egg and I'm making a podcast. I'm not going to do it, but I'm just saying like, it's wild thought. All right. I wanted to talk, we're talking about the human and AI hybrid approach here. We're talking about augmenting abilities. So it segues very nicely into the simulation specialists at Mersion who are using a lot of tools at once to drive these experiences. And so the question I was really curious about is that looking at some of your specialists, almost all of them, if not all of them, keep me honest, Sergeant, had a background in the performing arts. They were either an actor or a performer in some regard. And so I was wondering, was it?
Is it obvious from day one that your sim specialists needed to have a performance background or was that a skill set that you decided to leverage as you went on throughout the process? I'll be really helpful if this person was an actor. Yeah, I mean, it's a really interesting question. I actually think we're still trying to figure out the answer, you know, and I'll tell you why in a minute. So obviously over the course of, you know, six or seven years, there's technological barriers that we've overcome that allow, you know, pretty much anyone to go in and inhabit an avatar and appear real because, again, it's the AI handling a lot of that load. But at the same time, you know, back in the day when we were working at the university, a lot of the kinds of scenarios we would create in the virtual reality simulations required an acting background, particularly because we were dealing with, you know, multiple avatars in a virtual classroom, all controlled by a single person, and we didn't have technology back then to, you know, allow them to seamlessly play different kids, like different ages and they had to modulate their voices and, you know, and today technology has taken a lot of that stuff over because, you know, you can morph somebody's voice to sound like a different person. And in addition, there's just the cognitive load of needing to play multiple roles is something that people with an acting background find relatively easier than others. And the flip side of this is that, you know, the power of the platform comes from the idea that a subject matter expert is somebody that can really push the buttons of somebody wanting to learn, right? And you can take the example of, you know, if we wanted to apply this technology to teach kids that had autism social skills. Now what an expert in the field of autism will know is how do I safely interact with that kid in a way that teaches them social skills but doesn't do them harm, right? And that's something that you have to train for. And that's much harder to train.
If you don't have a background in that area, then it is to train you to inhabit an avatar because now the technology of has the affordance that allows you to be that avatar. And so we've even imagined a world someday, which we've not tested, but these are just, you know, when I say we, again, off the record, it's things that I think about we can do is you always had a favorite teacher in school and you always hated one of your teachers and you probably hated that subject. But you always had a favorite superhero. Now, if that teacher could manifest as a superhero, are you more likely to learn that subject? And we can do that today. You know, Superman or Spiderman teaching me math with their web slinging is probably much more attractive than my math teacher. Yeah. And so it's just things like that, that, you know, they're kind of wild, you know, applications and they're not tested, but the technology affordances allow us to do that today. And it's something that we want to study as researchers. For sure. Well, it's such a cool idea. You know, do you really you're extrapolating this thing that I grew up when I was a kid, I remember the G.I. Joe PSAs. And like they would come on and tell you like how to prevent a forest fire. Maybe that was Smokey the Bear. Obviously, they weren't that effective. I can't recall any of them specifically. But the point is, like your favorite character was trying to teach you something. And to think of like the ability to now map that onto a teacher or something in school. It's just it's it's a really cool, fascinating idea that, again, blows my mind. Funny little bit real quick for those listening at home. If you go to Immersion's website and check out the team photos, everyone looks great for the record. I'm not saying nobody. Everybody looks fantastic. But here's a fun game for our listeners. Don't read what anyone does and see if you could spot all the sim specialists based on who has proper headshots. I was going through and I was like, oh, that's a specialist. Yep. Got it. OK. Yep. Oh, dynamic lighting. Some specialists. Yep. Got it. It was pretty funny. But anyway, OK, just go a little bit deeper without pulling the curtain too far back one. And you kind of touched a little bit on this in terms of adapting your approach in your speech to work with a child with autism. But and maybe the answer is just the right actors and the right person for the job. One of the things I'm super curious about.
We talk about controlling multiple avatars simultaneously, and those avatars can look like anybody, they can be anybody. And so, to paraphrase some copy from Mergen's website, if you have, say, a young white female identifying sim specialist leading a simulation, how do you make sure the choices they make as a performer with the avatars are true to the experience of each represented culture, race, sexual orientation, gender identity, etc.? Do you know what I mean? Yeah, yeah, no, and it's a, it's, this is a question that, you know, we think about all the time. And, you know, we spend a lot of time trying to figure this out. But, you know, our stance, at least over things that we've learned over the last few years is that what matters the most is the learning experience for the person on the other side. Right. We want to be careful to not shift the focus on what does it take to play the avatar, because that's not what the platform's intended to do. What the platform's intended to do is help the learners on the other end, get the best possible experiential learning that they can. Now, what we do is we have a very rigorous training and calibration process that, you know, helps these people do their jobs and their roles. And, you know, in the same way that you couldn't let anyone off the street go fly a plane, there's people that get certified to be pilots in our system. Right. And of course, more and more, we're trying to make it easier for people to become the pilots. And what we focus on is making sure that those guardrails that we establish do not cause any sort of negative impact for the person that's going through, you know, the learning simulation. Things like, you know, people ask us this question, like, how are you going to eliminate or mitigate the bias? And I think my answer personally is that you can't mitigate bias, like bias exists. The first thing that you've all got to recognize is that no matter what you try, I'm going to bring biases into the system. And the real question is, how does that bias impact the learning experience? And did you design the learning experience in a way that bias is the biggest component or is the learning experience the biggest component?
I'm going to be talking about a learning experience about something where you don't want bias to play a role. And so there's a lot of thought and there's a fantastic learning and design team at Virgin that actually thinks about these questions every single day while they're designing the experiences. And they sit down with the clients and actually, you know, design the experiences with them so that we're actually targeting the learning experience rather than worrying about how somebody manifests. So just to extend your line of thinking, if you wanted to play a four-year-old kid, there's no way you're going to bring a four-year-old kid into Virgin and say, go play a four-year-old kid. It makes no sense. No, it doesn't work. In the same way, you have a neurologically diverse kid in there and you don't want to go get a neurological diverse kid to go play a neurological diverse kid. There's no learning. There's also so much more harm to the person. Extend that again and like, you know, you extend that to race and ethnicity and say, oh, go play that Indian guy that grew up in Bangalore when he was 20 years old. And I'm like, hell no, I hated that life. I don't want that. That's not the target of this experience. The target of the experience is the person that's going to the simulation on the other side and us being able to say, are you able to solve your learning challenge in the presence of bias? And we do that with multi-exemplar training. It's not one thing, right? We have people go through lots and lots of simulations. Each time there's a different person. Like, I'll ask you this question, right? If you drive in a car that you hired via Uber and the guy was erratic, does that mean you're never getting into another Uber again? We do that every day in every life, right? Like in everyday life. And so it's the same thing. The more that you drive, the more confidence you have in these things. And at the end of the day, you get better. And that's kind of what we're trying to go for. For sure. Yeah, and it's fascinating to hear. I was just sort of thinking of it myself and where the questions kind of came from, which is like I had the wrong comparison at first because I was just thinking about the entertainment industry. And I look at just like how we've gone from breakfast at Tiffany's in the 60s and the less said about that performance, the better. But everyone knows what I'm talking about. To like now representation is important, like even to animation. We want to make sure a black character is voiced by a black actor. And I was like, OK, so this is a slippery slope.
engages across almost the entire 55% of the population. Let's go a little bit deeper here. In a training situation, you want to be able to provide feedback. You want to guide someone towards progress. A facilitator has to be tuned in to the trainee's responses and behavior. There's no one-size-fits-all solution here that I can think of. To what extent do different people express emotions in different ways? Can AI assist in translating these expressions across different people? Yeah. I mean, absolutely. I mean, you see across cultures, there are differences in how people express emotion. In East Asian cultures, people don't express many high arousal emotions. It's not a cultural norm, so generally, you'll conceal it if you're laughing sometimes. I mean, I'm not going to too broadly generalize, but there is that trend. And it's significant enough that in our data, we see half as much facial movement in East Asian cultures in response to document videos and social interactions versus in Western cultures overall. And so that's a huge difference. But people understand the same facial expressions, right? People are able to see the facial expression, know what it means. You can normalize across cultures. And it's really fascinating, actually, about the audience and seeing it. We have Arjun instead of Avatar or Mergen's Avatar playing simultaneously. And actually, I was going to bring this up, but it just turned off, so I don't know if this is the best time. I can see it on my side. You can still see it? Okay. I can still see it. And I was. And even if we don't bring it up right now, we can do what's called a tease, and we'll bring it up later. Okay. I just said it came up earlier. So yeah. And also, when we do bring it up, Arjun, just a heads up, there appears to be a mouse cursor right over his shirt. Yes, that's it. I was going to say that. He's gone. He's gone. 
Okay, so for those listening, I haven't introduced it into the video feed yet. Don't worry, you haven't missed it. But when we do, I'll let you know and you're going to want to definitely check out the videos to see it because it is pretty wild. But Alan, not to derail you too much. What were you saying? So what I was going to say about that is that what's brilliant about this simulation is that, you know, at the same time, you probably don't want to be talking to a real person in this training context, because then there's a real person there and they have the presence of a person and you're being judged by a person. This makes you feel like it's a playground. But this avatar is actually incredibly good at listening. It maintains all the listening gestures, right? Sort of the head nods and the looks of confusion and very subtle eye twitches that people use to express interest and maybe a little bit of doubt or confusion just at the right times and really brings you in. And I think that really embodies sort of how people engage with each other and with empathy in very subtle ways that might otherwise be lost. And this is brilliant because if you want to turn your video off in a video conference, you could use this, right? This could be talking for you. And what's even better is that... And maybe this is the pros and cons of this. But if you want, it can pretend it's listening and actually be listening. Well, I've mastered that. We want a daily basis now, like sipping coffee and really engaged because of the avatar. Alan, I don't want to cut you off, but I do, because we're getting into a bit of territory. This was going to be my follow-up for Arjun, because you're right. We've scratched the surface of this before. I think it was with Greg Cross when we were talking about in episode two, the ways in which people felt more comfortable interacting with a digital avatar, right? And you've talked a little bit about just now why you think that is. And I'd love Arjun to talk about why he thinks it is that people are more comfortable interacting with a digital avatar, especially because there seems to be this sweet spot where you want to make the avatar, like you were saying, Alan, responsive and more lifelike and have all the little facial tics and things like that. But there is still something about the avatar that makes it easier for me to talk to, more receptive.
I just would love to know, Arjun, why do you think that is? Why? Yeah. Yeah. I mean, this is like actually stuff that has been studied by researchers for a couple of decades now. And like Jeremy Valenson, who's a really, really good friend of mine, is one of the pioneers in this field. And even back in the day when we didn't have the technology to create the kind of fidelity that we need with the avatars, you know, research studies found that people were more willing to disclose things that they wouldn't to a real human to an avatar. And there's something fascinating about the psychology of the way we think, like we think it's a computer and like, you know, when you have a computer and the computer is presenting a problem to you, your first instinct is I want to try to beat this. And the fact that there's no human on the other side, or at least no apparent human on the other side kind of makes you realize that you're not going to get judged. It's a safe space. And if it's a safe space, I can commit errors and I can commit mistakes. And if you can commit mistakes, it's the best form of learning. Because we're, as humans, like I should speak for myself here is like, I do not want to believe the person that says something's impossible. I want to go do it myself, fail, and then say, oh, crap, you're right. And you know, this is giving you that space where you can safely go in, hardest of conversations you wouldn't know how to approach, and you can approach that conversation. And there's enough stimulus properties in the technology right now to make this feel like a very real interaction. And it's all the things that Alan pointed out, which is, we've gone to great lengths to design the AI now where, you know, there's those subtle movements, there's those eyebrow raises, there's the saccades in the eyes that are kind of looking around. Our goal is that when somebody interacts with these avatars, they start to feel real. And then there's the digital component of this, which makes them feel vulnerable. And the minute you're vulnerable, you're in there actually learning. And it's almost, you know, the best form of learning because you're getting immediate feedback. You're trying to shape your own behavior in response to the avatar's actions, because clearly you can annoy the avatar. And when you annoy the avatar, you're like, oops, I should not have.
Let's go back and correct it. And next time this happens in real life, this is going back to the thing I was saying back in the day. It's in your memory box. It's one of those things that you retrieve at a time when you're having a difficult conversation saying, Oh man, when I was talking to the avatar, something similar happened. I better not push this guy's buttons in real life. And it's giving you that visual component that even if you are on the phone, you're almost now able to visualize what the other person on the other end sounds like, which we all do every day. And it's just that the holistic component of the idea that humans are somehow more comfortable with digital characters and the idea that it's a safe space and the fact that that platform can give you so much measurement, which is really hard to do if you were interacting with a person in real life, you have no measure of how you're doing. There's no audio recording. There's no camera that's telling you, you kind of twitched when that guy did this. There's no poker face. But here, because you're interacting with a digital character, we're actually capturing all those signals. And it's all of the technology that like Alan and the team are working on human AI, which is, you know, you look at the facial expressions, you kind of look at how those facial expressions created a signature for you over the interaction. You can kind of look at those signatures of different people interacting with the avatars. And you can almost cluster people saying, hey, there's a group of like minded people here. And that's just from the data. And when you present that data back to me and you show me, here's a period where you had a really negative impact on the avatar. You kind of look at that and go, oh, my God, was I actually doing that? I did not realize this. Over time, you kind of like get better, right? Which is this whole concept of social effectiveness, which is you have to adjust your behavior in a manner that's not rule governed. In the sense that every time you speak to different people, you manifest or you pull things from your repertoire that are taking that conversation in the right direction. As opposed to being rule governed, where you say, smile at the person, you know, the Comcast guy wishes me a good morning, no matter how bad my internet connection is. And every Comcast representative understands that I understand exactly how you're feeling right now.
No, you don't. You have no idea what's going on, right? And that's a canned response from customer service that you don't want. That's amazing. The other thing I kind of want from this is that I've now presented at several conferences where I'm giving a talk and, you know, maybe there's like a hundred people in the audience, 200 people. Humble brag. We get it, Alan. You're popular. But I don't see, I don't see anyone. I might as well be talking to nobody. Right. And talking to nobody is actually really difficult. Like there's nobody acknowledging what you're saying. There's just something missing biologically. It makes it very unnatural feeling. You kind of, sometimes, sometimes there is somebody who has their camera on by default and they're making an active listening, like not like they're really following intently and they're like, you can also listen to my conference. That would actually be a solution to go up. Yeah. But I'm like, God bless that person because this makes me feel so much more natural and encouraged to like go through my talk with enthusiasm because otherwise there would just be somebody there who like doesn't know they're actually being seen, who's like not paying any attention at all. And it kind of has this weird subconscious effect on you. But you know, this avatar would be perfect to have too, because it just has all the perfectly timed listening cues that you kind of need. Uh, it's, it's amazing. And, um, you know, I, I said I would announce it, but for those listening, I will have at this point, cut it in for Arjun's response and I'll bring, I'll be bringing it up further throughout this episode as we move forward. So, uh, go, go and check out the video. If you haven't, it's really, it's, it's pretty amazing, Alan, you were, you were just talking about, uh, the significance of, of getting that visual feedback when giving a talk and how important it is to see someone actively listening. And then I was, uh, uh, pantomiming and doing that for you. Uh, it is, it's amazing to see those little motions replicated and recreated with the avatar, which again, if you're listening now, we will have, at this point, we're going to start, we're just about to start to cut it in. And you'll see it once Arjun starts speaking, um, Arjun, one of the things I've, I've asked on the show before, whenever we drift into this territory is, was there a sweet spot or are you guys still dealing with the sweet spot of making it a lifelike and responsive enough without, uh, drifting into uncanny valley creepiness territory? Like there's a tight rope to, to, to walk down there. And I'm just curious of your personal experience in navigating that. Yeah. And, um, I think this is again, one of those things that we've.
Experimented with over almost a decade now. And this concept of the uncanny valley, I mean, it was by Mori back in the 70s. But while it exists, theoretically, there's actually no experimental evidence that the uncanny valley exists. It can't be recreated, which means that every person has their own uncanny valley. There's different... On a big spectrum, if you ask people to draw where that threshold of that dip is, where they're starting to feel creepy, different people will draw that in different places because of their own experiences, their own biases, the kinds of things they've seen, and so on and so forth. So actually, there's no experimental evidence. But having said that, I mean, the biggest thing for us is, again, going back to this idea that we create immersion or situational plausibility and place illusion are kind of like the two concepts that we really try to reinforce. The situational plausibility is this idea that is this likely to occur in my world? Right. And so if you break any one of those two constructs, they were defined by Melis later back in the day, you start to lose this immersion in the actual experience itself. And there are several factors that can change or affect that experience. So in technological terms, things like tracking or things like those freezes that we often see in Wi-Fi connections, which is like, if I were interacting with this person in real life, and he's not going to freeze. And if he freezes, it kind of destroys this. Is this real? And so the technology affordances play a big part. And then of course, there's this context setting, which is if you walk into a really big location where you're expecting a certain ambience and a certain aura, and you recreate that same experience in a different ambience and a different aura, it breaks illusion. As Mel used to say, back in the day, a fight like this would never happen in a bar like that, right, which is one of his famous things that he quotes. And so back to your original question of where are we on the spectrum? I mean, we push for realism. We want this to feel
Feel as authentic, and we capture that not just from appearance, because it's one thing capturing static appearance, which is these photo real renders that you actually see with metahumans and all of the other stuff. And it's another thing when you actually try to bring them to life, which is what we're doing. And we're trying to bring them to life in real time, as you can see right now, where the artificial intelligence is listening to my audio, looking for different patterns in the data, somehow learning what kind of body language and facial expressions to exhibit, you know, listening to things like the tone and pitch of my voice to shape the lips, based on how the lips are being shaped, deciding how the face needs to get shaped. It's a lot of computation going on. And for us to achieve that in, you know, less than 33 milliseconds is hard. And we're doing this in real time. And so for us is when you're interacting with this avatar, are we preserving those two concepts? And the minute the answer to that is yes, you're preserving it, then we're good. You know, we're not in that uncanny valley and people will vary. There's the occasional time when somebody says an avatar is creepy, but I almost have not heard that in the recent past, as we've seen technological advancement help improve the fidelity of the avatars. I mean, like we've been talking, you know, with this avatar on for about an hour now. And I, actually, it's a question for any of you, if you feel anything that that avatar is doing right now is creepy or looks odd or not, and you kind of get used to it, right? It's that initial reaction of what is this thing? And then you kind of are, in some ways, like you calibrate. Yeah. Yeah. For sure. And honestly, I haven't once felt creeped out or that it was weird. There was, like you said, a couple of seconds of calibration of just like, oh, I'm not a custom to seeing that. And then it was like, oh, yeah, it's just another person on the chat. He's in my peripheral vision. I look over. He's there. It's really fascinating the way your brain adjusts to it so quickly. Yeah. I mean, think of this from an evolutionary standpoint, right? We've seen humans and billions of humans and we see millions and millions of people. Your brain calibrates from when you're a baby. And how many avatars have we ever seen? 10? 15? 20?
You talked about infancy. I mean, this is kind of like pre-infancy, right? And over the years, this will become the norm. People in digital environments will need to use avatars to interact with others. And our job as researchers and technologists is to provide them with the best kinds of systems that will allow them to do the functions that they're required to do. Alan, you started to kind of touch on this a little bit, you know, just kind of looking down the road and sort of the implications of this technology moving forward just at a societal level. You know, I was talking to you earlier and you were telling me about how people tend to naturally gravitate towards other similar looking and culturally similar people. It's just how we're programmed. It's what we do. Do you think like AR and the metaverse and stuff like can function as a platform where people will be able to more easily form connections across demographics and across cultures outside of their comfort zones and bridge more gaps than we are today? Yeah. I mean, a hundred percent. And you can imagine there's the translation issue. Translation only gets you so far, right? You can know literally what somebody's saying. You need to be able to also translate their process. You want to be able to translate their facial expression. And there's all these subtle gestures people do where, you know, literally it's very difficult for somebody in, you know, maybe South America to do business with somebody in Japan because there are cultural barriers that go beyond just translation. You know, even when it comes to email, like where you have a lot of time to think about it. But then when you're speaking in person, it's really clear that there are these barriers. It's sort of unclear when somebody, it's okay to interrupt somebody, for example, or are they being polite? What are the norms of etiquette around emotional expressions? Because that's really where there are a lot of cultural differences. People sort of get the meaning of the emotional expression, but sort of laughing out loud has a different sort of etiquette around it in different countries. And so what if you could just surpass all of that and have the avatar act perfectly appropriately to you when you're looking at somebody else?
How do you guys think about, and this one I struggle with because on the one hand I'm like, Oh, this would be great. But also, okay, so let me just get my all my thoughts out. And then we'll put them together into a cohesive sentence. So thinking about just sort of the biases and the systemic racism that a lot of people, you know, it's 2022 and I'm still seeing headlines. There's a black family that had their white friend show off their home on their behalf and like, boom, it was appraised by almost a hundred thousand dollars more. How many stories have we heard? A person of color gets endless job rejections, but then all of a sudden they lie about the color of their skin. Bam, they get an interview. You know, it's disgusting. It happens all the time. And so my first thought was, Oh, we could create a system where maybe like for job interviews, like a more fair system where you disguise someone's like identity related attributes, but preserve or even augment their expressive behaviors. And I was like, that's a neat idea. But then you're also just kind of masking the problem. So I was like, what about using this to teach people with those biases or racist tendencies to see past that? And I know that's a big challenge because they got to want to learn. But so I'm throwing a lot out there at the board to see what sticks. But just in general, I felt like this could be such a powerful machine for us as a society moving forward. And I was just curious, any thoughts you have floating around there that can make it sound like I had a cohesive idea? Yeah. I mean, Alan, why don't you go and I kind of, I mean, this is the thing that keeps me up at night. Yeah. What do you think, Alan? Yeah. I mean, definitely. When you think about things like local accents or something where it can signal class, that's where there's a huge amount of bias still in this country. And obviously, racial bias and just being able to, like you said, you don't necessarily want to remove it from the equation during the job interview, but having people tested on the degree to which
This podcast is produced by Hume AI, a research lab and technology company. This podcast is produced by Hume AI, a research lab and technology company. Things are kind of innate, right? And they have all these fascinating things where they use these one cut plays where they have three different puppets and one puppet helps the other one and the other hinders the puppet and then they give babies infants, right? Like less than three months old, a choice between them and they automatically gravitate towards the ones that are helpful rather than hindering and so on and so forth. It's really fascinating. There's people studying a lot of this stuff, like Paul Bloom at Yale is one of the people that studies emotional empathy and cognitive empathy and all this other stuff. But it almost seems like positive biases that are for us are innate, which means we're kind of like always born being positive towards ourselves and the definition of us constitutes people that aren't strangers and people with the same likeness and people that we find and the negative biases for them are almost learned, which also means that if you're learned, you can be unlearned, right? Which is kind of what we play upon, which is kind of what we're talking about now. I think one of the first things and Alan hit upon this right at the very start of this, which is we do linguistic profiling and that's the time taking for us to say the word hello for it.
And 80% of the employers almost admit that we do discriminate based on accents, and this is like, you know, this is data that's out there, this is research that's out there. And the question for all of us is, the first step in eliminating something is recognizing its existence, right? And what the tools like what we're building now and stuff that, you know, Hume's building which allows us or gives us information about ourselves do is they allow us to measure and provide that information that tells me you have something that you don't recognize. This whole term called unconscious bias is something that by definition, it's not something you want to do, it's just there and you don't know you have it. And if we can pick the technology and have the technology basically provide the information around, hey, this is something that exists in you, that's your first step, which is recognition. And then you go ahead and design scenarios or design, you know, learning experiences that allow you to mitigate that bias. And over time, you kind of unlearn something that you've learned before. And that's the fascination. And that's the thing like, that I think we all are trying to solve is when we say we want a more empathic world, it's a world where we are learning to recognize these differences and still come together as one, right? And that's what technology is allowing us to do if applied in the right way. Right, right. That's beautiful, man. Well, I usually when we get into the homestretch, I always ask like, you know, what are the things we're really excited about coming down the pipe and all that. But I feel like we're kind of talking about that in a way right now. So actually, what I think will be fun to do to kind of cap things off, Arjun, you had almost mentioned something that's like spot on with this question we received. So, okay. Every week we say to our listeners, send us a question. And I finally checked before we taped. So I have something that actually really fits in nicely. You kind of started to talk about this before. This is from Intentionally Vague, and it says, hey, TFL team, so I lead social strategy for a large tech company. In regards to customer care and support, how can you scale support for your customers so they feel heard and taken care of without feeling
It's something like they are being handled by a robot. And you actually started mentioning this earlier. So I was like, this is great. Let's just, we'll cap it off with this. And I can actually get a fan question in here. So what do you think, man? Yeah. No, I know. You know, it's a fascinating question. The idea that here's where I would start. And it kind of follows up on the thing I was just saying before is recognition. And then of course, like the change, right? I mean, we all know that when we interact with humans, right. And we already are in these situations where we are certainly not happy with the kind of customer service we receive on a number of calls. And I've had this happen to myself. And, you know, there are times that, you know, things like you just mentioned happen, which is I have an odd accent, obviously, because I'm not from here. And then I get on the phone, the problem is still a problem. And then my wife, who's from California, gets on the phone and all of a sudden the problem is solved. And it's when we as humans in the customer support line can't solve for that problem, expecting, you know, AI and algorithms to solve that problem for us is a stretch. And the way I want to think about this, and Alan can speak much more to this than I can, is that first we have to get enough data that tells us that, you know, get away from that rule governing behavior, right? Like when somebody calls you, don't tell them you understand them and that you can certainly help them with their problem. Like try and listen to them. Be human, be empathic. Once you've done that, you have enough data to now train your algorithms around, okay, is this information that humans are? And if it's informational, then you use the robots in those places to scale. If you realize right at the moment that the person calls that, you know, this is way beyond being informational, this is a stressed out human being and definitely needs a human component to it. You try and put them on the line with another human and someday you hope that there's enough of those good interactions and samples that we create of bad interactions, not in real, like not in the real world, but like create synthetic samples of the bad interactions such that someday we can train them.
We train the AI to have those empathic responses, and then lastly, be transparent about it. Don't make the assumption that the person behind the scene knows that they're talking to a robot. Be super clear that, hey, you're about to talk to an empathic AI system, and be clear on how you went about creating that empathic AI system, which is really what Hume is doing right now, which is being able to validate why those algorithms are so much better than a whole bunch of other algorithms that have been created, because there's no transparency in the process of creation. But I'll let you, you know, speak more about this stuff. Yeah. I mean, you covered a ton of territory that I would say, you know, what is it first of all, what is it that sucks about talking to a service, you know, robot right now? What is it that's, you know, why is it that talking to an automated call center agent is just not, is a frustrating experience, let alone not being satisfying? Because, you know, first of all, it's something that doesn't understand what you're feeling. So obviously it doesn't care. And so there's nobody on the other line who's going to say, okay, I really do care that you're having a bad experience, because even if they did, you wouldn't believe them, because it is, it is simply an automated robot thing. But, you know, at the very least, one of the things that's frustrating is that, you know, even if you don't care, if it cares, you still want to be understood. You still want to communicate what is going on. And for the other thing to understand, okay, this is a problem. And a lot of that occurs in your emotional information. A lot of it isn't language. And even if it is, it might be subtle. So, you know, there's just something completely lacking about its ability to even understand you and keep pace, be more conversational, ask the follow up questions that the human would ask, if it knew you were frustrated, if it would, you know, the human would unpack frustration. Emotion is begging to be unpacked, right? That's sort of what emotional intonation does, is it makes somebody go, oh, like, I noticed that you're frustrated about this thing, you know, tell me a little bit more about what it is that's causing this. And so you don't need to be incredibly, you know, concrete about what you're saying. And so a lot of it is...
And there's an informational component to being understood. And then as I said, when it's non-informational, when it really does come down to, okay, there's nobody on the other line that cares about me. And then there should be a time when you get transferred to a human. It should never be that you're always stuck with this automated agent. It's just not a good experience to have. It can be improved. At a certain point, you want somebody to really understand the heights of your negative experience and maybe do something about it and say, we can compensate you for that. And sometimes that is what you're expecting. And only a human can get to the bottom of whether you're really having a negative time, or maybe you're over-exaggerating a little bit. You can be frustrated for both parties, but at least a human should be the one to make that assessment and not an automated agent. Yeah. It's almost like there's data, right? The healthcare sector almost has 90% of their lawsuits happen because the person on the other side didn't listen. It wasn't that a medical procedure went wrong or the bad medication was given. That's actually the cause, right? It's because somebody didn't listen. Yeah. It's wild. We all want our problems solved sometimes. Yeah. And I mean, talk about... Oh, I'm sorry. I didn't mean to cut you off, Arjun. Finish. That's what makes us human, right? That's what differentiates us from computers that are so task-oriented. Yeah. Well, I was just going to say, playing off of we all want our problems solved, I think both of you have solved intentionally vague's problem. That was a fantastic answer to anybody else listening. That's what you can expect. Send us a question. We've got really smart people here with really great advice and insight. Man, what a bummer that I got to wrap this up. Arjun, it has been so amazing to have you on the show with us today slash tonight, whoever's listening here. But again, such a treat. Thank you so much for taking time to hang out with us and being so generous with your time. I really appreciate it. We all really appreciate it. And I'm just very excited to have had this time with you. Thank you, man, so much. My pleasure, Alan. And Matt, thank you so much for having me on the show. I can't wait to keep chatting with you guys about more stuff. Yeah.
Éline, thank you as always, Éline, I wouldn't do this without you. Honestly, I appreciate you too, man. Thanks, guys. And to those listening and watching and ideally enjoying the show all over the world, I appreciate you too. I wouldn't show up without Éline, but we'd have no reason to show up together without you. So thank you, listeners and viewers out there. Do us a favor and let us know what you think, or even better, how you're feeling. Send us an email over at thefeelingslabathume.ai, T-H-E-F-E-E-L-I-N-G-S-L-A-B-A-T-H-U-E-M-E.ai. Ask a question, suggest a topic, or hey, let me know if you want to hear me grill Alan over his trip to South by Southwest. Whatever it is, send it this way, and I'm sure I'll eventually accidentally delete it, retrieve it, read it, and then do something about it. So go ahead, send it on over. Anyway, farewell for now from all of us here at the Feelings Lab, my friend. I'm Matt Forte. Thanks again, everybody, and please stay safe out there.
